{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phrase_3_report.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "Ct7otAslxmjg",
        "outputId": "41550205-dadc-41de-b6f8-9249257b4e86"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f56c1398-baa8-46cc-81a3-8c63a23c9d41\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f56c1398-baa8-46cc-81a3-8c63a23c9d41\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Maternal_Health_Risk_Data_Set.csv to Maternal_Health_Risk_Data_Set.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "x = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('Maternal_Health_Risk_Data_Set.csv', delimiter = ',')\n",
        "data.head()\n",
        "# Binary classification is done in phrase 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cLfMpMfKx245",
        "outputId": "28abba96-3845-4e06-aacc-174e8553db14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  in-Risk\n",
              "0   25         130           80  15.0      98.0         86        1\n",
              "1   35         140           90  13.0      98.0         70        1\n",
              "2   29          90           70   8.0     100.0         80        1\n",
              "3   30         140           85   7.0      98.0         70        1\n",
              "4   35         120           60   6.1      98.0         76        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34a6cc42-5d69-4136-8eef-1b2124353d5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>in-Risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>13.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>8.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>140</td>\n",
              "      <td>85</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34a6cc42-5d69-4136-8eef-1b2124353d5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34a6cc42-5d69-4136-8eef-1b2124353d5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34a6cc42-5d69-4136-8eef-1b2124353d5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataset = np.genfromtxt('Maternal_Health_Risk_Data_Set.csv',delimiter=',', skip_header = True)\n",
        "np.set_printoptions(formatter = {'float': '{:0.2f}'.format})\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DyIRienx5sv",
        "outputId": "94927b36-f379-4eb9-e60c-61b1a49449f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1014, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "np.random.shuffle(dataset)"
      ],
      "metadata": {
        "id": "fQKIGTZEyZrs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation, 20% validation set and 80% training \n",
        "index_20percent = int(0.2 * len(dataset[:, 0]))\n",
        "print(index_20percent)\n",
        "XVALID = dataset[:index_20percent, :-1]\n",
        "YVALID = dataset[:index_20percent, -1]\n",
        "XTRAIN = dataset[index_20percent:, :-1]\n",
        "YTRAIN = dataset[index_20percent:, -1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7m--8-tx-Ue",
        "outputId": "cbea0c62-c2df-4263-acc7-e99d5522fcff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = XTRAIN.mean(axis = 0)\n",
        "XTRAIN -= mean\n",
        "range = XTRAIN.max(axis = 0) - XTRAIN.min(axis = 0)\n",
        "XTRAIN /= range\n",
        "# mean normalization just like in phrase 1\n",
        "\n",
        "XVALID -= mean\n",
        "XVALID /= range"
      ],
      "metadata": {
        "id": "App8otrl6lJL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "q4PgGk9KySpH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential() # Logistic regression model\n",
        "model1.add(Dense(1, input_dim=len(XTRAIN[0,:]), activation='sigmoid'))\n",
        "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics='accuracy' )\n",
        "# activation and optimizer are changing in order to find highest validation accuracy"
      ],
      "metadata": {
        "id": "5CINtKzH3--R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(x= XTRAIN, y=YTRAIN, validation_data = (XVALID, YVALID), epochs = 1536, verbose = 1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKXPfgo85SUx",
        "outputId": "b12387cf-16a4-4b88-e75b-6f28a0331d0f"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1536\n",
            "26/26 [==============================] - 1s 15ms/step - loss: 0.7066 - accuracy: 0.5308 - val_loss: 0.7100 - val_accuracy: 0.5248\n",
            "Epoch 2/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.7010 - accuracy: 0.5456 - val_loss: 0.7062 - val_accuracy: 0.5099\n",
            "Epoch 3/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.5308 - val_loss: 0.7023 - val_accuracy: 0.4851\n",
            "Epoch 4/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.5271 - val_loss: 0.6988 - val_accuracy: 0.4752\n",
            "Epoch 5/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.5222 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
            "Epoch 6/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6819 - accuracy: 0.5259 - val_loss: 0.6926 - val_accuracy: 0.5050\n",
            "Epoch 7/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6776 - accuracy: 0.5283 - val_loss: 0.6896 - val_accuracy: 0.5050\n",
            "Epoch 8/1536\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.6735 - accuracy: 0.5271 - val_loss: 0.6866 - val_accuracy: 0.5050\n",
            "Epoch 9/1536\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.6694 - accuracy: 0.5246 - val_loss: 0.6839 - val_accuracy: 0.5050\n",
            "Epoch 10/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6655 - accuracy: 0.5271 - val_loss: 0.6812 - val_accuracy: 0.5099\n",
            "Epoch 11/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.5382 - val_loss: 0.6787 - val_accuracy: 0.5149\n",
            "Epoch 12/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.5431 - val_loss: 0.6761 - val_accuracy: 0.5198\n",
            "Epoch 13/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.5517 - val_loss: 0.6739 - val_accuracy: 0.5248\n",
            "Epoch 14/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.5542 - val_loss: 0.6715 - val_accuracy: 0.5297\n",
            "Epoch 15/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.5591 - val_loss: 0.6694 - val_accuracy: 0.5446\n",
            "Epoch 16/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.5616 - val_loss: 0.6673 - val_accuracy: 0.5446\n",
            "Epoch 17/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.5653 - val_loss: 0.6653 - val_accuracy: 0.5495\n",
            "Epoch 18/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.5751 - val_loss: 0.6633 - val_accuracy: 0.5446\n",
            "Epoch 19/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.5764 - val_loss: 0.6615 - val_accuracy: 0.5495\n",
            "Epoch 20/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.5739 - val_loss: 0.6596 - val_accuracy: 0.5495\n",
            "Epoch 21/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.5825 - val_loss: 0.6580 - val_accuracy: 0.5693\n",
            "Epoch 22/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.5862 - val_loss: 0.6564 - val_accuracy: 0.5743\n",
            "Epoch 23/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.5899 - val_loss: 0.6548 - val_accuracy: 0.5644\n",
            "Epoch 24/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.5948 - val_loss: 0.6531 - val_accuracy: 0.5693\n",
            "Epoch 25/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.5973 - val_loss: 0.6517 - val_accuracy: 0.5693\n",
            "Epoch 26/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.6084 - val_loss: 0.6502 - val_accuracy: 0.5594\n",
            "Epoch 27/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6172 - accuracy: 0.6145 - val_loss: 0.6488 - val_accuracy: 0.5644\n",
            "Epoch 28/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6182 - val_loss: 0.6473 - val_accuracy: 0.5594\n",
            "Epoch 29/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6232 - val_loss: 0.6460 - val_accuracy: 0.5594\n",
            "Epoch 30/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.6293 - val_loss: 0.6448 - val_accuracy: 0.5594\n",
            "Epoch 31/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.6330 - val_loss: 0.6434 - val_accuracy: 0.5693\n",
            "Epoch 32/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6379 - val_loss: 0.6422 - val_accuracy: 0.5842\n",
            "Epoch 33/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.6441 - val_loss: 0.6409 - val_accuracy: 0.5842\n",
            "Epoch 34/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.6490 - val_loss: 0.6398 - val_accuracy: 0.5891\n",
            "Epoch 35/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.6502 - val_loss: 0.6387 - val_accuracy: 0.5891\n",
            "Epoch 36/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6552 - val_loss: 0.6375 - val_accuracy: 0.5941\n",
            "Epoch 37/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6515 - val_loss: 0.6363 - val_accuracy: 0.5941\n",
            "Epoch 38/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6527 - val_loss: 0.6352 - val_accuracy: 0.5990\n",
            "Epoch 39/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6527 - val_loss: 0.6341 - val_accuracy: 0.5990\n",
            "Epoch 40/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.6539 - val_loss: 0.6331 - val_accuracy: 0.5990\n",
            "Epoch 41/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.6539 - val_loss: 0.6321 - val_accuracy: 0.5990\n",
            "Epoch 42/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.6527 - val_loss: 0.6311 - val_accuracy: 0.6040\n",
            "Epoch 43/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6478 - val_loss: 0.6301 - val_accuracy: 0.5990\n",
            "Epoch 44/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.6527 - val_loss: 0.6291 - val_accuracy: 0.6040\n",
            "Epoch 45/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6589 - val_loss: 0.6282 - val_accuracy: 0.6089\n",
            "Epoch 46/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.6601 - val_loss: 0.6271 - val_accuracy: 0.6089\n",
            "Epoch 47/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6601 - val_loss: 0.6262 - val_accuracy: 0.6089\n",
            "Epoch 48/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6638 - val_loss: 0.6253 - val_accuracy: 0.6089\n",
            "Epoch 49/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6675 - val_loss: 0.6244 - val_accuracy: 0.6089\n",
            "Epoch 50/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.6712 - val_loss: 0.6236 - val_accuracy: 0.6089\n",
            "Epoch 51/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6712 - val_loss: 0.6226 - val_accuracy: 0.6139\n",
            "Epoch 52/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6712 - val_loss: 0.6218 - val_accuracy: 0.6139\n",
            "Epoch 53/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.6724 - val_loss: 0.6209 - val_accuracy: 0.6139\n",
            "Epoch 54/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.6712 - val_loss: 0.6201 - val_accuracy: 0.6188\n",
            "Epoch 55/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.6724 - val_loss: 0.6193 - val_accuracy: 0.6188\n",
            "Epoch 56/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.6724 - val_loss: 0.6186 - val_accuracy: 0.6188\n",
            "Epoch 57/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.6724 - val_loss: 0.6176 - val_accuracy: 0.6139\n",
            "Epoch 58/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.6712 - val_loss: 0.6169 - val_accuracy: 0.6089\n",
            "Epoch 59/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.6749 - val_loss: 0.6162 - val_accuracy: 0.6139\n",
            "Epoch 60/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.6761 - val_loss: 0.6154 - val_accuracy: 0.6139\n",
            "Epoch 61/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.6749 - val_loss: 0.6147 - val_accuracy: 0.6139\n",
            "Epoch 62/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.6773 - val_loss: 0.6140 - val_accuracy: 0.6139\n",
            "Epoch 63/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.6773 - val_loss: 0.6132 - val_accuracy: 0.6139\n",
            "Epoch 64/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.6773 - val_loss: 0.6125 - val_accuracy: 0.6139\n",
            "Epoch 65/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.6773 - val_loss: 0.6118 - val_accuracy: 0.6139\n",
            "Epoch 66/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.6798 - val_loss: 0.6111 - val_accuracy: 0.6188\n",
            "Epoch 67/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.6798 - val_loss: 0.6105 - val_accuracy: 0.6139\n",
            "Epoch 68/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.6823 - val_loss: 0.6098 - val_accuracy: 0.6139\n",
            "Epoch 69/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.6823 - val_loss: 0.6091 - val_accuracy: 0.6188\n",
            "Epoch 70/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.6823 - val_loss: 0.6086 - val_accuracy: 0.6139\n",
            "Epoch 71/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.6835 - val_loss: 0.6078 - val_accuracy: 0.6139\n",
            "Epoch 72/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.6933 - val_loss: 0.6072 - val_accuracy: 0.6139\n",
            "Epoch 73/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.6946 - val_loss: 0.6066 - val_accuracy: 0.6188\n",
            "Epoch 74/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.6995 - val_loss: 0.6059 - val_accuracy: 0.6287\n",
            "Epoch 75/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7032 - val_loss: 0.6053 - val_accuracy: 0.6287\n",
            "Epoch 76/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7032 - val_loss: 0.6046 - val_accuracy: 0.6287\n",
            "Epoch 77/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7044 - val_loss: 0.6040 - val_accuracy: 0.6337\n",
            "Epoch 78/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7057 - val_loss: 0.6034 - val_accuracy: 0.6337\n",
            "Epoch 79/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7057 - val_loss: 0.6028 - val_accuracy: 0.6337\n",
            "Epoch 80/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7057 - val_loss: 0.6023 - val_accuracy: 0.6337\n",
            "Epoch 81/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7057 - val_loss: 0.6017 - val_accuracy: 0.6238\n",
            "Epoch 82/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7007 - val_loss: 0.6011 - val_accuracy: 0.6238\n",
            "Epoch 83/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7020 - val_loss: 0.6006 - val_accuracy: 0.6238\n",
            "Epoch 84/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7032 - val_loss: 0.6000 - val_accuracy: 0.6287\n",
            "Epoch 85/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7044 - val_loss: 0.5995 - val_accuracy: 0.6287\n",
            "Epoch 86/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7044 - val_loss: 0.5990 - val_accuracy: 0.6287\n",
            "Epoch 87/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7057 - val_loss: 0.5984 - val_accuracy: 0.6238\n",
            "Epoch 88/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7069 - val_loss: 0.5979 - val_accuracy: 0.6287\n",
            "Epoch 89/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7094 - val_loss: 0.5975 - val_accuracy: 0.6238\n",
            "Epoch 90/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7081 - val_loss: 0.5969 - val_accuracy: 0.6238\n",
            "Epoch 91/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7081 - val_loss: 0.5964 - val_accuracy: 0.6238\n",
            "Epoch 92/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7081 - val_loss: 0.5960 - val_accuracy: 0.6238\n",
            "Epoch 93/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7106 - val_loss: 0.5955 - val_accuracy: 0.6238\n",
            "Epoch 94/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7131 - val_loss: 0.5950 - val_accuracy: 0.6238\n",
            "Epoch 95/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7131 - val_loss: 0.5946 - val_accuracy: 0.6188\n",
            "Epoch 96/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7143 - val_loss: 0.5941 - val_accuracy: 0.6188\n",
            "Epoch 97/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7131 - val_loss: 0.5937 - val_accuracy: 0.6238\n",
            "Epoch 98/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7143 - val_loss: 0.5933 - val_accuracy: 0.6238\n",
            "Epoch 99/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7143 - val_loss: 0.5928 - val_accuracy: 0.6238\n",
            "Epoch 100/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7155 - val_loss: 0.5924 - val_accuracy: 0.6238\n",
            "Epoch 101/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7155 - val_loss: 0.5919 - val_accuracy: 0.6238\n",
            "Epoch 102/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7192 - val_loss: 0.5915 - val_accuracy: 0.6287\n",
            "Epoch 103/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7192 - val_loss: 0.5912 - val_accuracy: 0.6287\n",
            "Epoch 104/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7167 - val_loss: 0.5907 - val_accuracy: 0.6386\n",
            "Epoch 105/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7192 - val_loss: 0.5904 - val_accuracy: 0.6386\n",
            "Epoch 106/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7192 - val_loss: 0.5900 - val_accuracy: 0.6386\n",
            "Epoch 107/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7192 - val_loss: 0.5897 - val_accuracy: 0.6386\n",
            "Epoch 108/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7180 - val_loss: 0.5893 - val_accuracy: 0.6386\n",
            "Epoch 109/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7180 - val_loss: 0.5889 - val_accuracy: 0.6337\n",
            "Epoch 110/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7192 - val_loss: 0.5886 - val_accuracy: 0.6386\n",
            "Epoch 111/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7180 - val_loss: 0.5881 - val_accuracy: 0.6386\n",
            "Epoch 112/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7167 - val_loss: 0.5878 - val_accuracy: 0.6386\n",
            "Epoch 113/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7155 - val_loss: 0.5874 - val_accuracy: 0.6386\n",
            "Epoch 114/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7167 - val_loss: 0.5872 - val_accuracy: 0.6386\n",
            "Epoch 115/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7167 - val_loss: 0.5869 - val_accuracy: 0.6386\n",
            "Epoch 116/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7167 - val_loss: 0.5865 - val_accuracy: 0.6386\n",
            "Epoch 117/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7143 - val_loss: 0.5863 - val_accuracy: 0.6386\n",
            "Epoch 118/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7131 - val_loss: 0.5858 - val_accuracy: 0.6386\n",
            "Epoch 119/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7131 - val_loss: 0.5856 - val_accuracy: 0.6386\n",
            "Epoch 120/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7131 - val_loss: 0.5852 - val_accuracy: 0.6386\n",
            "Epoch 121/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7192 - val_loss: 0.5849 - val_accuracy: 0.6386\n",
            "Epoch 122/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7167 - val_loss: 0.5847 - val_accuracy: 0.6436\n",
            "Epoch 123/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7167 - val_loss: 0.5843 - val_accuracy: 0.6337\n",
            "Epoch 124/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7229 - val_loss: 0.5841 - val_accuracy: 0.6337\n",
            "Epoch 125/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7192 - val_loss: 0.5838 - val_accuracy: 0.6337\n",
            "Epoch 126/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7254 - val_loss: 0.5834 - val_accuracy: 0.6337\n",
            "Epoch 127/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7266 - val_loss: 0.5832 - val_accuracy: 0.6337\n",
            "Epoch 128/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7266 - val_loss: 0.5829 - val_accuracy: 0.6337\n",
            "Epoch 129/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7266 - val_loss: 0.5825 - val_accuracy: 0.6337\n",
            "Epoch 130/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7266 - val_loss: 0.5823 - val_accuracy: 0.6386\n",
            "Epoch 131/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7254 - val_loss: 0.5819 - val_accuracy: 0.6337\n",
            "Epoch 132/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7266 - val_loss: 0.5817 - val_accuracy: 0.6386\n",
            "Epoch 133/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7266 - val_loss: 0.5814 - val_accuracy: 0.6386\n",
            "Epoch 134/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7266 - val_loss: 0.5810 - val_accuracy: 0.6535\n",
            "Epoch 135/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7278 - val_loss: 0.5808 - val_accuracy: 0.6485\n",
            "Epoch 136/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7266 - val_loss: 0.5807 - val_accuracy: 0.6535\n",
            "Epoch 137/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7278 - val_loss: 0.5803 - val_accuracy: 0.6535\n",
            "Epoch 138/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7278 - val_loss: 0.5801 - val_accuracy: 0.6584\n",
            "Epoch 139/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7278 - val_loss: 0.5799 - val_accuracy: 0.6535\n",
            "Epoch 140/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7266 - val_loss: 0.5797 - val_accuracy: 0.6584\n",
            "Epoch 141/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7291 - val_loss: 0.5794 - val_accuracy: 0.6584\n",
            "Epoch 142/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7266 - val_loss: 0.5792 - val_accuracy: 0.6584\n",
            "Epoch 143/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7266 - val_loss: 0.5790 - val_accuracy: 0.6584\n",
            "Epoch 144/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7266 - val_loss: 0.5787 - val_accuracy: 0.6634\n",
            "Epoch 145/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7266 - val_loss: 0.5785 - val_accuracy: 0.6634\n",
            "Epoch 146/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7266 - val_loss: 0.5783 - val_accuracy: 0.6634\n",
            "Epoch 147/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7278 - val_loss: 0.5781 - val_accuracy: 0.6634\n",
            "Epoch 148/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7266 - val_loss: 0.5780 - val_accuracy: 0.6634\n",
            "Epoch 149/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7278 - val_loss: 0.5777 - val_accuracy: 0.6634\n",
            "Epoch 150/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7278 - val_loss: 0.5775 - val_accuracy: 0.6634\n",
            "Epoch 151/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7303 - val_loss: 0.5773 - val_accuracy: 0.6634\n",
            "Epoch 152/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7303 - val_loss: 0.5770 - val_accuracy: 0.6634\n",
            "Epoch 153/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7303 - val_loss: 0.5769 - val_accuracy: 0.6634\n",
            "Epoch 154/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7291 - val_loss: 0.5767 - val_accuracy: 0.6634\n",
            "Epoch 155/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.7303 - val_loss: 0.5765 - val_accuracy: 0.6634\n",
            "Epoch 156/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7303 - val_loss: 0.5764 - val_accuracy: 0.6634\n",
            "Epoch 157/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7303 - val_loss: 0.5762 - val_accuracy: 0.6634\n",
            "Epoch 158/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7328 - val_loss: 0.5759 - val_accuracy: 0.6634\n",
            "Epoch 159/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7328 - val_loss: 0.5758 - val_accuracy: 0.6634\n",
            "Epoch 160/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7328 - val_loss: 0.5755 - val_accuracy: 0.6683\n",
            "Epoch 161/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7303 - val_loss: 0.5754 - val_accuracy: 0.6683\n",
            "Epoch 162/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7291 - val_loss: 0.5753 - val_accuracy: 0.6683\n",
            "Epoch 163/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7254 - val_loss: 0.5750 - val_accuracy: 0.6683\n",
            "Epoch 164/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7266 - val_loss: 0.5749 - val_accuracy: 0.6733\n",
            "Epoch 165/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7278 - val_loss: 0.5746 - val_accuracy: 0.6733\n",
            "Epoch 166/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7278 - val_loss: 0.5746 - val_accuracy: 0.6634\n",
            "Epoch 167/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7266 - val_loss: 0.5744 - val_accuracy: 0.6782\n",
            "Epoch 168/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7291 - val_loss: 0.5742 - val_accuracy: 0.6683\n",
            "Epoch 169/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7328 - val_loss: 0.5741 - val_accuracy: 0.6782\n",
            "Epoch 170/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7328 - val_loss: 0.5740 - val_accuracy: 0.6782\n",
            "Epoch 171/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7328 - val_loss: 0.5739 - val_accuracy: 0.6782\n",
            "Epoch 172/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7328 - val_loss: 0.5737 - val_accuracy: 0.6782\n",
            "Epoch 173/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7328 - val_loss: 0.5736 - val_accuracy: 0.6782\n",
            "Epoch 174/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7328 - val_loss: 0.5734 - val_accuracy: 0.6782\n",
            "Epoch 175/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7328 - val_loss: 0.5733 - val_accuracy: 0.6782\n",
            "Epoch 176/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7328 - val_loss: 0.5731 - val_accuracy: 0.6782\n",
            "Epoch 177/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7328 - val_loss: 0.5731 - val_accuracy: 0.6782\n",
            "Epoch 178/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7328 - val_loss: 0.5728 - val_accuracy: 0.6782\n",
            "Epoch 179/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7328 - val_loss: 0.5728 - val_accuracy: 0.6782\n",
            "Epoch 180/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7328 - val_loss: 0.5726 - val_accuracy: 0.6782\n",
            "Epoch 181/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7328 - val_loss: 0.5724 - val_accuracy: 0.6782\n",
            "Epoch 182/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7328 - val_loss: 0.5723 - val_accuracy: 0.6782\n",
            "Epoch 183/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7352 - val_loss: 0.5722 - val_accuracy: 0.6733\n",
            "Epoch 184/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7328 - val_loss: 0.5721 - val_accuracy: 0.6733\n",
            "Epoch 185/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7352 - val_loss: 0.5719 - val_accuracy: 0.6733\n",
            "Epoch 186/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7352 - val_loss: 0.5717 - val_accuracy: 0.6782\n",
            "Epoch 187/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7352 - val_loss: 0.5717 - val_accuracy: 0.6782\n",
            "Epoch 188/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7352 - val_loss: 0.5715 - val_accuracy: 0.6782\n",
            "Epoch 189/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7352 - val_loss: 0.5715 - val_accuracy: 0.6733\n",
            "Epoch 190/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7365 - val_loss: 0.5713 - val_accuracy: 0.6782\n",
            "Epoch 191/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7377 - val_loss: 0.5711 - val_accuracy: 0.6782\n",
            "Epoch 192/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7377 - val_loss: 0.5710 - val_accuracy: 0.6782\n",
            "Epoch 193/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7278 - val_loss: 0.5708 - val_accuracy: 0.6485\n",
            "Epoch 194/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7217 - val_loss: 0.5707 - val_accuracy: 0.6485\n",
            "Epoch 195/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7204 - val_loss: 0.5706 - val_accuracy: 0.6485\n",
            "Epoch 196/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7229 - val_loss: 0.5706 - val_accuracy: 0.6485\n",
            "Epoch 197/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7217 - val_loss: 0.5704 - val_accuracy: 0.6535\n",
            "Epoch 198/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7204 - val_loss: 0.5704 - val_accuracy: 0.6535\n",
            "Epoch 199/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7217 - val_loss: 0.5703 - val_accuracy: 0.6535\n",
            "Epoch 200/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7266 - val_loss: 0.5702 - val_accuracy: 0.6535\n",
            "Epoch 201/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7217 - val_loss: 0.5701 - val_accuracy: 0.6535\n",
            "Epoch 202/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7241 - val_loss: 0.5700 - val_accuracy: 0.6535\n",
            "Epoch 203/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7217 - val_loss: 0.5699 - val_accuracy: 0.6535\n",
            "Epoch 204/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7204 - val_loss: 0.5698 - val_accuracy: 0.6535\n",
            "Epoch 205/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7204 - val_loss: 0.5698 - val_accuracy: 0.6535\n",
            "Epoch 206/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7204 - val_loss: 0.5697 - val_accuracy: 0.6535\n",
            "Epoch 207/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7204 - val_loss: 0.5697 - val_accuracy: 0.6535\n",
            "Epoch 208/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7204 - val_loss: 0.5696 - val_accuracy: 0.6535\n",
            "Epoch 209/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7204 - val_loss: 0.5695 - val_accuracy: 0.6535\n",
            "Epoch 210/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7217 - val_loss: 0.5694 - val_accuracy: 0.6485\n",
            "Epoch 211/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7217 - val_loss: 0.5694 - val_accuracy: 0.6485\n",
            "Epoch 212/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7217 - val_loss: 0.5694 - val_accuracy: 0.6485\n",
            "Epoch 213/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7217 - val_loss: 0.5693 - val_accuracy: 0.6485\n",
            "Epoch 214/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7217 - val_loss: 0.5693 - val_accuracy: 0.6485\n",
            "Epoch 215/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7217 - val_loss: 0.5691 - val_accuracy: 0.6485\n",
            "Epoch 216/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7217 - val_loss: 0.5691 - val_accuracy: 0.6485\n",
            "Epoch 217/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7217 - val_loss: 0.5690 - val_accuracy: 0.6485\n",
            "Epoch 218/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7217 - val_loss: 0.5690 - val_accuracy: 0.6485\n",
            "Epoch 219/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7192 - val_loss: 0.5688 - val_accuracy: 0.6485\n",
            "Epoch 220/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7192 - val_loss: 0.5687 - val_accuracy: 0.6485\n",
            "Epoch 221/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7192 - val_loss: 0.5687 - val_accuracy: 0.6485\n",
            "Epoch 222/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7192 - val_loss: 0.5686 - val_accuracy: 0.6485\n",
            "Epoch 223/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7192 - val_loss: 0.5685 - val_accuracy: 0.6485\n",
            "Epoch 224/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7192 - val_loss: 0.5683 - val_accuracy: 0.6485\n",
            "Epoch 225/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7167 - val_loss: 0.5683 - val_accuracy: 0.6485\n",
            "Epoch 226/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7167 - val_loss: 0.5682 - val_accuracy: 0.6485\n",
            "Epoch 227/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7167 - val_loss: 0.5682 - val_accuracy: 0.6485\n",
            "Epoch 228/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7167 - val_loss: 0.5682 - val_accuracy: 0.6485\n",
            "Epoch 229/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7167 - val_loss: 0.5681 - val_accuracy: 0.6485\n",
            "Epoch 230/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7167 - val_loss: 0.5680 - val_accuracy: 0.6485\n",
            "Epoch 231/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7167 - val_loss: 0.5680 - val_accuracy: 0.6485\n",
            "Epoch 232/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7167 - val_loss: 0.5678 - val_accuracy: 0.6485\n",
            "Epoch 233/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7167 - val_loss: 0.5678 - val_accuracy: 0.6485\n",
            "Epoch 234/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7167 - val_loss: 0.5677 - val_accuracy: 0.6485\n",
            "Epoch 235/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7167 - val_loss: 0.5676 - val_accuracy: 0.6485\n",
            "Epoch 236/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7167 - val_loss: 0.5676 - val_accuracy: 0.6485\n",
            "Epoch 237/1536\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7167 - val_loss: 0.5676 - val_accuracy: 0.6485\n",
            "Epoch 238/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7155 - val_loss: 0.5676 - val_accuracy: 0.6485\n",
            "Epoch 239/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7155 - val_loss: 0.5675 - val_accuracy: 0.6485\n",
            "Epoch 240/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7131 - val_loss: 0.5674 - val_accuracy: 0.6485\n",
            "Epoch 241/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7131 - val_loss: 0.5674 - val_accuracy: 0.6485\n",
            "Epoch 242/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7131 - val_loss: 0.5673 - val_accuracy: 0.6485\n",
            "Epoch 243/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7143 - val_loss: 0.5672 - val_accuracy: 0.6485\n",
            "Epoch 244/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7131 - val_loss: 0.5673 - val_accuracy: 0.6485\n",
            "Epoch 245/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7131 - val_loss: 0.5672 - val_accuracy: 0.6485\n",
            "Epoch 246/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7143 - val_loss: 0.5671 - val_accuracy: 0.6485\n",
            "Epoch 247/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7155 - val_loss: 0.5670 - val_accuracy: 0.6634\n",
            "Epoch 248/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7155 - val_loss: 0.5670 - val_accuracy: 0.6634\n",
            "Epoch 249/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7155 - val_loss: 0.5669 - val_accuracy: 0.6634\n",
            "Epoch 250/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7155 - val_loss: 0.5669 - val_accuracy: 0.6634\n",
            "Epoch 251/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7155 - val_loss: 0.5667 - val_accuracy: 0.6535\n",
            "Epoch 252/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7143 - val_loss: 0.5668 - val_accuracy: 0.6634\n",
            "Epoch 253/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7155 - val_loss: 0.5668 - val_accuracy: 0.6634\n",
            "Epoch 254/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7155 - val_loss: 0.5667 - val_accuracy: 0.6634\n",
            "Epoch 255/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7155 - val_loss: 0.5665 - val_accuracy: 0.6535\n",
            "Epoch 256/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7167 - val_loss: 0.5665 - val_accuracy: 0.6535\n",
            "Epoch 257/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7155 - val_loss: 0.5665 - val_accuracy: 0.6535\n",
            "Epoch 258/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7167 - val_loss: 0.5663 - val_accuracy: 0.6535\n",
            "Epoch 259/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7167 - val_loss: 0.5662 - val_accuracy: 0.6535\n",
            "Epoch 260/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7167 - val_loss: 0.5663 - val_accuracy: 0.6535\n",
            "Epoch 261/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7167 - val_loss: 0.5663 - val_accuracy: 0.6535\n",
            "Epoch 262/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7167 - val_loss: 0.5663 - val_accuracy: 0.6535\n",
            "Epoch 263/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7167 - val_loss: 0.5663 - val_accuracy: 0.6535\n",
            "Epoch 264/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7167 - val_loss: 0.5663 - val_accuracy: 0.6535\n",
            "Epoch 265/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7167 - val_loss: 0.5662 - val_accuracy: 0.6535\n",
            "Epoch 266/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7167 - val_loss: 0.5662 - val_accuracy: 0.6535\n",
            "Epoch 267/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7167 - val_loss: 0.5662 - val_accuracy: 0.6535\n",
            "Epoch 268/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7167 - val_loss: 0.5661 - val_accuracy: 0.6535\n",
            "Epoch 269/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7155 - val_loss: 0.5661 - val_accuracy: 0.6535\n",
            "Epoch 270/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7167 - val_loss: 0.5662 - val_accuracy: 0.6535\n",
            "Epoch 271/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7143 - val_loss: 0.5661 - val_accuracy: 0.6535\n",
            "Epoch 272/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7143 - val_loss: 0.5661 - val_accuracy: 0.6535\n",
            "Epoch 273/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7143 - val_loss: 0.5661 - val_accuracy: 0.6535\n",
            "Epoch 274/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7143 - val_loss: 0.5660 - val_accuracy: 0.6535\n",
            "Epoch 275/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7131 - val_loss: 0.5660 - val_accuracy: 0.6535\n",
            "Epoch 276/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7131 - val_loss: 0.5660 - val_accuracy: 0.6535\n",
            "Epoch 277/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7131 - val_loss: 0.5659 - val_accuracy: 0.6535\n",
            "Epoch 278/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7131 - val_loss: 0.5658 - val_accuracy: 0.6535\n",
            "Epoch 279/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7131 - val_loss: 0.5659 - val_accuracy: 0.6485\n",
            "Epoch 280/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7131 - val_loss: 0.5658 - val_accuracy: 0.6535\n",
            "Epoch 281/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7131 - val_loss: 0.5658 - val_accuracy: 0.6535\n",
            "Epoch 282/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7131 - val_loss: 0.5658 - val_accuracy: 0.6485\n",
            "Epoch 283/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7131 - val_loss: 0.5658 - val_accuracy: 0.6485\n",
            "Epoch 284/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7131 - val_loss: 0.5656 - val_accuracy: 0.6535\n",
            "Epoch 285/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7131 - val_loss: 0.5657 - val_accuracy: 0.6485\n",
            "Epoch 286/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7131 - val_loss: 0.5655 - val_accuracy: 0.6485\n",
            "Epoch 287/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7131 - val_loss: 0.5656 - val_accuracy: 0.6485\n",
            "Epoch 288/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7131 - val_loss: 0.5655 - val_accuracy: 0.6535\n",
            "Epoch 289/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7143 - val_loss: 0.5655 - val_accuracy: 0.6535\n",
            "Epoch 290/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7143 - val_loss: 0.5654 - val_accuracy: 0.6535\n",
            "Epoch 291/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7143 - val_loss: 0.5654 - val_accuracy: 0.6535\n",
            "Epoch 292/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7143 - val_loss: 0.5654 - val_accuracy: 0.6535\n",
            "Epoch 293/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7143 - val_loss: 0.5653 - val_accuracy: 0.6535\n",
            "Epoch 294/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7143 - val_loss: 0.5652 - val_accuracy: 0.6535\n",
            "Epoch 295/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7143 - val_loss: 0.5652 - val_accuracy: 0.6535\n",
            "Epoch 296/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7143 - val_loss: 0.5652 - val_accuracy: 0.6535\n",
            "Epoch 297/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7143 - val_loss: 0.5651 - val_accuracy: 0.6535\n",
            "Epoch 298/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7143 - val_loss: 0.5651 - val_accuracy: 0.6535\n",
            "Epoch 299/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7143 - val_loss: 0.5651 - val_accuracy: 0.6535\n",
            "Epoch 300/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7143 - val_loss: 0.5651 - val_accuracy: 0.6535\n",
            "Epoch 301/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7143 - val_loss: 0.5650 - val_accuracy: 0.6535\n",
            "Epoch 302/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7143 - val_loss: 0.5650 - val_accuracy: 0.6535\n",
            "Epoch 303/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7131 - val_loss: 0.5650 - val_accuracy: 0.6535\n",
            "Epoch 304/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7143 - val_loss: 0.5649 - val_accuracy: 0.6535\n",
            "Epoch 305/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7143 - val_loss: 0.5648 - val_accuracy: 0.6535\n",
            "Epoch 306/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7143 - val_loss: 0.5647 - val_accuracy: 0.6535\n",
            "Epoch 307/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7131 - val_loss: 0.5647 - val_accuracy: 0.6535\n",
            "Epoch 308/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7143 - val_loss: 0.5647 - val_accuracy: 0.6535\n",
            "Epoch 309/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7143 - val_loss: 0.5648 - val_accuracy: 0.6535\n",
            "Epoch 310/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7118 - val_loss: 0.5647 - val_accuracy: 0.6485\n",
            "Epoch 311/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7106 - val_loss: 0.5647 - val_accuracy: 0.6485\n",
            "Epoch 312/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7106 - val_loss: 0.5647 - val_accuracy: 0.6485\n",
            "Epoch 313/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7106 - val_loss: 0.5646 - val_accuracy: 0.6485\n",
            "Epoch 314/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7106 - val_loss: 0.5647 - val_accuracy: 0.6485\n",
            "Epoch 315/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7106 - val_loss: 0.5647 - val_accuracy: 0.6485\n",
            "Epoch 316/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7106 - val_loss: 0.5647 - val_accuracy: 0.6485\n",
            "Epoch 317/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7106 - val_loss: 0.5645 - val_accuracy: 0.6485\n",
            "Epoch 318/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7106 - val_loss: 0.5646 - val_accuracy: 0.6485\n",
            "Epoch 319/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7106 - val_loss: 0.5645 - val_accuracy: 0.6485\n",
            "Epoch 320/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7106 - val_loss: 0.5644 - val_accuracy: 0.6485\n",
            "Epoch 321/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7106 - val_loss: 0.5645 - val_accuracy: 0.6485\n",
            "Epoch 322/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7106 - val_loss: 0.5644 - val_accuracy: 0.6485\n",
            "Epoch 323/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7106 - val_loss: 0.5644 - val_accuracy: 0.6485\n",
            "Epoch 324/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7106 - val_loss: 0.5644 - val_accuracy: 0.6485\n",
            "Epoch 325/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7106 - val_loss: 0.5645 - val_accuracy: 0.6485\n",
            "Epoch 326/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7106 - val_loss: 0.5645 - val_accuracy: 0.6485\n",
            "Epoch 327/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7106 - val_loss: 0.5644 - val_accuracy: 0.6485\n",
            "Epoch 328/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7106 - val_loss: 0.5644 - val_accuracy: 0.6485\n",
            "Epoch 329/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7106 - val_loss: 0.5643 - val_accuracy: 0.6485\n",
            "Epoch 330/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7106 - val_loss: 0.5643 - val_accuracy: 0.6485\n",
            "Epoch 331/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7106 - val_loss: 0.5643 - val_accuracy: 0.6485\n",
            "Epoch 332/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7106 - val_loss: 0.5643 - val_accuracy: 0.6485\n",
            "Epoch 333/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7106 - val_loss: 0.5643 - val_accuracy: 0.6485\n",
            "Epoch 334/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7106 - val_loss: 0.5643 - val_accuracy: 0.6485\n",
            "Epoch 335/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7106 - val_loss: 0.5642 - val_accuracy: 0.6485\n",
            "Epoch 336/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7106 - val_loss: 0.5642 - val_accuracy: 0.6485\n",
            "Epoch 337/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7106 - val_loss: 0.5642 - val_accuracy: 0.6485\n",
            "Epoch 338/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 339/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7106 - val_loss: 0.5642 - val_accuracy: 0.6485\n",
            "Epoch 340/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7106 - val_loss: 0.5642 - val_accuracy: 0.6485\n",
            "Epoch 341/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 342/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 343/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 344/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 345/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 346/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 347/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 348/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7106 - val_loss: 0.5641 - val_accuracy: 0.6485\n",
            "Epoch 349/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7106 - val_loss: 0.5640 - val_accuracy: 0.6485\n",
            "Epoch 350/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7106 - val_loss: 0.5640 - val_accuracy: 0.6535\n",
            "Epoch 351/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7131 - val_loss: 0.5640 - val_accuracy: 0.6535\n",
            "Epoch 352/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7131 - val_loss: 0.5640 - val_accuracy: 0.6535\n",
            "Epoch 353/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 354/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 355/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 356/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 357/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7131 - val_loss: 0.5638 - val_accuracy: 0.6535\n",
            "Epoch 358/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 359/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 360/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 361/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 362/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7131 - val_loss: 0.5638 - val_accuracy: 0.6535\n",
            "Epoch 363/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.6535\n",
            "Epoch 364/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7131 - val_loss: 0.5638 - val_accuracy: 0.6535\n",
            "Epoch 365/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7131 - val_loss: 0.5638 - val_accuracy: 0.6535\n",
            "Epoch 366/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7131 - val_loss: 0.5638 - val_accuracy: 0.6535\n",
            "Epoch 367/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7131 - val_loss: 0.5638 - val_accuracy: 0.6535\n",
            "Epoch 368/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7131 - val_loss: 0.5637 - val_accuracy: 0.6535\n",
            "Epoch 369/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7131 - val_loss: 0.5637 - val_accuracy: 0.6535\n",
            "Epoch 370/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7131 - val_loss: 0.5636 - val_accuracy: 0.6535\n",
            "Epoch 371/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7131 - val_loss: 0.5637 - val_accuracy: 0.6535\n",
            "Epoch 372/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7131 - val_loss: 0.5636 - val_accuracy: 0.6535\n",
            "Epoch 373/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7131 - val_loss: 0.5636 - val_accuracy: 0.6535\n",
            "Epoch 374/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7131 - val_loss: 0.5636 - val_accuracy: 0.6535\n",
            "Epoch 375/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7131 - val_loss: 0.5635 - val_accuracy: 0.6535\n",
            "Epoch 376/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7131 - val_loss: 0.5635 - val_accuracy: 0.6535\n",
            "Epoch 377/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7131 - val_loss: 0.5634 - val_accuracy: 0.6535\n",
            "Epoch 378/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7131 - val_loss: 0.5634 - val_accuracy: 0.6535\n",
            "Epoch 379/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7131 - val_loss: 0.5634 - val_accuracy: 0.6535\n",
            "Epoch 380/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7131 - val_loss: 0.5634 - val_accuracy: 0.6535\n",
            "Epoch 381/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7131 - val_loss: 0.5634 - val_accuracy: 0.6535\n",
            "Epoch 382/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 383/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7131 - val_loss: 0.5634 - val_accuracy: 0.6535\n",
            "Epoch 384/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7131 - val_loss: 0.5632 - val_accuracy: 0.6535\n",
            "Epoch 385/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 386/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7131 - val_loss: 0.5632 - val_accuracy: 0.6535\n",
            "Epoch 387/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 388/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 389/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7131 - val_loss: 0.5632 - val_accuracy: 0.6535\n",
            "Epoch 390/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 391/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 392/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7131 - val_loss: 0.5632 - val_accuracy: 0.6535\n",
            "Epoch 393/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 394/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7131 - val_loss: 0.5632 - val_accuracy: 0.6535\n",
            "Epoch 395/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7131 - val_loss: 0.5633 - val_accuracy: 0.6535\n",
            "Epoch 396/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7106 - val_loss: 0.5631 - val_accuracy: 0.6535\n",
            "Epoch 397/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 398/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 399/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 400/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 401/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 402/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 403/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 404/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 405/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 406/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7106 - val_loss: 0.5631 - val_accuracy: 0.6535\n",
            "Epoch 407/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7118 - val_loss: 0.5631 - val_accuracy: 0.6535\n",
            "Epoch 408/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 409/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 410/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7106 - val_loss: 0.5631 - val_accuracy: 0.6535\n",
            "Epoch 411/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7106 - val_loss: 0.5629 - val_accuracy: 0.6535\n",
            "Epoch 412/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 413/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7106 - val_loss: 0.5629 - val_accuracy: 0.6535\n",
            "Epoch 414/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 415/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7106 - val_loss: 0.5630 - val_accuracy: 0.6535\n",
            "Epoch 416/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7106 - val_loss: 0.5629 - val_accuracy: 0.6535\n",
            "Epoch 417/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7106 - val_loss: 0.5629 - val_accuracy: 0.6535\n",
            "Epoch 418/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7106 - val_loss: 0.5629 - val_accuracy: 0.6535\n",
            "Epoch 419/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7106 - val_loss: 0.5628 - val_accuracy: 0.6535\n",
            "Epoch 420/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7106 - val_loss: 0.5628 - val_accuracy: 0.6535\n",
            "Epoch 421/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7106 - val_loss: 0.5627 - val_accuracy: 0.6584\n",
            "Epoch 422/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7106 - val_loss: 0.5628 - val_accuracy: 0.6535\n",
            "Epoch 423/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7106 - val_loss: 0.5629 - val_accuracy: 0.6535\n",
            "Epoch 424/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7106 - val_loss: 0.5628 - val_accuracy: 0.6535\n",
            "Epoch 425/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7094 - val_loss: 0.5628 - val_accuracy: 0.6584\n",
            "Epoch 426/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7106 - val_loss: 0.5628 - val_accuracy: 0.6584\n",
            "Epoch 427/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7106 - val_loss: 0.5628 - val_accuracy: 0.6584\n",
            "Epoch 428/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7081 - val_loss: 0.5629 - val_accuracy: 0.6584\n",
            "Epoch 429/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7106 - val_loss: 0.5629 - val_accuracy: 0.6584\n",
            "Epoch 430/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7106 - val_loss: 0.5627 - val_accuracy: 0.6584\n",
            "Epoch 431/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7094 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 432/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7106 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 433/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7094 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 434/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7155 - val_loss: 0.5628 - val_accuracy: 0.6634\n",
            "Epoch 435/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7106 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 436/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7106 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 437/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7155 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 438/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7155 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 439/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7155 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 440/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7155 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 441/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7155 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 442/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 443/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 444/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 445/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7155 - val_loss: 0.5627 - val_accuracy: 0.6634\n",
            "Epoch 446/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 447/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 448/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 449/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 450/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 451/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 452/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 453/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 454/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 455/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 456/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 457/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 458/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 459/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 460/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 461/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 462/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 463/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 464/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 465/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 466/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 467/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7155 - val_loss: 0.5626 - val_accuracy: 0.6634\n",
            "Epoch 468/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 469/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 470/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 471/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 472/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7155 - val_loss: 0.5625 - val_accuracy: 0.6634\n",
            "Epoch 473/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 474/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 475/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 476/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 477/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 478/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 479/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5624 - val_accuracy: 0.6634\n",
            "Epoch 480/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 481/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 482/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7167 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 483/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7167 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 484/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 485/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7167 - val_loss: 0.5623 - val_accuracy: 0.6634\n",
            "Epoch 486/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7167 - val_loss: 0.5623 - val_accuracy: 0.6683\n",
            "Epoch 487/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 488/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6683\n",
            "Epoch 489/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 490/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 491/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 492/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 493/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6683\n",
            "Epoch 494/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 495/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 496/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 497/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 498/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 499/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 500/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 501/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 502/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 503/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 504/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 505/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 506/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5623 - val_accuracy: 0.6683\n",
            "Epoch 507/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 508/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 509/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 510/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 511/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7155 - val_loss: 0.5622 - val_accuracy: 0.6683\n",
            "Epoch 512/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 513/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 514/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 515/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7155 - val_loss: 0.5620 - val_accuracy: 0.6683\n",
            "Epoch 516/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 517/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 518/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5620 - val_accuracy: 0.6683\n",
            "Epoch 519/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 520/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 521/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 522/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 523/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 524/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 525/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 526/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 527/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 528/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 529/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 530/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7155 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 531/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7155 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 532/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 533/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 534/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 535/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 536/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 537/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 538/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 539/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 540/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5620 - val_accuracy: 0.6683\n",
            "Epoch 541/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5620 - val_accuracy: 0.6683\n",
            "Epoch 542/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5621 - val_accuracy: 0.6683\n",
            "Epoch 543/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 544/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 545/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 546/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 547/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7167 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 548/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 549/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 550/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 551/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 552/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 553/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 554/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 555/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 556/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 557/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 558/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 559/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 560/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 561/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 562/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 563/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 564/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 565/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 566/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 567/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 568/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 569/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 570/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 571/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 572/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7167 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 573/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 574/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 575/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 576/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 577/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 578/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 579/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 580/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 581/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 582/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 583/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 584/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 585/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6634\n",
            "Epoch 586/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6634\n",
            "Epoch 587/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 588/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 589/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 590/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 591/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 592/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6634\n",
            "Epoch 593/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6634\n",
            "Epoch 594/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6634\n",
            "Epoch 595/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6634\n",
            "Epoch 596/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6634\n",
            "Epoch 597/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6634\n",
            "Epoch 598/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6634\n",
            "Epoch 599/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6634\n",
            "Epoch 600/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6634\n",
            "Epoch 601/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 602/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 603/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 604/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 605/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 606/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 607/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 608/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 609/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 610/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 611/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 612/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 613/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 614/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 615/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 616/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 617/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 618/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 619/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 620/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 621/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 622/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 623/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 624/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 625/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 626/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 627/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 628/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 629/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7131 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 630/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 631/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 632/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 633/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 634/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 635/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 636/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 637/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 638/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 639/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 640/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 641/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 642/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 643/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 644/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 645/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 646/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 647/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 648/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 649/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 650/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 651/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 652/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 653/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 654/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 655/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 656/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7143 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 657/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 658/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 659/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 660/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 661/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 662/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 663/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 664/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 665/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 666/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 667/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 668/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 669/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 670/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 671/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 672/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 673/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 674/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 675/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 676/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 677/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 678/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 679/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 680/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 681/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 682/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 683/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 684/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 685/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 686/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 687/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 688/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 689/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 690/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 691/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 692/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 693/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 694/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 695/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 696/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 697/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 698/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 699/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 700/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 701/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 702/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 703/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 704/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 705/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 706/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 707/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 708/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 709/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 710/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 711/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 712/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 713/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 714/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 715/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 716/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 717/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 718/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 719/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 720/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 721/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 722/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 723/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 724/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 725/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 726/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 727/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 728/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 729/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 730/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 731/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7131 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 732/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 733/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7131 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 734/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 735/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 736/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 737/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 738/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 739/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 740/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 741/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 742/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 743/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 744/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 745/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7143 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 746/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7143 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 747/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 748/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 749/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 750/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 751/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7131 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 752/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7143 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 753/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7131 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 754/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 755/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7143 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 756/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5610 - val_accuracy: 0.6683\n",
            "Epoch 757/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7131 - val_loss: 0.5610 - val_accuracy: 0.6683\n",
            "Epoch 758/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 759/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 760/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7167 - val_loss: 0.5609 - val_accuracy: 0.6733\n",
            "Epoch 761/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7143 - val_loss: 0.5610 - val_accuracy: 0.6683\n",
            "Epoch 762/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5610 - val_accuracy: 0.6683\n",
            "Epoch 763/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7131 - val_loss: 0.5610 - val_accuracy: 0.6733\n",
            "Epoch 764/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7180 - val_loss: 0.5610 - val_accuracy: 0.6683\n",
            "Epoch 765/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 766/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 767/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 768/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 769/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 770/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 771/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 772/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 773/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 774/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 775/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 776/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 777/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5611 - val_accuracy: 0.6683\n",
            "Epoch 778/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 779/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 780/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 781/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 782/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 783/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 784/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 785/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 786/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 787/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7131 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 788/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 789/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 790/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 791/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 792/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 793/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 794/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 795/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 796/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 797/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7106 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 798/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 799/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 800/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 801/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 802/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 803/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 804/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 805/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 806/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 807/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 808/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 809/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 810/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 811/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 812/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 813/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 814/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 815/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 816/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 817/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 818/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 819/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7094 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 820/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7106 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 821/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 822/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 823/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 824/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 825/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 826/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 827/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 828/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 829/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 830/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 831/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 832/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 833/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 834/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 835/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 836/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 837/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 838/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 839/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 840/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 841/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 842/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 843/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 844/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 845/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7131 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 846/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7143 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 847/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 848/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 849/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 850/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 851/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 852/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 853/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7094 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 854/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 855/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7081 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 856/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7081 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 857/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6634\n",
            "Epoch 858/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7081 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 859/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7069 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 860/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7081 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 861/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7081 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 862/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7143 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 863/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7081 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 864/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 865/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 866/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 867/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 868/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 869/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 870/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 871/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 872/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 873/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 874/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 875/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 876/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 877/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 878/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 879/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6931\n",
            "Epoch 880/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7143 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 881/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 882/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 883/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 884/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 885/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 886/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 887/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7167 - val_loss: 0.5610 - val_accuracy: 0.6733\n",
            "Epoch 888/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 889/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 890/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 891/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 892/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7180 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 893/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 894/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 895/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5610 - val_accuracy: 0.6733\n",
            "Epoch 896/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 897/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 898/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 899/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 900/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 901/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 902/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 903/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 904/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 905/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 906/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 907/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 908/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 909/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 910/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 911/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7180 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 912/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 913/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 914/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 915/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 916/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 917/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 918/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 919/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 920/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 921/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 922/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 923/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 924/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7143 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 925/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 926/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 927/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 928/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 929/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 930/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 931/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 932/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7180 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 933/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 934/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 935/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 936/1536\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 937/1536\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 938/1536\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 0.4843 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 939/1536\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 940/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7192 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 941/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 942/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 943/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 944/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 945/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 946/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 947/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 948/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 949/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7143 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 950/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 951/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 952/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 953/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 954/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 955/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 956/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 957/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 958/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 959/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7143 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 960/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 961/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 962/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 963/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 964/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 965/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 966/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 967/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 968/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 969/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 970/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 971/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 972/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 973/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 974/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 975/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 976/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 977/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 978/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 979/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 980/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 981/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 982/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 983/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 984/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 985/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 986/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 987/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 988/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 989/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 990/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 991/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 992/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 993/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 994/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 995/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 996/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 997/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 998/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 999/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1000/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1001/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1002/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1003/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1004/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1005/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 1006/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1007/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1008/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1009/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1010/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1011/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1012/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1013/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1014/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1015/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1016/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1017/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1018/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 1019/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 1020/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1021/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 1022/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1023/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1024/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1025/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1026/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1027/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 1028/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 1029/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 1030/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 1031/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 1032/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5611 - val_accuracy: 0.6733\n",
            "Epoch 1033/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 1034/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6733\n",
            "Epoch 1035/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 1036/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1037/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1038/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1039/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1040/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1041/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1042/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1043/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1044/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1045/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1046/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1047/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1048/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1049/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1050/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1051/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1052/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1053/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1054/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1055/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1056/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1057/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1058/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1059/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1060/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1061/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1062/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1063/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1064/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1065/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1066/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1067/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1068/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1069/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1070/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1071/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1072/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1073/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1074/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1075/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1076/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1077/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1078/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1079/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1080/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1081/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1082/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1083/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1084/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1085/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1086/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1087/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1088/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1089/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1090/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1091/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1092/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1093/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1094/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1095/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1096/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1097/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1098/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1099/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1100/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1101/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1102/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1103/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1104/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1105/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1106/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1107/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1108/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1109/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1110/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1111/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1112/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1113/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1114/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1115/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1116/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1117/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1118/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1119/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1120/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1121/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1122/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1123/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1124/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7241 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1125/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7241 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1126/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1127/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1128/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1129/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1130/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1131/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1132/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1133/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1134/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7241 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1135/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7217 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1136/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1137/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1138/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1139/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7241 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1140/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1141/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1142/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1143/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1144/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7241 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1145/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1146/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1147/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1148/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7241 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1149/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1150/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7241 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1151/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7241 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1152/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1153/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1154/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1155/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1156/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1157/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1158/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1159/1536\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1160/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1161/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1162/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1163/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1164/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1165/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1166/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 1167/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1168/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1169/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1170/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1171/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1172/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1173/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1174/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1175/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1176/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1177/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1178/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.7204 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1179/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7229 - val_loss: 0.5616 - val_accuracy: 0.6733\n",
            "Epoch 1180/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1181/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1182/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1183/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1184/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1185/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1186/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1187/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1188/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1189/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1190/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1191/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1192/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1193/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1194/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7241 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1195/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1196/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1197/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5613 - val_accuracy: 0.6733\n",
            "Epoch 1198/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1199/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1200/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1201/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1202/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7241 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1203/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1204/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1205/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1206/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1207/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1208/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1209/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1210/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1211/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1212/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1213/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1214/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1215/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1216/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1217/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7217 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1218/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1219/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1220/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1221/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1222/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1223/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1224/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1225/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1226/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1227/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1228/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1229/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1230/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1231/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1232/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1233/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1234/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1235/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1236/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1237/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1238/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1239/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1240/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1241/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1242/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1243/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1244/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1245/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1246/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1247/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1248/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1249/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5615 - val_accuracy: 0.6733\n",
            "Epoch 1250/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1251/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1252/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1253/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1254/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7229 - val_loss: 0.5614 - val_accuracy: 0.6733\n",
            "Epoch 1255/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1256/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1257/1536\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1258/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1259/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1260/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1261/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1262/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1263/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1264/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1265/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1266/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1267/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1268/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1269/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1270/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1271/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1272/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1273/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1274/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1275/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1276/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1277/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1278/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1279/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1280/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1281/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1282/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1283/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1284/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1285/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1286/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1287/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1288/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1289/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7155 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1290/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7167 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1291/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1292/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1293/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1294/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1295/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1296/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1297/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1298/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1299/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1300/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1301/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1302/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1303/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1304/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1305/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1306/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1307/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1308/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1309/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1310/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1311/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1312/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1313/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1314/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1315/1536\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1316/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1317/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1318/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1319/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1320/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1321/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1322/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1323/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1324/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1325/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1326/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1327/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1328/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1329/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1330/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1331/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1332/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1333/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1334/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1335/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1336/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1337/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1338/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1339/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1340/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1341/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1342/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1343/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1344/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1345/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1346/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1347/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1348/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1349/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1350/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1351/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1352/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7167 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1353/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1354/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1355/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1356/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7143 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1357/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1358/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1359/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1360/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1361/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1362/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1363/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1364/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1365/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1366/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1367/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1368/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1369/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1370/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1371/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1372/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1373/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1374/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1375/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1376/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1377/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1378/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1379/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1380/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1381/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1382/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1383/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1384/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1385/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 1386/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5612 - val_accuracy: 0.6683\n",
            "Epoch 1387/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1388/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1389/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1390/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1391/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1392/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1393/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1394/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1395/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1396/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1397/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1398/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1399/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1400/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1401/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1402/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1403/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1404/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1405/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1406/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1407/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1408/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1409/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1410/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1411/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1412/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1413/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1414/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1415/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1416/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1417/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1418/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1419/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1420/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1421/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1422/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1423/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1424/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1425/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1426/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1427/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1428/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1429/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1430/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1431/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1432/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1433/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1434/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1435/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1436/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1437/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1438/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1439/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1440/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1441/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1442/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1443/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1444/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1445/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1446/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1447/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1448/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1449/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1450/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1451/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1452/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1453/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1454/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1455/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1456/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1457/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1458/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1459/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1460/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1461/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1462/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1463/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1464/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1465/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1466/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1467/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1468/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1469/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1470/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1471/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1472/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1473/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1474/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1475/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1476/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1477/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1478/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1479/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1480/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1481/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1482/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1483/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1484/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1485/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1486/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1487/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1488/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1489/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1490/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1491/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1492/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1493/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1494/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1495/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1496/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1497/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1498/1536\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1499/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1500/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1501/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1502/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1503/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1504/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5619 - val_accuracy: 0.6683\n",
            "Epoch 1505/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1506/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1507/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5618 - val_accuracy: 0.6683\n",
            "Epoch 1508/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1509/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1510/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1511/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1512/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1513/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1514/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1515/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5617 - val_accuracy: 0.6683\n",
            "Epoch 1516/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1517/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1518/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1519/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1520/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1521/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1522/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1523/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1524/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1525/1536\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1526/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7217 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1527/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1528/1536\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1529/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7192 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1530/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1531/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1532/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5613 - val_accuracy: 0.6683\n",
            "Epoch 1533/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7204 - val_loss: 0.5614 - val_accuracy: 0.6683\n",
            "Epoch 1534/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n",
            "Epoch 1535/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5616 - val_accuracy: 0.6683\n",
            "Epoch 1536/1536\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7180 - val_loss: 0.5615 - val_accuracy: 0.6683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.params)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "P0tDQE5ZLc43",
        "outputId": "d6ca18fb-7753-4f63-d0d8-0724810be4b8"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 1536, 'steps': 26}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAADQCAYAAACpz8JCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXQc1ZX48e/tTa199yqDbbDxhvEijMExmN2QYJYEzBKCkxBOmBBImPCLSRjsMD9+h2QIIcwYCGtIhkDAYAIJYJbYhB0veN+xDZZXSbYkW7u63++PV5LasiS3pK5uS7qfc+qo69Wrqlul7tuvX1W/FmMMSiml3OVJdABKKdUbaLJVSqk40GSrlFJxoMlWKaXiQJOtUkrFgSZbpZSKA1+iA4iVvLw8M3jw4ESHoZTqYZYtW1ZijMnv6nZ6TLIdPHgwS5cuTXQYSqkeRkS+jMV2tBtBKaXiQJOtUkrFgSZbpZSKgx7TZ6vUsaK+vp6ioiJqamoSHYrqgGAwSEFBAX6/35Xt995ku/zPULwBLrw30ZGoHqaoqIj09HQGDx6MiCQ6HBUFYwylpaUUFRUxZMgQV/bRe7sRdi6FVX9NdBSqB6qpqSE3N1cTbTciIuTm5rr6aaTXJtsdNcmEqw6ADjGpXKCJtvtx+3/Wa5PtylLBYxqgtiLRoSgVU2VlZTz88MOdWvfiiy+mrKys3Tp3330377zzTqe2354//vGP3HLLLe3WWbx4MR999FHM9x0PriZbEZkuIhtFZIuIzG5l+e9EZIUzbRKRsohlN4jIZme6IdaxNSRl2wdV+2O9aaUSqr1k29DQ0O66r7/+OllZWe3WueeeezjvvPM6HV9XaLJthYh4gXnARcAo4BoRGRVZxxjzU2PMOGPMOOC/gZeddXOAOcBpwCRgjohkxzI+k5xj/2qyVT3M7Nmz+eKLLxg3bhx33HEHixcvZurUqcyYMYNRo+xL8LLLLmPixImMHj2axx57rGndwYMHU1JSwvbt2xk5ciQ/+MEPGD16NBdccAHV1dUAzJo1i/nz5zfVnzNnDhMmTODkk09mw4YNABQXF3P++eczevRobrzxRo4//nhKSkqOiPXpp59m+PDhTJo0iQ8//LCp/LXXXuO0005j/PjxnHfeeezdu5ft27fz6KOP8rvf/Y5x48bx/vvvt1rvWOXm3QiTgC3GmK0AIvI8cCmwro3612ATLMCFwNvGmP3Oum8D04HnYhZdik22tRUlBGO2UaUO96vX1rJuV2y7qkYNyGDOJaPbXH7fffexZs0aVqxYAdjW4PLly1mzZk3TlfannnqKnJwcqqurOfXUU/nmN79Jbm7uYdvZvHkzzz33HI8//jhXXXUVL730Et/+9reP2F9eXh7Lly/n4Ycf5v777+eJJ57gV7/6Feeccw533nknb775Jk8++eQR6+3evZs5c+awbNkyMjMzOfvssxk/fjwAX/va1/jkk08QEZ544gl+85vf8Nvf/pYf/vCHpKWl8bOf/QyAAwcOtFrvWORmsh0I7IiYL8K2VI8gIscDQ4B/trPuwFgG52lMtoeKNdmqHm/SpEmH3dL00EMPsWDBAgB27NjB5s2bj0i2Q4YMYdy4cQBMnDiR7du3t7rtK664oqnOyy+/DMAHH3zQtP3p06eTnX3kB9NPP/2UadOmkZ9vx3iZOXMmmzZtAuztczNnzmT37t3U1dW1eTtWtPWOBcfKfbZXA/ONMaGOrCQiNwE3ARx33HEd2qEvzT6xGg6Wdmg9pTqivRZoPKWmpjY9Xrx4Me+88w4ff/wxKSkpTJs2rdVbnpKSkpoee73epm6Etup5vd6j9glH68c//jG33347M2bMYPHixcydO7dL9Y4Fbl4g2wkMipgvcMpaczWHdxFEta4x5jFjTKExprDx3TFa/rQcwkYIVWqyVT1Leno6Bw8ebHN5eXk52dnZpKSksGHDBj755JOYxzBlyhReeOEFAN566y0OHDhwRJ3TTjuN9957j9LSUurr63nxxRcPi3HgQPth9plnnmkqb3lsbdU7FrmZbJcAw0RkiIgEsAn11ZaVRGQEkA18HFG8ELhARLKdC2MXOGUxkxZMooIUwpV6gUz1LLm5uUyZMoUxY8Zwxx13HLF8+vTpNDQ0MHLkSGbPns3kyZNjHsOcOXN46623GDNmDC+++CL9+vUjPT39sDr9+/dn7ty5nH766UyZMoWRI0c2LZs7dy5XXnklEydOJC8vr6n8kksuYcGCBU0XyNqqdywS4+JN/SJyMfAg4AWeMsbcKyL3AEuNMa86deYCQWPM7Bbrfg/4hTN7rzHm6fb2VVhYaDoynu3KHWVkPD6J5MGF9PveX6JeT6mjWb9+/WGJozeqra3F6/Xi8/n4+OOPufnmm5su2B3LWvvficgyY0xhV7ftap+tMeZ14PUWZXe3mJ/bxrpPAU+5FVtqko8y0kmtPvLjjVKqa7766iuuuuoqwuEwgUCAxx9/PNEhJdyxcoEs7tKSfHxl0ji+VpOtUrE2bNgwPv/880SHcUzptV/XTU3ycoB0/JpslVJx0HuTbcBHsckkuW6/DkajlHJdr022Ho9Q7snGZ+qgpjzR4Silerhem2wBDvqdb8wc2pfYQJRSPV6vTrZVTcn22B28Qql4SEtLA2DXrl1861vfarXOtGnTONrtlQ8++CBVVVVN89EM2dgZjfG2pSvDTLqlVyfbmiTnJmhNtkoBMGDAgKYRvTqjZbKNZshGN2iyPcaEUpxkW1mc2ECUiqHZs2czb968pvm5c+dy//33c+jQIc4999ym4RD/9re/HbHu9u3bGTNmDADV1dVcffXVjBw5kssvv/ywsRFuvvlmCgsLGT16NHPm2MH6HnroIXbt2sXZZ5/N2WefDTQP2QjwwAMPMGbMGMaMGcODDz7YtL+2hnKMtG3bNk4//XROPvlk7rrrrqbyto6p5TCT0Ry723rtfbYA3pRs6vHh15atcssbs2HP6thus9/JcNF9bS6eOXMmP/nJT/jRj34EwAsvvMDChQsJBoMsWLCAjIwMSkpKmDx5MjNmzGjz52AeeeQRUlJSWL9+PatWrWLChAlNy+69915ycnIIhUKce+65rFq1iltvvZUHHniARYsWHfHV2WXLlvH000/z6aefYozhtNNO46yzziI7OzuqoRxvu+02br75Zr7zne8c9kbS1jG1HGayoaGhQ8fuhl7dsk1PTmI/mXqBTPUo48ePZ9++fezatYuVK1eSnZ3NoEGDMMbwi1/8grFjx3Leeeexc+fOdgfb/te//tWU9MaOHcvYsWOblr3wwgtMmDCB8ePHs3btWtata2uYauuDDz7g8ssvJzU1lbS0NK644gref/99ILqhHD/88EOuueYaAK6//vqm8miPqaPH7oZe3bLNTPGz12TRt2JXokNRPVU7LVA3XXnllcyfP589e/Ywc+ZMAJ599lmKi4tZtmwZfr+fwYMHd+rXZLdt28b999/PkiVLyM7OZtasWV36Vdpoh3JsrRUa7THF6ti7ole3bDOCPorCuYTLixIdilIxNXPmTJ5//nnmz5/PlVdeCdjhCPv06YPf72fRokV8+eWX7W7jzDPP5C9/sYM0rVmzhlWrVgFQUVFBamoqmZmZ7N27lzfeeKNpnbaGd5w6dSqvvPIKVVVVVFZWsmDBAqZOnRr18UyZMoXnn38esImzUVvH1NpQjB05djf06pZtRrKfnSYPKV9tv0WmPz+teojRo0dz8OBBBg4cSP/+/QG47rrruOSSSzj55JMpLCxkxIgR7W7j5ptv5rvf/S4jR45k5MiRTJw4EYBTTjmF8ePHM2LECAYNGsSUKVOa1rnpppuYPn06AwYMYNGiRU3lEyZMYNasWUyaNAmAG2+8kfHjx7f56w8t/f73v+faa6/l17/+NZdeemlTeVvHFDnM5EUXXcTPf/7zDh27G1wdYjGeOjrEIsDfVuzk8xfvY67/T3DHF5B6bI+HqboHHWKx+3JziMVe3o1gW7YAlH2V2GCUUj1a7062yX52NSbb8h3tV1ZKqS7o1ck2M9lHUVOy1YtkSin39OpkmxH0U04q9d4UKNOWrYqdnnItpDdx+3/Wu5Ntsh8QKpL6azeCiplgMEhpaakm3G7EGENpaSnBYNC1ffTqW7+Cfi8Bn4cDgb7k6gUyFSMFBQUUFRVRXKxjbnQnwWCQgoIC17bfq5Mt2K6Efd5+nHjgHb3XVsWE3+9nyJAhiQ5DHWN6dTcCOBfJPAOhtkLHSFBKuabXJ9uslABfhO03bCjdnNhglFI9Vq9PttkpATbU9bEzpVsSG4xSqsdyNdmKyHQR2SgiW0Rkdht1rhKRdSKyVkT+ElEeEpEVzvSqWzHmpgbYWJMJviCUaMtWKeUO1y6QiYgXmAecDxQBS0TkVWPMuog6w4A7gSnGmAMi0idiE9XGmHFuxdcoOzVAaVUDpuAEpGST27tTSvVSbrZsJwFbjDFbjTF1wPPApS3q/ACYZ4w5AGCMifsVqtzUAPUhQ0PeKNizJt67V0r1Em4m24FA5DcFipyySMOB4SLyoYh8IiLTI5YFRWSpU35ZazsQkZucOks7e09jdmoAgENZo+DgLqgs6dR2lFKqPYm+QOYDhgHTgGuAx0Wk8ac4j3eGNbsWeFBETmi5sjHmMWNMoTGmMD8/v1MB5DrJtiT9JFuwZ1WntqOUUu1xM9nuBAZFzBc4ZZGKgFeNMfXGmG3AJmzyxRiz0/m7FVgMjHcjyMaW7e5kJ5fH+sf5lFIKd5PtEmCYiAwRkQBwNdDyroJXsK1aRCQP262wVUSyRSQponwK0P4vynVSY8t2b30qZBRoslVKucK1uxGMMQ0icguwEPACTxlj1orIPcBSY8yrzrILRGQdEALuMMaUisgZwB9EJIx9Q7gv8i6GWGps2R6oqrM/Ea3JVinlAlfHRjDGvA683qLs7ojHBrjdmSLrfASc7GZsjVIDXgJeD6WVddB/LGxeCPXV4E+Ox+6VUr1Eoi+QJZyIkJMa4ECl07I1YdjnSiNaKdWL9fpkC5CTGqD0UB30d75DUdSxH45USqmj0WQL9MlIYt/BWsgaBJmD4MuPEh2SUqqH0WQL9ElPYt/BGjtz/Bk22eoo+0qpGNJkC/RJD1J8sJZQ2NhkW7kPSr9IdFhKqR5Eky3QNyOJsIHSylo4foot/PLDxAallOpRNNkC+en2R972VdRC7omQmq/9tkqpmNJki23ZArbfVqS531YppWJEky3QJyOiZQu2K6H8K9Bf3FVKxYgmWyA/zbZs9zYl2zPsX23dKqViRJMtEPB5yEkNNN/+1WcUJOfAF/9MbGBKqR5Dk62jT3pSc8vW44VhF8DmtyAcSmxgSqkeQZOto09GkOLGli3A8Auh+gAULUlcUEqpHkOTraNfRhK7yiOS7YnngscHG99IXFBKqR5Dk62jIDuF4oO11NQ73QbBTHuhbNPCxAamlOoRNNk6CrLt+LW7yqqbC4dPh+L1cGB7YoJSSvUYmmwdA7Nssi06EJFsT7rI/l3X8td8lFKqYzTZOgpyUoAWyTZnKAyYAKtfTFBUSqmeQpOto296Ej6PUHSg6vAFJ19pf968eGNiAlNK9QiabB0+r4f+WUF2RvbZAoy5AhBYPT8hcSmlegZNthEGZiUf3o0AkN4PhpxpuxJ0QHGlVCdpso1QkJ1yZDcCwLhr4cA22Pav+AellOoRokq2InKbiGSI9aSILBeRC9wOLt4KspPZW1FLbUOLr+iOugySs2Hpk4kJTCnV7UXbsv2eMaYCuADIBq4H7nMtqgQpyLZ3JOwqqzl8gT8I466DDf+Ag3sSEJlSqruLNtmK8/di4M/GmLURZW2vJDJdRDaKyBYRmd1GnatEZJ2IrBWRv0SU3yAim53phijj7JLBuTbZbi+pPHJh4fcg3ADL/xyPUJRSPUy0yXaZiLyFTbYLRSQdCLe3goh4gXnARcAo4BoRGdWizjDgTmCKMWY08BOnPAeYA5wGTALmiEh21EfVSUPyUgH4ovjQkQtzT4Ch02DZH3UkMKVUh0WbbL8PzAZONcZUAX7gu0dZZxKwxRiz1RhTBzwPXNqizg+AecaYAwDGmH1O+YXA28aY/c6yt4HpUcbaaTmpATKT/WxtrWULtnVbUWS7E5RSqgOiTbanAxuNMWUi8m3gLqD8KOsMBHZEzBc5ZZGGA8NF5EMR+UREpndgXUTkJhFZKiJLi4uLozyUtokIQ/NT2dpayxbgpK/bb5W9f7/eBqaU6pBok+0jQJWInAL8O/AF8KcY7N8HDAOmAdcAj4tIVrQrG2MeM8YUGmMK8/PzYxAODM1LY1tbLVuvD752O+xeCZvfjsn+lFK9Q7TJtsEYY7DdAP9jjJkHpB9lnZ3AoIj5AqcsUhHwqjGm3hizDdiETb7RrOuKofmp7K2o5VBtQ+sVxs6ErONg0b3aulVKRS3aZHtQRO7E3vL1DxHxYPtt27MEGCYiQ0QkAFwNtBw+6xVsqxYRycN2K2wFFgIXiEi2c2HsAqfMdUOdi2Tbitto3foCcNZs2L0C1r0Sj5CUUj1AtMl2JlCLvd92D7al+V/trWCMaQBuwSbJ9cALxpi1InKPiMxwqi0ESkVkHbAIuMMYU2qM2Q/8JzZhLwHuccpcNzQ/DYCtJW3024Jt3fYZDQvvgro2krJSSkUQE+VHYRHpC5zqzH4WcefAMaGwsNAsXbq0y9upqQ8x8u43ufWcYfz0/OFtV/zyI3j6ItuHe96cLu9XKXVsEpFlxpjCrm4n2q/rXgV8BlwJXAV8KiLf6urOj0VBv5eC7OTW77WNdPwZMPZq+Oi/Yc/q+ASnlOq2ou1G+CX2HtsbjDHfwd5D+x/uhZVYJ/VNZ+Oeg0eveOH/g5QceOlGqK8+en2lVK8VbbL1tOg2KO3Aut3OiH4ZbC2pPHJAmpZSc+GyR6B4A7zVY997lFIxEG3CfFNEForILBGZBfwDeN29sBJrRP90QmHDln1H6UoA+5Pnk38ESx6Hz//X/eCUUt1SVMnWGHMH8Bgw1pkeM8b83M3AEmlEvwwANuyOoisB4PxfwdCz4bXbdMxbpVSrou4KMMa8ZIy53ZkWuBlUog3OTSHg87BhT0V0K3j9cNUzkHMCvHADlH7hboBKqW6n3WQrIgdFpKKV6aCIRJmJuh+f18PwvmlsiOYiWaNgJlzzHIjYW8L2rnMvQKVUt9NusjXGpBtjMlqZ0o0xGfEKMhFG9MtgfbTdCI1yT4BZr4N44I8Xw87l7gSnlOp2euwdBV01ekAGJYdq2VNec/TKkfqMgO++AUnp8MwlOmCNUgrQZNumUwbZwcdW7Cjr+Mo5Q+B7CyF7CDx7Jbx1F4TaGNhGKdUraLJtw6j+Gfi90rlkC5AxAL7/Fky43n7L7PFpsP2DmMaolOo+NNm2Iej3MrJ/Bis7m2wBAilwyUNw5R+hugz++HV4/joo3hizOJVS3YMm23acUpDF6p3lhMJdGLdWBEZfDrcsgbPvgq3vwcOTYf73Ye/a2AWrlDqmabJtxymDsjhU23D0QWmi4U+Gs+6AW5fDGT+GTW/CI2fAkxfA+7+1dy7oYORK9ViabNsxblAm0MmLZG1J6wPn3wM/XQPn/AfUV8G798DjZ8NvR9hBbZb/CfZv0+SrVA/iS3QAx7KheWmkJ/n4/KsyriocdPQVOiI5G878mZ0qS2DTQtjyDmxdDKtftHWCmTB4KhScCrkn2otuqfmQ3t/+HppSqtvQV2w7PB5hwvHZLNnu8o9EpObB+OvsZIy9gLb9fShaYqcNfz+8vnggbzjkn2RvL8s/yc4nZ0MwyyZpTcZKHVP0FXkUk4fm8us3N1B8sJb89CT3dyhivxjRZwRM+oEtK/sKKouhYjdUlcCB7bBvPexaAetfAxM+cjtJmZCcZRNw019nSsmFtL7gDdjEnN4P6g5BIB0yB9qE7wtqwlYqhvTVdBSTh+YA8Nm2/Xx9bP/EBJF1nJ0GtrIsHIY9q+DQPqg+ADVl9m/T5MyX72xeHo7yCxbBLAik2Yt7IuBLsoOkp/UDfxDEa78pF0iBuipbL2OATehJzre56yqhocZ2f/gCdh1fkp0APD5oqLX78SXZ+bpD9o3A47PbT852jjUEGFvmT24+fhr7tqX52ETs+o3r1FXafUS+gYTDUFvhHJ8XPF5bbgyE6mw8Ina+vtr2r1ftt29eSRlOfbF/RQ4/dw21dptg9xmqt+vXVULtIbtPf4pd5g3Yeo0D0DfUgMfffIy+oI3TG4BDe+0nG4/X/m8BTMgeWzgE9ZV2v+EGu8/kLKgpt4MleQNOnSp7TUA89o03kGKPJ5Bq33zrq2z8jVOozvm05G8+5poyexyBFOfcpkJ9DYTr7XYjp/rq5v+HxzkXB/eAx2PjTs6BzALn+VVlt5uUbv9vJmzrG2OfF43nqPH/Yk9A8/+tvtpZz0D1frv9zIHOOfPb85KcZV9PcabJ9ijGDMwkJeDlk62liUu27fF4YMC46OsbY5PuoX32RXRwj30hh0N2vnyHfWKG6m15XaV9AZiwTaiBVLtO1X77wtq5GzDgTbJP5MpimpOfS8RrX/ihOhuXeCNa90fZtzfJSV7lRy7zBe12wg3Odj1Ocqg7ekz+VHs+GutHvqH5gs2xdobHb7etYmPqv8O5d8d9t5psj8Lv9VA4OIdPtpYmOpTYELE/5ZNiW+z0Hxvb7YfqofagTcYej20xheqgpgIaqm2ya6ixZdVlNjkFM+w6oTqnJQpgmltVNeWHt5Iqi20Vb4Cm1o8xttXlT25u8dSUOy0kcVpeVU7rqMapF7LdKQ01dp2a8uaWWyC1+ZeTRWxc6f1tC7223NY1Yds6riiyCdGXZGP0BmyLzzgtrNoKe5yp+c2tyVCdPZZQrdNyCzufHpLtp4ZQg12vsUWX1scm8GCm3QbYx+B8GqiysYdD9o3IF7Tnpr7KdimFG+w+PU5LOmeI3V9lCVTsstupr7bH1djqbvwE4vHa/0841Nxi9vrtuas+YPfjCzavY8KHT96APacmZNf1+GzXVajerl9bYWNoqHWeD5m25dz0icPX/L/1pzT/T+yDw/9HXr89hxh7nmvKobzInsNQnf2U1HdMbJ/zUdJkG4XJQ3P4zZsbKTlUS15aHPptuzOv//Bk3ihjQGLiUe3LGZroCNw3cEKiIwD0PtuoTB6aC8BHX/SQ1q1SKu402UbhlIIsslL8LN6w7+iVlVKqFa4mWxGZLiIbRWSLiMxuZfksESkWkRXOdGPEslBE+atuxnk0Xo9w1vB8Fm8qJtyVcRKUUr2Wa8lWRLzAPOAiYBRwjYiMaqXqX40x45zpiYjy6ojyGW7FGa1zRvRhf2UdK4ti+NVdpVSv4WbLdhKwxRiz1RhTBzwPXOri/lx15rB8PAKLtCtBKdUJbibbgcCOiPkiWr8t/5siskpE5otI5AAEQRFZKiKfiMhlre1ARG5y6iwtLi6OYehHyk4NMP64bP65UZOtUqrjEn2B7DVgsDFmLPA28EzEsuONMYXAtcCDInJCy5WNMY8ZYwqNMYX5+fmuB3veyL6s2VnBjv1Vru9LKdWzuJlsdwKRLdUCp6yJMabUGFPrzD4BTIxYttP5uxVYDIx3MdaofMP5BtnfV+1OcCRKqe7GzWS7BBgmIkNEJABcDRx2V4GIRH7/dQaw3inPFpEk53EeMAVY52KsURmUk8Ipg7L4+6pdiQ5FKdXNuJZsjTENwC3AQmwSfcEYs1ZE7hGRxrsLbhWRtSKyErgVmOWUjwSWOuWLgPuMMQlPtgCXjO3P2l0VbI3FrzcopXoNMT3k1wAKCwvN0qVLXd/PnvIaTr/vXX563nBuPXeY6/tTSiWWiCxzrh91SaIvkHU7/TKDnDo4hwWf76SnvFEppdynybYTZhYOYltJJZ9sdfkXHJRSPYYm2074+tj+ZAR9/OWzrxIdilKqm9Bk2wlBv5crJhTw5prdlB6qPfoKSqleT5NtJ1172nHUhwwvLS9KdChKqW5Ak20nDe+bzqTBOTzz0ZfUNXTy506UUr2GJtsu+NE5J7KzrJr5y7R1q5RqnybbLjhzWB7jj8ti3qIt2rpVSrVLk20XiAg/OW+4tm6VUkelybaLtHWrlIqGJtsu0tatUioammxjoLF1+9C7mzlU25DocJRSxyBNtjEgIvzHN0ax92AN9y/cmOhwlFLHIE22MTLhuGy+M/l4nvl4Oyt26I9CKqUOp8k2hn524Un0TQ8y+6VV1If0YplSqpkm2xhKD/r5z8vGsGHPQf7nn1sSHY5S6hiiyTbGzh/VlyvGD+Shf27mX5vc/cVfpVT3ocnWBfdefjIn9U3ntuc/p+iA/hKvUkqTrSuSA14e+fZEGkKGf3t2OdV1oUSHpJRKME22LhmSl8oDM8exemc5P35uOQ16wUypXk2TrYvOH9WXey4dwzvr93Hr859TU68tXKV6K1+iA+jprp98PLX1If7vP9ZTcugzHr++kMwUf6LDUkrFmbZs4+DGqUN56JrxrPiqjG8++hE7y6oTHZJSKs5cTbYiMl1ENorIFhGZ3cryWSJSLCIrnOnGiGU3iMhmZ7rBzTjjYcYpA3jme5PYW1HD5fM+ZHVReaJDUkrFkWvJVkS8wDzgImAUcI2IjGql6l+NMeOc6Qln3RxgDnAaMAmYIyLZbsUaL6efkMv8H56B1yNc/vCHPPDWRh2WUalews2W7SRgizFmqzGmDngeuDTKdS8E3jbG7DfGHADeBqa7FGdcndQvnTdum8qMcQN46J9buOS/P2BVkY6loFRP52ayHQjsiJgvcspa+qaIrBKR+SIyqIPrdktZKQEeuGocT95QSFl1HZfO+5A7XlzJ3oqaRIemlHJJoi+QvQYMNsaMxbZen+nIyiJyk4gsFZGlxcXd76ux547sy1s/PYsfTB3K31bs4szfLOJnL67Ulq5SPZCbyXYnMChivsApa2KMKTXG1DqzTwATo13XWf8xY0yhMaYwPz8/ZoHHU2ayn19cPJJ3bj+Lb04s4PXVu5nxPx9y6bwPeWlZkd6bq1QPIcYYdzYs4gM2AediE+US4FpjzNqIOv2NMbudx5cDPzfGTHYukC0DJjhVlwMTjTH72zOPQZoAAAsBSURBVNpfYWGhWbp0qSvHEk8VNfW8vKyIP3/yJV8UV5Kd4ufKwkF8/eT+jC3IREQSHaJSvYqILDPGFHZ1O659qcEY0yAitwALAS/wlDFmrYjcAyw1xrwK3CoiM4AGYD8wy1l3v4j8JzZBA9zTXqLtSTKCfmZNGcINZwzm4y9K+dPHX/LUB9t47F9b6ZuRxJnD8pk6PJ8pJ+SSm5aU6HCVUlFyrWUbbz2lZduasqo63l2/j3c37OWDzSVU1NjfORs9IIPThuQy7rgsTinIZFB2Ch6PtnyViqVYtWw12XYzobBh9c5yPthczPubS1hZVEZNvb1XNz3Jx+iBGYzol8GJfdIYmpfKkPxU+qYHNQkr1UmabFvoLcm2pfpQmI17DrJ6Zzlrd5WzemcFm/cepCpiWMeg38Og7BT6ZQbpmxGkb0aS89dO/TKC5KUF8HkTfXOKUseeY77PVsWH3+thzMBMxgzMbCoLhw27K2rYXlLJNmfasb+KvQdr2bKvhH0HawmFD3+TFYG8tCT6tUjGeWlJZCb7yU0LkJMaIDPZT3rQR7LfqxfrlOoATbY9kMcjDMxKZmBWMlNOzDtieShsKK2sZV9FLXsrathTUcPeilr2OY93ltXw+VdllFbWtbkPEUgN+EhN8jp/7eO0JB8pznxakpeUgI+g30vQ7yHo95Ls9xL0e0nyeewU8djn9eD3CgGvB7/Xg99n5/0ej3aDqG5Pk20v5PUIfdKD9EkPHtYibqm2IcT+yjrKq+spOVhHWbV9fKimgcraBg7VhuzfugaqahuorA2xq6yGyjr7uLK2geoY3Sfs9UhTIvZ5PXjElglCkt9DwOvBI4IIiAgeAY/zl4h5gYh6jXUOX6+5jjh1aFGncTtHqweC87epzpHzjftrNVaPsz2kje1DQ9gctt1GxhhCBgLeo7xRtfMJxSuCwRDZ29gYjwiEjcHrxNRdjOyfwdiCrLjvV5OtalOSz0v/zGT6ZyZDv85tIxQ21DWEqakPUdMQorouRFVdiLpQmNr6MLUNIWrqw9SHwjSEw9Q3GOpCYRpCYepD9nF902S31RAOU9dg5/1eobbBzoeNTQphYxONwSaDpnlDRB1DOAwhwoQjyk1jfezysJNlGrcTNgZMxHadekfur3FbTnnY2X5Tncb90VzHHJ7UlDt+dPYJmmxVz+P1CMkBL8kBb6JD6TZMRGJv+QbRlJTDzfNej0S8AZjDWrdeEepC4TZbnu0l98Y3EnFa0AjgvGEY543GI3JE//+xLjUpMWlPk61SxxgRwSvgpRt9NldHpff6KKVUHGiyVUqpONBkq5RScaDJViml4kCTrVJKxUGPGRtBRIqBLzu4Wh5Q4kI4GoPGoDF0/xjAxpFqjOnyrxP0mGTbGSKyNBYDTGgMGoPG0PNiiHUc2o2glFJxoMlWKaXioLcn28cSHQAaQyONwdIYrGMhBohhHL26z1YppeKlt7dslVIqLnptshWR6SKyUUS2iMhsl/YxSEQWicg6EVkrIrc55Tki8raIbHb+ZjvlIiIPOTGtEpEJ7e+hQ7F4ReRzEfm7Mz9ERD519vVXEQk45UnO/BZn+eAYxpAlIvNFZIOIrBeR0+N9LkTkp87/Yo2IPCciQbfPhYg8JSL7RGRNRFmHj1tEbnDqbxaRG2IQw385/4tVIrJARLIilt3pxLBRRC6MKO/066a1GCKW/buIGBHJi/d5cMp/7JyLtSLyG1fOgx3ns3dN2J9W/wIYCgSAlcAoF/bTH5jgPE4HNgGjgN8As53y2cCvnccXA29gB7ObDHwaw1huB/4C/N2ZfwG42nn8KHCz8/jfgEedx1cDf41hDM8ANzqPA0BWPM8FMBDYBiRHnINZbp8L4ExgArAmoqxDxw3kAFudv9nO4+wuxnAB4HMe/zoihlHOayIJGOK8Vrxdfd20FoNTPghYiL1PPi8B5+Fs4B0gyZnv48Z5iGly6S4TcDqwMGL+TuDOOOz3b8D5wEagv1PWH9joPP4DcE1E/aZ6XdxvAfAucA7wd+cJXBLxQms6H86T/nTnsc+pJzGIIROb6KRFedzOBTbZ7nBeqD7nXFwYj3MBDG7xAu/QcQPXAH+IKD+sXmdiaLHscuDZ1l4PjechFq+b1mIA5gOnANtpTrZxOw/YN9vzWqkX0/PQW7sRGl90jYqcMtc4H0HHA58CfY0xu51Fe4C+Lsf1IPB/gLAznwuUGWMaWtlPUwzO8nKnflcNAYqBp53ujCdEJJU4ngtjzE7gfuArYDf22JYR/3MBHT9ut5+z38O2JOMag4hcCuw0xqxssSie52E4MNXpKnpPRE51I4bemmzjSkTSgJeAnxhjKiKXGfvW6NotISLyDWCfMWaZW/uIkg/78e0RY8x4oBL78blJHM5FNnApNvEPAFKB6W7tL1puH/fRiMgvgQbg2TjvNwX4BXB3PPfbCh/2085k4A7gBZHY/6pab022O7H9RI0KnLKYExE/NtE+a4x52SneKyL9neX9gX0uxjUFmCEi24HnsV0JvweyRKTxlzoi99MUg7M8EyjtYgxg3/2LjDGfOvPzsck3nufiPGCbMabYGFMPvIw9P/E+F9Dx43blOSsis4BvANc5ST+eMZyAfeNb6Tw/C4DlItIvjjGAfW6+bKzPsJ8A82IdQ29NtkuAYc5V6AD24sersd6J8+74JLDeGPNAxKJXgcarqDdg+3Iby7/jXImdDJRHfNTsFGPMncaYAmPMYOxx/tMYcx2wCPhWGzE0xvYtp36XW13GmD3ADhE5ySk6F1hHHM8FtvtgsoikOP+bxhjiei5a2XY0x70QuEBEsp0W+gVOWaeJyHRs99IMY0xVi9iuFns3xhBgGPAZMX7dGGNWG2P6GGMGO8/PIuwF5T3E8TwAr2AvkiEiw7EXvUqI9XnoSMdyT5qwVzs3Ya8q/tKlfXwN+/FwFbDCmS7G9vu9C2zGXgXNceoLMM+JaTVQGON4ptF8N8JQ54mzBXiR5iuxQWd+i7N8aAz3Pw5Y6pyPV7BXk+N6LoBfARuANcCfsVeaXT0XwHPYPuJ6bEL5fmeOG9uvusWZvhuDGLZg+x4bn5uPRtT/pRPDRuCiWLxuWouhxfLtNF8gi+d5CAD/6zwnlgPnuHEe9BtkSikVB721G0EppeJKk61SSsWBJlullIoDTbZKKRUHmmyVUioONNkq1QoRmSbOCGlKxYImW6WUigNNtqpbE5Fvi8hnIrJCRP4gdtzeQyLyO2ds0ndFJN+pO05EPpHm8Vsbx5A9UUTeEZGVIrJcRE5wNp8mzePvPuvG9+VV76HJVnVbIjISmAlMMcaMA0LAddgBZpYaY0YD7wFznFX+BPzcGDMW+62kxvJngXnGmFOAM7DfMAI7SttPsOOaDsWOo6BUp/iOXkWpY9a5wERgidPoTMYO6BIG/urU+V/gZRHJBLKMMe855c8AL4pIOjDQGLMAwBhTA+Bs7zNjTJEzvwI7DuoH7h+W6ok02aruTIBnjDF3HlYo8h8t6nX2O+m1EY9D6OtFdYF2I6ju7F3gWyLSB5p+1+t47PO6cRSva4EPjDHlwAERmeqUXw+8Z4w5CBSJyGXONpKccVaViil9p1bdljFmnYjcBbwlIh7sSE4/wg5MPslZtg/brwt2KMNHnWS6FfiuU3498AcRucfZxpVxPAzVS+ioX6rHEZFDxpi0RMehVCTtRlBKqTjQlq1SSsWBtmyVUioONNkqpVQcaLJVSqk40GSrlFJxoMlWKaXiQJOtUkrFwf8H1P4yL6TJr+gAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the train set\n",
        "P1 = model1.predict(XTRAIN)\n",
        "accuracy = model1.evaluate(XTRAIN, YTRAIN)\n",
        "my_f1 = f1_score(YTRAIN, P1.round())\n",
        "my_precision = precision_score(YTRAIN, P1.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GABMoL7O5p3q",
        "outputId": "c5ba66d7-b17e-4b59-95f7-1031100d4b52"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7180\n",
            "f1:  0.7693856998992951\n",
            "precision:  0.7579365079365079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the validation set\n",
        "P1 = model1.predict(XVALID)\n",
        "accuracy = model1.evaluate(XVALID, YVALID)\n",
        "my_f1 = f1_score(YVALID, P1.round())\n",
        "my_precision = precision_score(YVALID, P1.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkFWadl57Pq-",
        "outputId": "3598c55e-f4cc-4483-a22b-1268ff256b65"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.6683\n",
            "f1:  0.7413127413127413\n",
            "precision:  0.6857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2= Sequential() # multi-layer network\n",
        "model2.add(Dense(16, input_dim= len(XTRAIN[0,:]), activation = 'relu' ))\n",
        "model2.add(Dense(8, activation = 'relu' ))\n",
        "model2.add(Dense(4, activation = 'relu' ))\n",
        "model2.add(Dense(2, activation = 'relu' ))\n",
        "model2.add(Dense(1, activation = 'sigmoid')) \n",
        "model2.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics='accuracy' )\n",
        "# activation and optimizer are changing in order to find highest validation accuracy"
      ],
      "metadata": {
        "id": "ZRGO4-KM58ki"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(x= XTRAIN, y=YTRAIN, validation_data = (XVALID, YVALID), epochs = 256, verbose = 1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJCKyXxEDGX4",
        "outputId": "a35a0e3a-10f0-4911-8a7b-002d11f04703"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "26/26 [==============================] - 1s 10ms/step - loss: 0.6735 - accuracy: 0.5998 - val_loss: 0.6690 - val_accuracy: 0.5941\n",
            "Epoch 2/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6010 - val_loss: 0.6510 - val_accuracy: 0.5941\n",
            "Epoch 3/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6010 - val_loss: 0.6314 - val_accuracy: 0.5941\n",
            "Epoch 4/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6010 - val_loss: 0.6126 - val_accuracy: 0.5941\n",
            "Epoch 5/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.6059 - val_loss: 0.5980 - val_accuracy: 0.6436\n",
            "Epoch 6/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7032 - val_loss: 0.5846 - val_accuracy: 0.6584\n",
            "Epoch 7/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7167 - val_loss: 0.5714 - val_accuracy: 0.6733\n",
            "Epoch 8/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7057 - val_loss: 0.5587 - val_accuracy: 0.6634\n",
            "Epoch 9/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7241 - val_loss: 0.5471 - val_accuracy: 0.7228\n",
            "Epoch 10/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7549 - val_loss: 0.5385 - val_accuracy: 0.7475\n",
            "Epoch 11/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7660 - val_loss: 0.5317 - val_accuracy: 0.7475\n",
            "Epoch 12/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7648 - val_loss: 0.5264 - val_accuracy: 0.7327\n",
            "Epoch 13/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7833 - val_loss: 0.5228 - val_accuracy: 0.7327\n",
            "Epoch 14/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7808 - val_loss: 0.5183 - val_accuracy: 0.7327\n",
            "Epoch 15/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7796 - val_loss: 0.5179 - val_accuracy: 0.7327\n",
            "Epoch 16/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7759 - val_loss: 0.5147 - val_accuracy: 0.7327\n",
            "Epoch 17/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7808 - val_loss: 0.5154 - val_accuracy: 0.7376\n",
            "Epoch 18/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7746 - val_loss: 0.5167 - val_accuracy: 0.7327\n",
            "Epoch 19/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7327\n",
            "Epoch 20/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7820 - val_loss: 0.5128 - val_accuracy: 0.7376\n",
            "Epoch 21/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7833 - val_loss: 0.5118 - val_accuracy: 0.7376\n",
            "Epoch 22/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7820 - val_loss: 0.5099 - val_accuracy: 0.7376\n",
            "Epoch 23/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7820 - val_loss: 0.5123 - val_accuracy: 0.7376\n",
            "Epoch 24/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7796 - val_loss: 0.5096 - val_accuracy: 0.7327\n",
            "Epoch 25/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7820 - val_loss: 0.5092 - val_accuracy: 0.7327\n",
            "Epoch 26/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7869 - val_loss: 0.5149 - val_accuracy: 0.7277\n",
            "Epoch 27/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7833 - val_loss: 0.5074 - val_accuracy: 0.7426\n",
            "Epoch 28/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7894 - val_loss: 0.5148 - val_accuracy: 0.7277\n",
            "Epoch 29/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7327\n",
            "Epoch 30/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7857 - val_loss: 0.5095 - val_accuracy: 0.7327\n",
            "Epoch 31/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7845 - val_loss: 0.5083 - val_accuracy: 0.7327\n",
            "Epoch 32/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7845 - val_loss: 0.5080 - val_accuracy: 0.7327\n",
            "Epoch 33/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7857 - val_loss: 0.5072 - val_accuracy: 0.7327\n",
            "Epoch 34/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7845 - val_loss: 0.5067 - val_accuracy: 0.7376\n",
            "Epoch 35/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7869 - val_loss: 0.5080 - val_accuracy: 0.7327\n",
            "Epoch 36/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7845 - val_loss: 0.5063 - val_accuracy: 0.7327\n",
            "Epoch 37/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7869 - val_loss: 0.5069 - val_accuracy: 0.7327\n",
            "Epoch 38/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7869 - val_loss: 0.5061 - val_accuracy: 0.7327\n",
            "Epoch 39/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7906 - val_loss: 0.5049 - val_accuracy: 0.7327\n",
            "Epoch 40/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7894 - val_loss: 0.5067 - val_accuracy: 0.7327\n",
            "Epoch 41/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7919 - val_loss: 0.5103 - val_accuracy: 0.7327\n",
            "Epoch 42/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7919 - val_loss: 0.5069 - val_accuracy: 0.7376\n",
            "Epoch 43/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7894 - val_loss: 0.5089 - val_accuracy: 0.7277\n",
            "Epoch 44/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7906 - val_loss: 0.5063 - val_accuracy: 0.7327\n",
            "Epoch 45/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7869 - val_loss: 0.5110 - val_accuracy: 0.7277\n",
            "Epoch 46/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7894 - val_loss: 0.5061 - val_accuracy: 0.7327\n",
            "Epoch 47/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7277\n",
            "Epoch 48/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7894 - val_loss: 0.5076 - val_accuracy: 0.7327\n",
            "Epoch 49/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7327\n",
            "Epoch 50/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7894 - val_loss: 0.5073 - val_accuracy: 0.7376\n",
            "Epoch 51/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7894 - val_loss: 0.5107 - val_accuracy: 0.7277\n",
            "Epoch 52/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7894 - val_loss: 0.5065 - val_accuracy: 0.7327\n",
            "Epoch 53/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7894 - val_loss: 0.5065 - val_accuracy: 0.7327\n",
            "Epoch 54/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7919 - val_loss: 0.5075 - val_accuracy: 0.7673\n",
            "Epoch 55/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7906 - val_loss: 0.5063 - val_accuracy: 0.7327\n",
            "Epoch 56/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7906 - val_loss: 0.5086 - val_accuracy: 0.7376\n",
            "Epoch 57/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.7919 - val_loss: 0.5067 - val_accuracy: 0.7327\n",
            "Epoch 58/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.7894 - val_loss: 0.5080 - val_accuracy: 0.7376\n",
            "Epoch 59/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8017 - val_loss: 0.5068 - val_accuracy: 0.7327\n",
            "Epoch 60/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7869 - val_loss: 0.5065 - val_accuracy: 0.7426\n",
            "Epoch 61/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.7943 - val_loss: 0.5061 - val_accuracy: 0.7376\n",
            "Epoch 62/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.7956 - val_loss: 0.5076 - val_accuracy: 0.7327\n",
            "Epoch 63/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.7894 - val_loss: 0.5096 - val_accuracy: 0.7376\n",
            "Epoch 64/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.7943 - val_loss: 0.5045 - val_accuracy: 0.7574\n",
            "Epoch 65/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.7931 - val_loss: 0.5075 - val_accuracy: 0.7327\n",
            "Epoch 66/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8054 - val_loss: 0.5075 - val_accuracy: 0.7376\n",
            "Epoch 67/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.7943 - val_loss: 0.5066 - val_accuracy: 0.7376\n",
            "Epoch 68/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.7968 - val_loss: 0.5086 - val_accuracy: 0.7376\n",
            "Epoch 69/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.7993 - val_loss: 0.5068 - val_accuracy: 0.7624\n",
            "Epoch 70/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.7956 - val_loss: 0.5096 - val_accuracy: 0.7376\n",
            "Epoch 71/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.7931 - val_loss: 0.5082 - val_accuracy: 0.7376\n",
            "Epoch 72/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8067 - val_loss: 0.5098 - val_accuracy: 0.7376\n",
            "Epoch 73/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.7968 - val_loss: 0.5069 - val_accuracy: 0.7574\n",
            "Epoch 74/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.7993 - val_loss: 0.5077 - val_accuracy: 0.7426\n",
            "Epoch 75/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.7931 - val_loss: 0.5086 - val_accuracy: 0.7376\n",
            "Epoch 76/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.7980 - val_loss: 0.5074 - val_accuracy: 0.7475\n",
            "Epoch 77/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8140 - val_loss: 0.5074 - val_accuracy: 0.7376\n",
            "Epoch 78/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.7993 - val_loss: 0.5072 - val_accuracy: 0.7723\n",
            "Epoch 79/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8177 - val_loss: 0.5175 - val_accuracy: 0.7079\n",
            "Epoch 80/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.7894 - val_loss: 0.5068 - val_accuracy: 0.7624\n",
            "Epoch 81/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8017 - val_loss: 0.5092 - val_accuracy: 0.7525\n",
            "Epoch 82/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8140 - val_loss: 0.5167 - val_accuracy: 0.7079\n",
            "Epoch 83/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.7968 - val_loss: 0.5089 - val_accuracy: 0.7624\n",
            "Epoch 84/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8202 - val_loss: 0.5173 - val_accuracy: 0.7030\n",
            "Epoch 85/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8017 - val_loss: 0.5113 - val_accuracy: 0.7376\n",
            "Epoch 86/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8005 - val_loss: 0.5097 - val_accuracy: 0.7574\n",
            "Epoch 87/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.7993 - val_loss: 0.5093 - val_accuracy: 0.7426\n",
            "Epoch 88/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8116 - val_loss: 0.5124 - val_accuracy: 0.7277\n",
            "Epoch 89/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8079 - val_loss: 0.5088 - val_accuracy: 0.7525\n",
            "Epoch 90/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8128 - val_loss: 0.5154 - val_accuracy: 0.7228\n",
            "Epoch 91/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.7956 - val_loss: 0.5081 - val_accuracy: 0.7475\n",
            "Epoch 92/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5097 - val_accuracy: 0.7426\n",
            "Epoch 93/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8202 - val_loss: 0.5103 - val_accuracy: 0.7376\n",
            "Epoch 94/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.7980 - val_loss: 0.5113 - val_accuracy: 0.7525\n",
            "Epoch 95/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7376\n",
            "Epoch 96/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8202 - val_loss: 0.5134 - val_accuracy: 0.7277\n",
            "Epoch 97/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8017 - val_loss: 0.5140 - val_accuracy: 0.7277\n",
            "Epoch 98/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8005 - val_loss: 0.5101 - val_accuracy: 0.7574\n",
            "Epoch 99/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.7993 - val_loss: 0.5111 - val_accuracy: 0.7426\n",
            "Epoch 100/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8214 - val_loss: 0.5136 - val_accuracy: 0.7277\n",
            "Epoch 101/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.7968 - val_loss: 0.5105 - val_accuracy: 0.7574\n",
            "Epoch 102/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8190 - val_loss: 0.5190 - val_accuracy: 0.7030\n",
            "Epoch 103/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8005 - val_loss: 0.5146 - val_accuracy: 0.7277\n",
            "Epoch 104/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8017 - val_loss: 0.5129 - val_accuracy: 0.7376\n",
            "Epoch 105/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8153 - val_loss: 0.5131 - val_accuracy: 0.7426\n",
            "Epoch 106/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8165 - val_loss: 0.5170 - val_accuracy: 0.7228\n",
            "Epoch 107/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8005 - val_loss: 0.5142 - val_accuracy: 0.7376\n",
            "Epoch 108/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8153 - val_loss: 0.5197 - val_accuracy: 0.7129\n",
            "Epoch 109/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8067 - val_loss: 0.5144 - val_accuracy: 0.7475\n",
            "Epoch 110/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8177 - val_loss: 0.5136 - val_accuracy: 0.7376\n",
            "Epoch 111/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8165 - val_loss: 0.5154 - val_accuracy: 0.7475\n",
            "Epoch 112/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8177 - val_loss: 0.5146 - val_accuracy: 0.7376\n",
            "Epoch 113/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8103 - val_loss: 0.5129 - val_accuracy: 0.7426\n",
            "Epoch 114/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8054 - val_loss: 0.5146 - val_accuracy: 0.7475\n",
            "Epoch 115/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8214 - val_loss: 0.5191 - val_accuracy: 0.7277\n",
            "Epoch 116/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8153 - val_loss: 0.5191 - val_accuracy: 0.7376\n",
            "Epoch 117/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8165 - val_loss: 0.5190 - val_accuracy: 0.7129\n",
            "Epoch 118/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8153 - val_loss: 0.5146 - val_accuracy: 0.7376\n",
            "Epoch 119/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8214 - val_loss: 0.5141 - val_accuracy: 0.7475\n",
            "Epoch 120/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8190 - val_loss: 0.5168 - val_accuracy: 0.7376\n",
            "Epoch 121/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8165 - val_loss: 0.5143 - val_accuracy: 0.7376\n",
            "Epoch 122/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8202 - val_loss: 0.5172 - val_accuracy: 0.7376\n",
            "Epoch 123/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8190 - val_loss: 0.5165 - val_accuracy: 0.7376\n",
            "Epoch 124/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8054 - val_loss: 0.5175 - val_accuracy: 0.7376\n",
            "Epoch 125/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8091 - val_loss: 0.5155 - val_accuracy: 0.7376\n",
            "Epoch 126/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8202 - val_loss: 0.5197 - val_accuracy: 0.7376\n",
            "Epoch 127/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8214 - val_loss: 0.5164 - val_accuracy: 0.7376\n",
            "Epoch 128/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8214 - val_loss: 0.5209 - val_accuracy: 0.7129\n",
            "Epoch 129/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8190 - val_loss: 0.5194 - val_accuracy: 0.7376\n",
            "Epoch 130/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8054 - val_loss: 0.5167 - val_accuracy: 0.7376\n",
            "Epoch 131/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8239 - val_loss: 0.5170 - val_accuracy: 0.7426\n",
            "Epoch 132/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8251 - val_loss: 0.5187 - val_accuracy: 0.7426\n",
            "Epoch 133/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8276 - val_loss: 0.5226 - val_accuracy: 0.7327\n",
            "Epoch 134/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8264 - val_loss: 0.5219 - val_accuracy: 0.7376\n",
            "Epoch 135/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8153 - val_loss: 0.5187 - val_accuracy: 0.7475\n",
            "Epoch 136/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8177 - val_loss: 0.5173 - val_accuracy: 0.7426\n",
            "Epoch 137/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8288 - val_loss: 0.5190 - val_accuracy: 0.7376\n",
            "Epoch 138/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8214 - val_loss: 0.5190 - val_accuracy: 0.7376\n",
            "Epoch 139/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8227 - val_loss: 0.5180 - val_accuracy: 0.7426\n",
            "Epoch 140/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8214 - val_loss: 0.5179 - val_accuracy: 0.7525\n",
            "Epoch 141/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8251 - val_loss: 0.5180 - val_accuracy: 0.7426\n",
            "Epoch 142/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8177 - val_loss: 0.5235 - val_accuracy: 0.7178\n",
            "Epoch 143/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8239 - val_loss: 0.5221 - val_accuracy: 0.7178\n",
            "Epoch 144/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8239 - val_loss: 0.5221 - val_accuracy: 0.7178\n",
            "Epoch 145/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8227 - val_loss: 0.5202 - val_accuracy: 0.7426\n",
            "Epoch 146/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8214 - val_loss: 0.5259 - val_accuracy: 0.7178\n",
            "Epoch 147/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8264 - val_loss: 0.5208 - val_accuracy: 0.7426\n",
            "Epoch 148/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8264 - val_loss: 0.5219 - val_accuracy: 0.7327\n",
            "Epoch 149/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8288 - val_loss: 0.5214 - val_accuracy: 0.7327\n",
            "Epoch 150/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8276 - val_loss: 0.5190 - val_accuracy: 0.7376\n",
            "Epoch 151/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8325 - val_loss: 0.5236 - val_accuracy: 0.7327\n",
            "Epoch 152/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8276 - val_loss: 0.5240 - val_accuracy: 0.7228\n",
            "Epoch 153/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8227 - val_loss: 0.5198 - val_accuracy: 0.7376\n",
            "Epoch 154/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8264 - val_loss: 0.5253 - val_accuracy: 0.7327\n",
            "Epoch 155/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8276 - val_loss: 0.5212 - val_accuracy: 0.7376\n",
            "Epoch 156/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8264 - val_loss: 0.5224 - val_accuracy: 0.7327\n",
            "Epoch 157/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8387 - val_loss: 0.5262 - val_accuracy: 0.7178\n",
            "Epoch 158/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8239 - val_loss: 0.5199 - val_accuracy: 0.7327\n",
            "Epoch 159/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8239 - val_loss: 0.5222 - val_accuracy: 0.7426\n",
            "Epoch 160/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8288 - val_loss: 0.5215 - val_accuracy: 0.7376\n",
            "Epoch 161/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8337 - val_loss: 0.5229 - val_accuracy: 0.7376\n",
            "Epoch 162/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8300 - val_loss: 0.5214 - val_accuracy: 0.7376\n",
            "Epoch 163/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8313 - val_loss: 0.5217 - val_accuracy: 0.7327\n",
            "Epoch 164/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8264 - val_loss: 0.5234 - val_accuracy: 0.7178\n",
            "Epoch 165/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8165 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
            "Epoch 166/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8374 - val_loss: 0.5260 - val_accuracy: 0.7178\n",
            "Epoch 167/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8264 - val_loss: 0.5221 - val_accuracy: 0.7327\n",
            "Epoch 168/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8362 - val_loss: 0.5244 - val_accuracy: 0.7178\n",
            "Epoch 169/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8251 - val_loss: 0.5248 - val_accuracy: 0.7327\n",
            "Epoch 170/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8300 - val_loss: 0.5202 - val_accuracy: 0.7426\n",
            "Epoch 171/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8264 - val_loss: 0.5205 - val_accuracy: 0.7376\n",
            "Epoch 172/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8337 - val_loss: 0.5273 - val_accuracy: 0.7178\n",
            "Epoch 173/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8399 - val_loss: 0.5245 - val_accuracy: 0.7376\n",
            "Epoch 174/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8300 - val_loss: 0.5187 - val_accuracy: 0.7426\n",
            "Epoch 175/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8337 - val_loss: 0.5190 - val_accuracy: 0.7376\n",
            "Epoch 176/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8411 - val_loss: 0.5239 - val_accuracy: 0.7327\n",
            "Epoch 177/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8350 - val_loss: 0.5251 - val_accuracy: 0.7178\n",
            "Epoch 178/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8325 - val_loss: 0.5237 - val_accuracy: 0.7327\n",
            "Epoch 179/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8325 - val_loss: 0.5197 - val_accuracy: 0.7426\n",
            "Epoch 180/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8288 - val_loss: 0.5224 - val_accuracy: 0.7327\n",
            "Epoch 181/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8362 - val_loss: 0.5246 - val_accuracy: 0.7129\n",
            "Epoch 182/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8202 - val_loss: 0.5216 - val_accuracy: 0.7376\n",
            "Epoch 183/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8411 - val_loss: 0.5212 - val_accuracy: 0.7327\n",
            "Epoch 184/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8399 - val_loss: 0.5208 - val_accuracy: 0.7376\n",
            "Epoch 185/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8399 - val_loss: 0.5229 - val_accuracy: 0.7426\n",
            "Epoch 186/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8362 - val_loss: 0.5275 - val_accuracy: 0.7376\n",
            "Epoch 187/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8411 - val_loss: 0.5205 - val_accuracy: 0.7376\n",
            "Epoch 188/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8387 - val_loss: 0.5222 - val_accuracy: 0.7178\n",
            "Epoch 189/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8362 - val_loss: 0.5209 - val_accuracy: 0.7376\n",
            "Epoch 190/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8288 - val_loss: 0.5192 - val_accuracy: 0.7475\n",
            "Epoch 191/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8362 - val_loss: 0.5210 - val_accuracy: 0.7426\n",
            "Epoch 192/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8288 - val_loss: 0.5226 - val_accuracy: 0.7426\n",
            "Epoch 193/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8374 - val_loss: 0.5226 - val_accuracy: 0.7426\n",
            "Epoch 194/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8411 - val_loss: 0.5223 - val_accuracy: 0.7376\n",
            "Epoch 195/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8436 - val_loss: 0.5230 - val_accuracy: 0.7228\n",
            "Epoch 196/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8313 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
            "Epoch 197/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8387 - val_loss: 0.5231 - val_accuracy: 0.7376\n",
            "Epoch 198/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8362 - val_loss: 0.5214 - val_accuracy: 0.7376\n",
            "Epoch 199/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8411 - val_loss: 0.5230 - val_accuracy: 0.7426\n",
            "Epoch 200/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8350 - val_loss: 0.5206 - val_accuracy: 0.7376\n",
            "Epoch 201/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8387 - val_loss: 0.5223 - val_accuracy: 0.7376\n",
            "Epoch 202/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8411 - val_loss: 0.5220 - val_accuracy: 0.7376\n",
            "Epoch 203/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8387 - val_loss: 0.5217 - val_accuracy: 0.7228\n",
            "Epoch 204/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8350 - val_loss: 0.5228 - val_accuracy: 0.7376\n",
            "Epoch 205/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8399 - val_loss: 0.5194 - val_accuracy: 0.7376\n",
            "Epoch 206/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8461 - val_loss: 0.5211 - val_accuracy: 0.7376\n",
            "Epoch 207/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8387 - val_loss: 0.5199 - val_accuracy: 0.7327\n",
            "Epoch 208/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8374 - val_loss: 0.5224 - val_accuracy: 0.7228\n",
            "Epoch 209/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8350 - val_loss: 0.5235 - val_accuracy: 0.7178\n",
            "Epoch 210/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8374 - val_loss: 0.5226 - val_accuracy: 0.7277\n",
            "Epoch 211/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8411 - val_loss: 0.5225 - val_accuracy: 0.7376\n",
            "Epoch 212/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8399 - val_loss: 0.5238 - val_accuracy: 0.7277\n",
            "Epoch 213/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8411 - val_loss: 0.5228 - val_accuracy: 0.7228\n",
            "Epoch 214/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8436 - val_loss: 0.5211 - val_accuracy: 0.7426\n",
            "Epoch 215/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8251 - val_loss: 0.5351 - val_accuracy: 0.7228\n",
            "Epoch 216/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8399 - val_loss: 0.5213 - val_accuracy: 0.7376\n",
            "Epoch 217/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8399 - val_loss: 0.5193 - val_accuracy: 0.7327\n",
            "Epoch 218/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8387 - val_loss: 0.5261 - val_accuracy: 0.7178\n",
            "Epoch 219/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8251 - val_loss: 0.5214 - val_accuracy: 0.7327\n",
            "Epoch 220/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8461 - val_loss: 0.5209 - val_accuracy: 0.7376\n",
            "Epoch 221/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8350 - val_loss: 0.5189 - val_accuracy: 0.7178\n",
            "Epoch 222/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8473 - val_loss: 0.5236 - val_accuracy: 0.7426\n",
            "Epoch 223/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8436 - val_loss: 0.5185 - val_accuracy: 0.7327\n",
            "Epoch 224/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8399 - val_loss: 0.5242 - val_accuracy: 0.7327\n",
            "Epoch 225/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8448 - val_loss: 0.5230 - val_accuracy: 0.7376\n",
            "Epoch 226/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8411 - val_loss: 0.5227 - val_accuracy: 0.7178\n",
            "Epoch 227/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8350 - val_loss: 0.5225 - val_accuracy: 0.7426\n",
            "Epoch 228/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8411 - val_loss: 0.5195 - val_accuracy: 0.7376\n",
            "Epoch 229/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8399 - val_loss: 0.5212 - val_accuracy: 0.7426\n",
            "Epoch 230/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8473 - val_loss: 0.5173 - val_accuracy: 0.7475\n",
            "Epoch 231/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8411 - val_loss: 0.5211 - val_accuracy: 0.7327\n",
            "Epoch 232/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8399 - val_loss: 0.5165 - val_accuracy: 0.7327\n",
            "Epoch 233/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8411 - val_loss: 0.5167 - val_accuracy: 0.7277\n",
            "Epoch 234/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8448 - val_loss: 0.5213 - val_accuracy: 0.7426\n",
            "Epoch 235/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8350 - val_loss: 0.5214 - val_accuracy: 0.7327\n",
            "Epoch 236/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8337 - val_loss: 0.5167 - val_accuracy: 0.7376\n",
            "Epoch 237/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8411 - val_loss: 0.5188 - val_accuracy: 0.7376\n",
            "Epoch 238/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8362 - val_loss: 0.5198 - val_accuracy: 0.7426\n",
            "Epoch 239/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8411 - val_loss: 0.5231 - val_accuracy: 0.7426\n",
            "Epoch 240/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8448 - val_loss: 0.5218 - val_accuracy: 0.7327\n",
            "Epoch 241/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8424 - val_loss: 0.5194 - val_accuracy: 0.7376\n",
            "Epoch 242/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8411 - val_loss: 0.5211 - val_accuracy: 0.7475\n",
            "Epoch 243/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8448 - val_loss: 0.5185 - val_accuracy: 0.7376\n",
            "Epoch 244/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8448 - val_loss: 0.5199 - val_accuracy: 0.7426\n",
            "Epoch 245/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8411 - val_loss: 0.5185 - val_accuracy: 0.7327\n",
            "Epoch 246/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8411 - val_loss: 0.5190 - val_accuracy: 0.7376\n",
            "Epoch 247/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8424 - val_loss: 0.5242 - val_accuracy: 0.7228\n",
            "Epoch 248/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8350 - val_loss: 0.5204 - val_accuracy: 0.7376\n",
            "Epoch 249/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8436 - val_loss: 0.5193 - val_accuracy: 0.7327\n",
            "Epoch 250/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8461 - val_loss: 0.5210 - val_accuracy: 0.7426\n",
            "Epoch 251/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8313 - val_loss: 0.5243 - val_accuracy: 0.7178\n",
            "Epoch 252/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8436 - val_loss: 0.5183 - val_accuracy: 0.7426\n",
            "Epoch 253/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8424 - val_loss: 0.5205 - val_accuracy: 0.7277\n",
            "Epoch 254/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8547 - val_loss: 0.5279 - val_accuracy: 0.7426\n",
            "Epoch 255/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8399 - val_loss: 0.5204 - val_accuracy: 0.7525\n",
            "Epoch 256/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8399 - val_loss: 0.5210 - val_accuracy: 0.7376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history2.params)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "history = history2\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "gvMhOqrWVrYM",
        "outputId": "c2815b63-201a-47b0-fd6e-a891a80d52c4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 256, 'steps': 26}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the train set\n",
        "P2 = model2.predict(XTRAIN)\n",
        "accuracy = model2.evaluate(XTRAIN, YTRAIN)\n",
        "my_f1 = f1_score(YTRAIN, P2.round())\n",
        "my_precision = precision_score(YTRAIN, P2.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAUHv_KtKDgZ",
        "outputId": "4aec052a-a58e-4ede-e2b7-25ebdc3146d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8140\n",
            "f1:  0.8346111719605696\n",
            "precision:  0.900709219858156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the validation set\n",
        "P2 = model2.predict(XVALID)\n",
        "accuracy = model2.evaluate(XVALID, YVALID)\n",
        "my_f1 = f1_score(YVALID, P2.round())\n",
        "my_precision = precision_score(YVALID, P2.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "id": "xG2Cc2CpKGKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3= Sequential() # multi-layer network\n",
        "model3.add(Dense(8, input_dim= len(XTRAIN[0,:]), activation = 'relu' ))\n",
        "model3.add(Dense(4, activation = 'relu' ))\n",
        "model3.add(Dense(2, activation = 'relu' ))\n",
        "model3.add(Dense(1, activation = 'sigmoid')) \n",
        "model3.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics='accuracy' )\n",
        "# activation and optimizer are changing in order to find highest validation accuracy"
      ],
      "metadata": {
        "id": "Nr9kvAnIqmvf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history3 = model3.fit(x= XTRAIN, y=YTRAIN, validation_data = (XVALID, YVALID), epochs = 512, verbose = 1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu8aodXxqnXd",
        "outputId": "cb4cbf6c-a3e3-4a59-ba80-ce4b6706ff5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/512\n",
            "26/26 [==============================] - 1s 11ms/step - loss: 0.6842 - accuracy: 0.5850 - val_loss: 0.6807 - val_accuracy: 0.6188\n",
            "Epoch 2/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.5948 - val_loss: 0.6712 - val_accuracy: 0.6188\n",
            "Epoch 3/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.5948 - val_loss: 0.6626 - val_accuracy: 0.6188\n",
            "Epoch 4/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.5948 - val_loss: 0.6542 - val_accuracy: 0.6188\n",
            "Epoch 5/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.5948 - val_loss: 0.6457 - val_accuracy: 0.6188\n",
            "Epoch 6/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.5948 - val_loss: 0.6366 - val_accuracy: 0.6188\n",
            "Epoch 7/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.5948 - val_loss: 0.6274 - val_accuracy: 0.6188\n",
            "Epoch 8/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.5948 - val_loss: 0.6179 - val_accuracy: 0.6188\n",
            "Epoch 9/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.5948 - val_loss: 0.6073 - val_accuracy: 0.6188\n",
            "Epoch 10/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.5948 - val_loss: 0.5975 - val_accuracy: 0.6188\n",
            "Epoch 11/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.5948 - val_loss: 0.5881 - val_accuracy: 0.6188\n",
            "Epoch 12/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.5948 - val_loss: 0.5783 - val_accuracy: 0.6188\n",
            "Epoch 13/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.5948 - val_loss: 0.5688 - val_accuracy: 0.6188\n",
            "Epoch 14/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.5948 - val_loss: 0.5604 - val_accuracy: 0.6188\n",
            "Epoch 15/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.5948 - val_loss: 0.5534 - val_accuracy: 0.6188\n",
            "Epoch 16/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.5948 - val_loss: 0.5470 - val_accuracy: 0.6188\n",
            "Epoch 17/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.6342 - val_loss: 0.5410 - val_accuracy: 0.7030\n",
            "Epoch 18/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7254 - val_loss: 0.5360 - val_accuracy: 0.7129\n",
            "Epoch 19/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7303 - val_loss: 0.5308 - val_accuracy: 0.7129\n",
            "Epoch 20/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7254 - val_loss: 0.5267 - val_accuracy: 0.7228\n",
            "Epoch 21/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7291 - val_loss: 0.5220 - val_accuracy: 0.7376\n",
            "Epoch 22/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7377 - val_loss: 0.5175 - val_accuracy: 0.7426\n",
            "Epoch 23/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7377 - val_loss: 0.5138 - val_accuracy: 0.7426\n",
            "Epoch 24/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7365 - val_loss: 0.5115 - val_accuracy: 0.7624\n",
            "Epoch 25/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7611 - val_loss: 0.5092 - val_accuracy: 0.7772\n",
            "Epoch 26/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7438 - val_loss: 0.5055 - val_accuracy: 0.7673\n",
            "Epoch 27/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7599 - val_loss: 0.5037 - val_accuracy: 0.7673\n",
            "Epoch 28/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7685 - val_loss: 0.5016 - val_accuracy: 0.7673\n",
            "Epoch 29/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7623 - val_loss: 0.4996 - val_accuracy: 0.7574\n",
            "Epoch 30/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7635 - val_loss: 0.4980 - val_accuracy: 0.7574\n",
            "Epoch 31/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7672 - val_loss: 0.4955 - val_accuracy: 0.7574\n",
            "Epoch 32/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7697 - val_loss: 0.4945 - val_accuracy: 0.7673\n",
            "Epoch 33/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7771 - val_loss: 0.4924 - val_accuracy: 0.7574\n",
            "Epoch 34/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7672 - val_loss: 0.4912 - val_accuracy: 0.7673\n",
            "Epoch 35/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7672 - val_loss: 0.4893 - val_accuracy: 0.7525\n",
            "Epoch 36/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7759 - val_loss: 0.4885 - val_accuracy: 0.7624\n",
            "Epoch 37/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7672 - val_loss: 0.4874 - val_accuracy: 0.7723\n",
            "Epoch 38/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7746 - val_loss: 0.4852 - val_accuracy: 0.7475\n",
            "Epoch 39/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7722 - val_loss: 0.4851 - val_accuracy: 0.7723\n",
            "Epoch 40/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7685 - val_loss: 0.4833 - val_accuracy: 0.7723\n",
            "Epoch 41/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7709 - val_loss: 0.4824 - val_accuracy: 0.7723\n",
            "Epoch 42/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7697 - val_loss: 0.4807 - val_accuracy: 0.7723\n",
            "Epoch 43/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7734 - val_loss: 0.4800 - val_accuracy: 0.7723\n",
            "Epoch 44/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7672 - val_loss: 0.4788 - val_accuracy: 0.7723\n",
            "Epoch 45/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7734 - val_loss: 0.4778 - val_accuracy: 0.7723\n",
            "Epoch 46/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7746 - val_loss: 0.4766 - val_accuracy: 0.7723\n",
            "Epoch 47/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7709 - val_loss: 0.4768 - val_accuracy: 0.7673\n",
            "Epoch 48/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7722 - val_loss: 0.4753 - val_accuracy: 0.7673\n",
            "Epoch 49/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7746 - val_loss: 0.4745 - val_accuracy: 0.7673\n",
            "Epoch 50/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7722 - val_loss: 0.4737 - val_accuracy: 0.7723\n",
            "Epoch 51/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7722 - val_loss: 0.4732 - val_accuracy: 0.7723\n",
            "Epoch 52/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7685 - val_loss: 0.4728 - val_accuracy: 0.7525\n",
            "Epoch 53/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7734 - val_loss: 0.4724 - val_accuracy: 0.7525\n",
            "Epoch 54/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7709 - val_loss: 0.4710 - val_accuracy: 0.7772\n",
            "Epoch 55/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7709 - val_loss: 0.4718 - val_accuracy: 0.7525\n",
            "Epoch 56/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7746 - val_loss: 0.4711 - val_accuracy: 0.7723\n",
            "Epoch 57/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7685 - val_loss: 0.4700 - val_accuracy: 0.7673\n",
            "Epoch 58/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7722 - val_loss: 0.4694 - val_accuracy: 0.7772\n",
            "Epoch 59/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7722 - val_loss: 0.4682 - val_accuracy: 0.7525\n",
            "Epoch 60/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7722 - val_loss: 0.4681 - val_accuracy: 0.7673\n",
            "Epoch 61/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7759 - val_loss: 0.4677 - val_accuracy: 0.7723\n",
            "Epoch 62/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7734 - val_loss: 0.4667 - val_accuracy: 0.7723\n",
            "Epoch 63/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7746 - val_loss: 0.4667 - val_accuracy: 0.7525\n",
            "Epoch 64/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7746 - val_loss: 0.4659 - val_accuracy: 0.7723\n",
            "Epoch 65/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7734 - val_loss: 0.4657 - val_accuracy: 0.7723\n",
            "Epoch 66/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7746 - val_loss: 0.4652 - val_accuracy: 0.7525\n",
            "Epoch 67/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7722 - val_loss: 0.4653 - val_accuracy: 0.7723\n",
            "Epoch 68/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7746 - val_loss: 0.4643 - val_accuracy: 0.7723\n",
            "Epoch 69/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7746 - val_loss: 0.4639 - val_accuracy: 0.7723\n",
            "Epoch 70/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7709 - val_loss: 0.4642 - val_accuracy: 0.7525\n",
            "Epoch 71/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7759 - val_loss: 0.4632 - val_accuracy: 0.7723\n",
            "Epoch 72/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7734 - val_loss: 0.4631 - val_accuracy: 0.7673\n",
            "Epoch 73/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7759 - val_loss: 0.4629 - val_accuracy: 0.7673\n",
            "Epoch 74/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7697 - val_loss: 0.4628 - val_accuracy: 0.7525\n",
            "Epoch 75/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7722 - val_loss: 0.4631 - val_accuracy: 0.7723\n",
            "Epoch 76/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7746 - val_loss: 0.4615 - val_accuracy: 0.7673\n",
            "Epoch 77/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7722 - val_loss: 0.4619 - val_accuracy: 0.7673\n",
            "Epoch 78/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7660 - val_loss: 0.4618 - val_accuracy: 0.7525\n",
            "Epoch 79/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7722 - val_loss: 0.4619 - val_accuracy: 0.7525\n",
            "Epoch 80/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7722 - val_loss: 0.4615 - val_accuracy: 0.7525\n",
            "Epoch 81/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7759 - val_loss: 0.4620 - val_accuracy: 0.7673\n",
            "Epoch 82/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7759 - val_loss: 0.4614 - val_accuracy: 0.7673\n",
            "Epoch 83/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7771 - val_loss: 0.4612 - val_accuracy: 0.7525\n",
            "Epoch 84/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7746 - val_loss: 0.4614 - val_accuracy: 0.7673\n",
            "Epoch 85/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7734 - val_loss: 0.4608 - val_accuracy: 0.7525\n",
            "Epoch 86/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7734 - val_loss: 0.4609 - val_accuracy: 0.7673\n",
            "Epoch 87/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7783 - val_loss: 0.4606 - val_accuracy: 0.7525\n",
            "Epoch 88/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7759 - val_loss: 0.4603 - val_accuracy: 0.7673\n",
            "Epoch 89/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7796 - val_loss: 0.4605 - val_accuracy: 0.7673\n",
            "Epoch 90/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7783 - val_loss: 0.4605 - val_accuracy: 0.7673\n",
            "Epoch 91/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7783 - val_loss: 0.4596 - val_accuracy: 0.7673\n",
            "Epoch 92/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7771 - val_loss: 0.4608 - val_accuracy: 0.7723\n",
            "Epoch 93/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7771 - val_loss: 0.4596 - val_accuracy: 0.7673\n",
            "Epoch 94/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7746 - val_loss: 0.4604 - val_accuracy: 0.7673\n",
            "Epoch 95/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7771 - val_loss: 0.4605 - val_accuracy: 0.7673\n",
            "Epoch 96/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7796 - val_loss: 0.4594 - val_accuracy: 0.7673\n",
            "Epoch 97/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7759 - val_loss: 0.4594 - val_accuracy: 0.7723\n",
            "Epoch 98/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7783 - val_loss: 0.4590 - val_accuracy: 0.7673\n",
            "Epoch 99/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7759 - val_loss: 0.4594 - val_accuracy: 0.7723\n",
            "Epoch 100/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7771 - val_loss: 0.4589 - val_accuracy: 0.7673\n",
            "Epoch 101/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7746 - val_loss: 0.4595 - val_accuracy: 0.7673\n",
            "Epoch 102/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7734 - val_loss: 0.4593 - val_accuracy: 0.7723\n",
            "Epoch 103/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7734 - val_loss: 0.4597 - val_accuracy: 0.7723\n",
            "Epoch 104/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7746 - val_loss: 0.4596 - val_accuracy: 0.7723\n",
            "Epoch 105/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7759 - val_loss: 0.4597 - val_accuracy: 0.7673\n",
            "Epoch 106/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7771 - val_loss: 0.4590 - val_accuracy: 0.7723\n",
            "Epoch 107/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7759 - val_loss: 0.4590 - val_accuracy: 0.7673\n",
            "Epoch 108/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7759 - val_loss: 0.4586 - val_accuracy: 0.7673\n",
            "Epoch 109/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7746 - val_loss: 0.4599 - val_accuracy: 0.7772\n",
            "Epoch 110/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7722 - val_loss: 0.4585 - val_accuracy: 0.7723\n",
            "Epoch 111/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7759 - val_loss: 0.4588 - val_accuracy: 0.7673\n",
            "Epoch 112/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7759 - val_loss: 0.4584 - val_accuracy: 0.7673\n",
            "Epoch 113/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7759 - val_loss: 0.4582 - val_accuracy: 0.7723\n",
            "Epoch 114/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7734 - val_loss: 0.4594 - val_accuracy: 0.7673\n",
            "Epoch 115/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7759 - val_loss: 0.4581 - val_accuracy: 0.7723\n",
            "Epoch 116/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7783 - val_loss: 0.4588 - val_accuracy: 0.7723\n",
            "Epoch 117/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7746 - val_loss: 0.4584 - val_accuracy: 0.7723\n",
            "Epoch 118/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7722 - val_loss: 0.4587 - val_accuracy: 0.7723\n",
            "Epoch 119/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7759 - val_loss: 0.4585 - val_accuracy: 0.7723\n",
            "Epoch 120/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7759 - val_loss: 0.4587 - val_accuracy: 0.7723\n",
            "Epoch 121/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7759 - val_loss: 0.4590 - val_accuracy: 0.7723\n",
            "Epoch 122/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7771 - val_loss: 0.4588 - val_accuracy: 0.7723\n",
            "Epoch 123/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7734 - val_loss: 0.4584 - val_accuracy: 0.7723\n",
            "Epoch 124/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7697 - val_loss: 0.4585 - val_accuracy: 0.7673\n",
            "Epoch 125/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7746 - val_loss: 0.4585 - val_accuracy: 0.7673\n",
            "Epoch 126/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7796 - val_loss: 0.4583 - val_accuracy: 0.7723\n",
            "Epoch 127/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7759 - val_loss: 0.4580 - val_accuracy: 0.7673\n",
            "Epoch 128/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7783 - val_loss: 0.4588 - val_accuracy: 0.7624\n",
            "Epoch 129/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7697 - val_loss: 0.4590 - val_accuracy: 0.7723\n",
            "Epoch 130/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7746 - val_loss: 0.4583 - val_accuracy: 0.7624\n",
            "Epoch 131/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7808 - val_loss: 0.4595 - val_accuracy: 0.7624\n",
            "Epoch 132/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7820 - val_loss: 0.4608 - val_accuracy: 0.7723\n",
            "Epoch 133/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7685 - val_loss: 0.4597 - val_accuracy: 0.7673\n",
            "Epoch 134/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7820 - val_loss: 0.4589 - val_accuracy: 0.7624\n",
            "Epoch 135/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7808 - val_loss: 0.4602 - val_accuracy: 0.7673\n",
            "Epoch 136/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7759 - val_loss: 0.4610 - val_accuracy: 0.7772\n",
            "Epoch 137/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7672 - val_loss: 0.4611 - val_accuracy: 0.7723\n",
            "Epoch 138/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7771 - val_loss: 0.4603 - val_accuracy: 0.7624\n",
            "Epoch 139/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7759 - val_loss: 0.4609 - val_accuracy: 0.7723\n",
            "Epoch 140/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7771 - val_loss: 0.4615 - val_accuracy: 0.7574\n",
            "Epoch 141/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7783 - val_loss: 0.4612 - val_accuracy: 0.7673\n",
            "Epoch 142/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7783 - val_loss: 0.4618 - val_accuracy: 0.7624\n",
            "Epoch 143/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7783 - val_loss: 0.4609 - val_accuracy: 0.7673\n",
            "Epoch 144/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7734 - val_loss: 0.4624 - val_accuracy: 0.7624\n",
            "Epoch 145/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7759 - val_loss: 0.4618 - val_accuracy: 0.7525\n",
            "Epoch 146/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7808 - val_loss: 0.4622 - val_accuracy: 0.7525\n",
            "Epoch 147/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7759 - val_loss: 0.4623 - val_accuracy: 0.7525\n",
            "Epoch 148/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7771 - val_loss: 0.4623 - val_accuracy: 0.7525\n",
            "Epoch 149/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7746 - val_loss: 0.4620 - val_accuracy: 0.7525\n",
            "Epoch 150/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7820 - val_loss: 0.4621 - val_accuracy: 0.7624\n",
            "Epoch 151/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7808 - val_loss: 0.4614 - val_accuracy: 0.7574\n",
            "Epoch 152/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7820 - val_loss: 0.4631 - val_accuracy: 0.7624\n",
            "Epoch 153/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7833 - val_loss: 0.4621 - val_accuracy: 0.7525\n",
            "Epoch 154/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7783 - val_loss: 0.4634 - val_accuracy: 0.7525\n",
            "Epoch 155/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7820 - val_loss: 0.4642 - val_accuracy: 0.7574\n",
            "Epoch 156/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7796 - val_loss: 0.4639 - val_accuracy: 0.7574\n",
            "Epoch 157/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7771 - val_loss: 0.4648 - val_accuracy: 0.7525\n",
            "Epoch 158/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7820 - val_loss: 0.4641 - val_accuracy: 0.7525\n",
            "Epoch 159/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7746 - val_loss: 0.4649 - val_accuracy: 0.7574\n",
            "Epoch 160/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7808 - val_loss: 0.4647 - val_accuracy: 0.7574\n",
            "Epoch 161/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7808 - val_loss: 0.4651 - val_accuracy: 0.7574\n",
            "Epoch 162/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7820 - val_loss: 0.4643 - val_accuracy: 0.7574\n",
            "Epoch 163/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7820 - val_loss: 0.4631 - val_accuracy: 0.7525\n",
            "Epoch 164/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7820 - val_loss: 0.4640 - val_accuracy: 0.7624\n",
            "Epoch 165/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7882 - val_loss: 0.4633 - val_accuracy: 0.7525\n",
            "Epoch 166/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7820 - val_loss: 0.4643 - val_accuracy: 0.7525\n",
            "Epoch 167/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7845 - val_loss: 0.4635 - val_accuracy: 0.7525\n",
            "Epoch 168/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7820 - val_loss: 0.4647 - val_accuracy: 0.7426\n",
            "Epoch 169/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7857 - val_loss: 0.4648 - val_accuracy: 0.7525\n",
            "Epoch 170/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7845 - val_loss: 0.4637 - val_accuracy: 0.7574\n",
            "Epoch 171/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7857 - val_loss: 0.4656 - val_accuracy: 0.7525\n",
            "Epoch 172/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7857 - val_loss: 0.4636 - val_accuracy: 0.7525\n",
            "Epoch 173/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7869 - val_loss: 0.4645 - val_accuracy: 0.7426\n",
            "Epoch 174/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7894 - val_loss: 0.4655 - val_accuracy: 0.7426\n",
            "Epoch 175/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7894 - val_loss: 0.4645 - val_accuracy: 0.7426\n",
            "Epoch 176/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7894 - val_loss: 0.4644 - val_accuracy: 0.7426\n",
            "Epoch 177/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7894 - val_loss: 0.4654 - val_accuracy: 0.7475\n",
            "Epoch 178/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7931 - val_loss: 0.4650 - val_accuracy: 0.7426\n",
            "Epoch 179/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.4657 - val_accuracy: 0.7475\n",
            "Epoch 180/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7894 - val_loss: 0.4657 - val_accuracy: 0.7475\n",
            "Epoch 181/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7906 - val_loss: 0.4653 - val_accuracy: 0.7426\n",
            "Epoch 182/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7894 - val_loss: 0.4650 - val_accuracy: 0.7426\n",
            "Epoch 183/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7956 - val_loss: 0.4654 - val_accuracy: 0.7426\n",
            "Epoch 184/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4660 - val_accuracy: 0.7475\n",
            "Epoch 185/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7869 - val_loss: 0.4669 - val_accuracy: 0.7426\n",
            "Epoch 186/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4672 - val_accuracy: 0.7426\n",
            "Epoch 187/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.4655 - val_accuracy: 0.7426\n",
            "Epoch 188/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7906 - val_loss: 0.4651 - val_accuracy: 0.7426\n",
            "Epoch 189/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7869 - val_loss: 0.4676 - val_accuracy: 0.7475\n",
            "Epoch 190/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7919 - val_loss: 0.4660 - val_accuracy: 0.7475\n",
            "Epoch 191/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7894 - val_loss: 0.4659 - val_accuracy: 0.7426\n",
            "Epoch 192/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7869 - val_loss: 0.4671 - val_accuracy: 0.7426\n",
            "Epoch 193/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7894 - val_loss: 0.4677 - val_accuracy: 0.7426\n",
            "Epoch 194/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7857 - val_loss: 0.4657 - val_accuracy: 0.7426\n",
            "Epoch 195/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8005 - val_loss: 0.4701 - val_accuracy: 0.7475\n",
            "Epoch 196/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7906 - val_loss: 0.4663 - val_accuracy: 0.7426\n",
            "Epoch 197/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7894 - val_loss: 0.4661 - val_accuracy: 0.7426\n",
            "Epoch 198/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7857 - val_loss: 0.4656 - val_accuracy: 0.7426\n",
            "Epoch 199/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7906 - val_loss: 0.4691 - val_accuracy: 0.7525\n",
            "Epoch 200/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7894 - val_loss: 0.4664 - val_accuracy: 0.7426\n",
            "Epoch 201/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7894 - val_loss: 0.4659 - val_accuracy: 0.7426\n",
            "Epoch 202/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7894 - val_loss: 0.4654 - val_accuracy: 0.7426\n",
            "Epoch 203/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.4640 - val_accuracy: 0.7426\n",
            "Epoch 204/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7894 - val_loss: 0.4658 - val_accuracy: 0.7426\n",
            "Epoch 205/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7894 - val_loss: 0.4663 - val_accuracy: 0.7475\n",
            "Epoch 206/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.4658 - val_accuracy: 0.7426\n",
            "Epoch 207/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7943 - val_loss: 0.4669 - val_accuracy: 0.7426\n",
            "Epoch 208/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7820 - val_loss: 0.4637 - val_accuracy: 0.7574\n",
            "Epoch 209/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7894 - val_loss: 0.4665 - val_accuracy: 0.7475\n",
            "Epoch 210/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7894 - val_loss: 0.4656 - val_accuracy: 0.7426\n",
            "Epoch 211/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7857 - val_loss: 0.4663 - val_accuracy: 0.7475\n",
            "Epoch 212/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7906 - val_loss: 0.4651 - val_accuracy: 0.7426\n",
            "Epoch 213/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.4646 - val_accuracy: 0.7426\n",
            "Epoch 214/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7894 - val_loss: 0.4647 - val_accuracy: 0.7426\n",
            "Epoch 215/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7894 - val_loss: 0.4658 - val_accuracy: 0.7426\n",
            "Epoch 216/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7882 - val_loss: 0.4642 - val_accuracy: 0.7426\n",
            "Epoch 217/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7894 - val_loss: 0.4670 - val_accuracy: 0.7525\n",
            "Epoch 218/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7919 - val_loss: 0.4655 - val_accuracy: 0.7426\n",
            "Epoch 219/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7869 - val_loss: 0.4642 - val_accuracy: 0.7426\n",
            "Epoch 220/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7894 - val_loss: 0.4660 - val_accuracy: 0.7475\n",
            "Epoch 221/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7882 - val_loss: 0.4654 - val_accuracy: 0.7475\n",
            "Epoch 222/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7919 - val_loss: 0.4656 - val_accuracy: 0.7426\n",
            "Epoch 223/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7857 - val_loss: 0.4663 - val_accuracy: 0.7426\n",
            "Epoch 224/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7919 - val_loss: 0.4658 - val_accuracy: 0.7426\n",
            "Epoch 225/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7906 - val_loss: 0.4641 - val_accuracy: 0.7426\n",
            "Epoch 226/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7894 - val_loss: 0.4657 - val_accuracy: 0.7475\n",
            "Epoch 227/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7906 - val_loss: 0.4648 - val_accuracy: 0.7426\n",
            "Epoch 228/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7869 - val_loss: 0.4655 - val_accuracy: 0.7475\n",
            "Epoch 229/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7894 - val_loss: 0.4659 - val_accuracy: 0.7475\n",
            "Epoch 230/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7906 - val_loss: 0.4654 - val_accuracy: 0.7475\n",
            "Epoch 231/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7906 - val_loss: 0.4655 - val_accuracy: 0.7475\n",
            "Epoch 232/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7906 - val_loss: 0.4667 - val_accuracy: 0.7525\n",
            "Epoch 233/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7931 - val_loss: 0.4655 - val_accuracy: 0.7426\n",
            "Epoch 234/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7968 - val_loss: 0.4657 - val_accuracy: 0.7475\n",
            "Epoch 235/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7943 - val_loss: 0.4655 - val_accuracy: 0.7426\n",
            "Epoch 236/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7894 - val_loss: 0.4647 - val_accuracy: 0.7426\n",
            "Epoch 237/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7906 - val_loss: 0.4666 - val_accuracy: 0.7525\n",
            "Epoch 238/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7943 - val_loss: 0.4651 - val_accuracy: 0.7376\n",
            "Epoch 239/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7894 - val_loss: 0.4654 - val_accuracy: 0.7426\n",
            "Epoch 240/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7894 - val_loss: 0.4666 - val_accuracy: 0.7525\n",
            "Epoch 241/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7894 - val_loss: 0.4650 - val_accuracy: 0.7475\n",
            "Epoch 242/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7869 - val_loss: 0.4672 - val_accuracy: 0.7525\n",
            "Epoch 243/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7906 - val_loss: 0.4671 - val_accuracy: 0.7525\n",
            "Epoch 244/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7993 - val_loss: 0.4664 - val_accuracy: 0.7475\n",
            "Epoch 245/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7845 - val_loss: 0.4644 - val_accuracy: 0.7426\n",
            "Epoch 246/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7894 - val_loss: 0.4660 - val_accuracy: 0.7475\n",
            "Epoch 247/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7894 - val_loss: 0.4640 - val_accuracy: 0.7426\n",
            "Epoch 248/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7906 - val_loss: 0.4649 - val_accuracy: 0.7426\n",
            "Epoch 249/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.4643 - val_accuracy: 0.7426\n",
            "Epoch 250/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7906 - val_loss: 0.4670 - val_accuracy: 0.7525\n",
            "Epoch 251/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7869 - val_loss: 0.4646 - val_accuracy: 0.7426\n",
            "Epoch 252/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7894 - val_loss: 0.4638 - val_accuracy: 0.7426\n",
            "Epoch 253/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7906 - val_loss: 0.4649 - val_accuracy: 0.7426\n",
            "Epoch 254/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7869 - val_loss: 0.4650 - val_accuracy: 0.7426\n",
            "Epoch 255/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7943 - val_loss: 0.4671 - val_accuracy: 0.7525\n",
            "Epoch 256/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7906 - val_loss: 0.4653 - val_accuracy: 0.7426\n",
            "Epoch 257/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7931 - val_loss: 0.4660 - val_accuracy: 0.7525\n",
            "Epoch 258/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7943 - val_loss: 0.4674 - val_accuracy: 0.7475\n",
            "Epoch 259/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7919 - val_loss: 0.4655 - val_accuracy: 0.7525\n",
            "Epoch 260/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7956 - val_loss: 0.4653 - val_accuracy: 0.7525\n",
            "Epoch 261/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7894 - val_loss: 0.4658 - val_accuracy: 0.7525\n",
            "Epoch 262/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7869 - val_loss: 0.4632 - val_accuracy: 0.7426\n",
            "Epoch 263/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7956 - val_loss: 0.4652 - val_accuracy: 0.7525\n",
            "Epoch 264/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7943 - val_loss: 0.4643 - val_accuracy: 0.7426\n",
            "Epoch 265/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7919 - val_loss: 0.4637 - val_accuracy: 0.7426\n",
            "Epoch 266/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7906 - val_loss: 0.4665 - val_accuracy: 0.7525\n",
            "Epoch 267/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7943 - val_loss: 0.4647 - val_accuracy: 0.7426\n",
            "Epoch 268/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7919 - val_loss: 0.4643 - val_accuracy: 0.7426\n",
            "Epoch 269/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7931 - val_loss: 0.4686 - val_accuracy: 0.7475\n",
            "Epoch 270/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7894 - val_loss: 0.4643 - val_accuracy: 0.7376\n",
            "Epoch 271/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7906 - val_loss: 0.4642 - val_accuracy: 0.7376\n",
            "Epoch 272/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7956 - val_loss: 0.4663 - val_accuracy: 0.7525\n",
            "Epoch 273/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7943 - val_loss: 0.4660 - val_accuracy: 0.7525\n",
            "Epoch 274/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7956 - val_loss: 0.4635 - val_accuracy: 0.7376\n",
            "Epoch 275/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7894 - val_loss: 0.4648 - val_accuracy: 0.7426\n",
            "Epoch 276/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7956 - val_loss: 0.4650 - val_accuracy: 0.7475\n",
            "Epoch 277/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.4644 - val_accuracy: 0.7376\n",
            "Epoch 278/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7968 - val_loss: 0.4653 - val_accuracy: 0.7475\n",
            "Epoch 279/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7931 - val_loss: 0.4659 - val_accuracy: 0.7475\n",
            "Epoch 280/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7931 - val_loss: 0.4648 - val_accuracy: 0.7475\n",
            "Epoch 281/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7894 - val_loss: 0.4631 - val_accuracy: 0.7624\n",
            "Epoch 282/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7894 - val_loss: 0.4630 - val_accuracy: 0.7376\n",
            "Epoch 283/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7894 - val_loss: 0.4628 - val_accuracy: 0.7624\n",
            "Epoch 284/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7931 - val_loss: 0.4668 - val_accuracy: 0.7475\n",
            "Epoch 285/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7956 - val_loss: 0.4645 - val_accuracy: 0.7475\n",
            "Epoch 286/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7894 - val_loss: 0.4646 - val_accuracy: 0.7475\n",
            "Epoch 287/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7894 - val_loss: 0.4649 - val_accuracy: 0.7475\n",
            "Epoch 288/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7882 - val_loss: 0.4637 - val_accuracy: 0.7475\n",
            "Epoch 289/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7919 - val_loss: 0.4628 - val_accuracy: 0.7475\n",
            "Epoch 290/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7906 - val_loss: 0.4635 - val_accuracy: 0.7475\n",
            "Epoch 291/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7919 - val_loss: 0.4642 - val_accuracy: 0.7475\n",
            "Epoch 292/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7931 - val_loss: 0.4636 - val_accuracy: 0.7475\n",
            "Epoch 293/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7931 - val_loss: 0.4627 - val_accuracy: 0.7475\n",
            "Epoch 294/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7906 - val_loss: 0.4626 - val_accuracy: 0.7426\n",
            "Epoch 295/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7919 - val_loss: 0.4628 - val_accuracy: 0.7475\n",
            "Epoch 296/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7956 - val_loss: 0.4633 - val_accuracy: 0.7475\n",
            "Epoch 297/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7931 - val_loss: 0.4639 - val_accuracy: 0.7525\n",
            "Epoch 298/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7943 - val_loss: 0.4640 - val_accuracy: 0.7475\n",
            "Epoch 299/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7919 - val_loss: 0.4635 - val_accuracy: 0.7475\n",
            "Epoch 300/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7931 - val_loss: 0.4633 - val_accuracy: 0.7475\n",
            "Epoch 301/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7906 - val_loss: 0.4632 - val_accuracy: 0.7475\n",
            "Epoch 302/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7894 - val_loss: 0.4640 - val_accuracy: 0.7426\n",
            "Epoch 303/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7943 - val_loss: 0.4629 - val_accuracy: 0.7525\n",
            "Epoch 304/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7906 - val_loss: 0.4636 - val_accuracy: 0.7475\n",
            "Epoch 305/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7919 - val_loss: 0.4632 - val_accuracy: 0.7525\n",
            "Epoch 306/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7956 - val_loss: 0.4628 - val_accuracy: 0.7525\n",
            "Epoch 307/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7906 - val_loss: 0.4641 - val_accuracy: 0.7426\n",
            "Epoch 308/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7919 - val_loss: 0.4604 - val_accuracy: 0.7624\n",
            "Epoch 309/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7968 - val_loss: 0.4628 - val_accuracy: 0.7525\n",
            "Epoch 310/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7882 - val_loss: 0.4640 - val_accuracy: 0.7475\n",
            "Epoch 311/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7906 - val_loss: 0.4609 - val_accuracy: 0.7475\n",
            "Epoch 312/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.7869 - val_loss: 0.4626 - val_accuracy: 0.7475\n",
            "Epoch 313/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7943 - val_loss: 0.4638 - val_accuracy: 0.7426\n",
            "Epoch 314/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7956 - val_loss: 0.4631 - val_accuracy: 0.7525\n",
            "Epoch 315/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7980 - val_loss: 0.4617 - val_accuracy: 0.7673\n",
            "Epoch 316/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7931 - val_loss: 0.4622 - val_accuracy: 0.7475\n",
            "Epoch 317/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7906 - val_loss: 0.4605 - val_accuracy: 0.7673\n",
            "Epoch 318/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.7968 - val_loss: 0.4652 - val_accuracy: 0.7475\n",
            "Epoch 319/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7968 - val_loss: 0.4611 - val_accuracy: 0.7475\n",
            "Epoch 320/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7906 - val_loss: 0.4606 - val_accuracy: 0.7426\n",
            "Epoch 321/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.7956 - val_loss: 0.4608 - val_accuracy: 0.7475\n",
            "Epoch 322/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.7968 - val_loss: 0.4625 - val_accuracy: 0.7525\n",
            "Epoch 323/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7956 - val_loss: 0.4633 - val_accuracy: 0.7475\n",
            "Epoch 324/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7919 - val_loss: 0.4608 - val_accuracy: 0.7426\n",
            "Epoch 325/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.7919 - val_loss: 0.4605 - val_accuracy: 0.7426\n",
            "Epoch 326/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.7956 - val_loss: 0.4630 - val_accuracy: 0.7475\n",
            "Epoch 327/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.7956 - val_loss: 0.4609 - val_accuracy: 0.7475\n",
            "Epoch 328/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7956 - val_loss: 0.4613 - val_accuracy: 0.7525\n",
            "Epoch 329/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.7968 - val_loss: 0.4613 - val_accuracy: 0.7525\n",
            "Epoch 330/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.7956 - val_loss: 0.4616 - val_accuracy: 0.7475\n",
            "Epoch 331/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7956 - val_loss: 0.4609 - val_accuracy: 0.7475\n",
            "Epoch 332/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.7980 - val_loss: 0.4601 - val_accuracy: 0.7475\n",
            "Epoch 333/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.7919 - val_loss: 0.4594 - val_accuracy: 0.7673\n",
            "Epoch 334/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.7968 - val_loss: 0.4598 - val_accuracy: 0.7475\n",
            "Epoch 335/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.7931 - val_loss: 0.4604 - val_accuracy: 0.7475\n",
            "Epoch 336/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.7993 - val_loss: 0.4635 - val_accuracy: 0.7574\n",
            "Epoch 337/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8005 - val_loss: 0.4599 - val_accuracy: 0.7624\n",
            "Epoch 338/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.7919 - val_loss: 0.4603 - val_accuracy: 0.7475\n",
            "Epoch 339/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8017 - val_loss: 0.4606 - val_accuracy: 0.7475\n",
            "Epoch 340/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7919 - val_loss: 0.4607 - val_accuracy: 0.7426\n",
            "Epoch 341/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.7943 - val_loss: 0.4597 - val_accuracy: 0.7624\n",
            "Epoch 342/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.7956 - val_loss: 0.4598 - val_accuracy: 0.7475\n",
            "Epoch 343/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8005 - val_loss: 0.4615 - val_accuracy: 0.7525\n",
            "Epoch 344/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.7956 - val_loss: 0.4622 - val_accuracy: 0.7475\n",
            "Epoch 345/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.7980 - val_loss: 0.4611 - val_accuracy: 0.7475\n",
            "Epoch 346/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.7980 - val_loss: 0.4607 - val_accuracy: 0.7475\n",
            "Epoch 347/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7993 - val_loss: 0.4605 - val_accuracy: 0.7475\n",
            "Epoch 348/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.7968 - val_loss: 0.4615 - val_accuracy: 0.7426\n",
            "Epoch 349/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.7993 - val_loss: 0.4605 - val_accuracy: 0.7475\n",
            "Epoch 350/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8005 - val_loss: 0.4600 - val_accuracy: 0.7673\n",
            "Epoch 351/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8005 - val_loss: 0.4608 - val_accuracy: 0.7624\n",
            "Epoch 352/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.7980 - val_loss: 0.4610 - val_accuracy: 0.7624\n",
            "Epoch 353/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.7980 - val_loss: 0.4639 - val_accuracy: 0.7525\n",
            "Epoch 354/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8054 - val_loss: 0.4595 - val_accuracy: 0.7624\n",
            "Epoch 355/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.7993 - val_loss: 0.4620 - val_accuracy: 0.7426\n",
            "Epoch 356/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8005 - val_loss: 0.4587 - val_accuracy: 0.7574\n",
            "Epoch 357/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.7993 - val_loss: 0.4606 - val_accuracy: 0.7723\n",
            "Epoch 358/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.7956 - val_loss: 0.4592 - val_accuracy: 0.7624\n",
            "Epoch 359/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8017 - val_loss: 0.4597 - val_accuracy: 0.7624\n",
            "Epoch 360/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8030 - val_loss: 0.4611 - val_accuracy: 0.7673\n",
            "Epoch 361/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8030 - val_loss: 0.4602 - val_accuracy: 0.7673\n",
            "Epoch 362/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8017 - val_loss: 0.4641 - val_accuracy: 0.7475\n",
            "Epoch 363/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8005 - val_loss: 0.4643 - val_accuracy: 0.7475\n",
            "Epoch 364/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.7980 - val_loss: 0.4603 - val_accuracy: 0.7673\n",
            "Epoch 365/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8017 - val_loss: 0.4638 - val_accuracy: 0.7525\n",
            "Epoch 366/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.7980 - val_loss: 0.4615 - val_accuracy: 0.7624\n",
            "Epoch 367/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.7968 - val_loss: 0.4637 - val_accuracy: 0.7525\n",
            "Epoch 368/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8005 - val_loss: 0.4614 - val_accuracy: 0.7673\n",
            "Epoch 369/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8054 - val_loss: 0.4613 - val_accuracy: 0.7673\n",
            "Epoch 370/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8042 - val_loss: 0.4637 - val_accuracy: 0.7723\n",
            "Epoch 371/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8005 - val_loss: 0.4635 - val_accuracy: 0.7525\n",
            "Epoch 372/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8005 - val_loss: 0.4620 - val_accuracy: 0.7673\n",
            "Epoch 373/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8017 - val_loss: 0.4613 - val_accuracy: 0.7673\n",
            "Epoch 374/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8030 - val_loss: 0.4609 - val_accuracy: 0.7673\n",
            "Epoch 375/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8005 - val_loss: 0.4613 - val_accuracy: 0.7673\n",
            "Epoch 376/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8042 - val_loss: 0.4636 - val_accuracy: 0.7723\n",
            "Epoch 377/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8005 - val_loss: 0.4609 - val_accuracy: 0.7624\n",
            "Epoch 378/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.7956 - val_loss: 0.4629 - val_accuracy: 0.7723\n",
            "Epoch 379/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8017 - val_loss: 0.4618 - val_accuracy: 0.7673\n",
            "Epoch 380/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8017 - val_loss: 0.4633 - val_accuracy: 0.7723\n",
            "Epoch 381/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8005 - val_loss: 0.4624 - val_accuracy: 0.7673\n",
            "Epoch 382/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8042 - val_loss: 0.4596 - val_accuracy: 0.7624\n",
            "Epoch 383/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.7993 - val_loss: 0.4629 - val_accuracy: 0.7723\n",
            "Epoch 384/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8067 - val_loss: 0.4623 - val_accuracy: 0.7723\n",
            "Epoch 385/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8067 - val_loss: 0.4625 - val_accuracy: 0.7723\n",
            "Epoch 386/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8005 - val_loss: 0.4630 - val_accuracy: 0.7673\n",
            "Epoch 387/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8042 - val_loss: 0.4619 - val_accuracy: 0.7723\n",
            "Epoch 388/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8017 - val_loss: 0.4625 - val_accuracy: 0.7723\n",
            "Epoch 389/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8017 - val_loss: 0.4646 - val_accuracy: 0.7525\n",
            "Epoch 390/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8017 - val_loss: 0.4607 - val_accuracy: 0.7624\n",
            "Epoch 391/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8030 - val_loss: 0.4629 - val_accuracy: 0.7673\n",
            "Epoch 392/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8054 - val_loss: 0.4618 - val_accuracy: 0.7723\n",
            "Epoch 393/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8005 - val_loss: 0.4613 - val_accuracy: 0.7723\n",
            "Epoch 394/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8042 - val_loss: 0.4632 - val_accuracy: 0.7723\n",
            "Epoch 395/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8067 - val_loss: 0.4629 - val_accuracy: 0.7723\n",
            "Epoch 396/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.7993 - val_loss: 0.4622 - val_accuracy: 0.7673\n",
            "Epoch 397/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8030 - val_loss: 0.4614 - val_accuracy: 0.7673\n",
            "Epoch 398/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8017 - val_loss: 0.4634 - val_accuracy: 0.7723\n",
            "Epoch 399/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8030 - val_loss: 0.4614 - val_accuracy: 0.7723\n",
            "Epoch 400/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.7956 - val_loss: 0.4603 - val_accuracy: 0.7673\n",
            "Epoch 401/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8005 - val_loss: 0.4620 - val_accuracy: 0.7723\n",
            "Epoch 402/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8030 - val_loss: 0.4635 - val_accuracy: 0.7723\n",
            "Epoch 403/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8042 - val_loss: 0.4638 - val_accuracy: 0.7723\n",
            "Epoch 404/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8067 - val_loss: 0.4635 - val_accuracy: 0.7723\n",
            "Epoch 405/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8079 - val_loss: 0.4621 - val_accuracy: 0.7723\n",
            "Epoch 406/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8042 - val_loss: 0.4647 - val_accuracy: 0.7673\n",
            "Epoch 407/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8067 - val_loss: 0.4617 - val_accuracy: 0.7723\n",
            "Epoch 408/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8017 - val_loss: 0.4609 - val_accuracy: 0.7673\n",
            "Epoch 409/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8030 - val_loss: 0.4611 - val_accuracy: 0.7723\n",
            "Epoch 410/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8054 - val_loss: 0.4640 - val_accuracy: 0.7723\n",
            "Epoch 411/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8017 - val_loss: 0.4633 - val_accuracy: 0.7673\n",
            "Epoch 412/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8005 - val_loss: 0.4647 - val_accuracy: 0.7673\n",
            "Epoch 413/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8054 - val_loss: 0.4600 - val_accuracy: 0.7673\n",
            "Epoch 414/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8042 - val_loss: 0.4631 - val_accuracy: 0.7673\n",
            "Epoch 415/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8067 - val_loss: 0.4632 - val_accuracy: 0.7673\n",
            "Epoch 416/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8067 - val_loss: 0.4621 - val_accuracy: 0.7723\n",
            "Epoch 417/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8067 - val_loss: 0.4623 - val_accuracy: 0.7673\n",
            "Epoch 418/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8054 - val_loss: 0.4604 - val_accuracy: 0.7723\n",
            "Epoch 419/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8067 - val_loss: 0.4599 - val_accuracy: 0.7723\n",
            "Epoch 420/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8042 - val_loss: 0.4603 - val_accuracy: 0.7723\n",
            "Epoch 421/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8017 - val_loss: 0.4625 - val_accuracy: 0.7673\n",
            "Epoch 422/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8054 - val_loss: 0.4591 - val_accuracy: 0.7723\n",
            "Epoch 423/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8054 - val_loss: 0.4636 - val_accuracy: 0.7673\n",
            "Epoch 424/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8067 - val_loss: 0.4617 - val_accuracy: 0.7673\n",
            "Epoch 425/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8054 - val_loss: 0.4567 - val_accuracy: 0.7673\n",
            "Epoch 426/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8017 - val_loss: 0.4602 - val_accuracy: 0.7723\n",
            "Epoch 427/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8067 - val_loss: 0.4599 - val_accuracy: 0.7723\n",
            "Epoch 428/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8017 - val_loss: 0.4612 - val_accuracy: 0.7673\n",
            "Epoch 429/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8042 - val_loss: 0.4616 - val_accuracy: 0.7723\n",
            "Epoch 430/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8054 - val_loss: 0.4606 - val_accuracy: 0.7723\n",
            "Epoch 431/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8042 - val_loss: 0.4587 - val_accuracy: 0.7723\n",
            "Epoch 432/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8017 - val_loss: 0.4618 - val_accuracy: 0.7673\n",
            "Epoch 433/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8054 - val_loss: 0.4585 - val_accuracy: 0.7723\n",
            "Epoch 434/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8067 - val_loss: 0.4576 - val_accuracy: 0.7723\n",
            "Epoch 435/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8054 - val_loss: 0.4638 - val_accuracy: 0.7624\n",
            "Epoch 436/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8079 - val_loss: 0.4566 - val_accuracy: 0.7624\n",
            "Epoch 437/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8005 - val_loss: 0.4638 - val_accuracy: 0.7673\n",
            "Epoch 438/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8042 - val_loss: 0.4612 - val_accuracy: 0.7673\n",
            "Epoch 439/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8054 - val_loss: 0.4565 - val_accuracy: 0.7723\n",
            "Epoch 440/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8054 - val_loss: 0.4601 - val_accuracy: 0.7723\n",
            "Epoch 441/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8054 - val_loss: 0.4603 - val_accuracy: 0.7673\n",
            "Epoch 442/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8054 - val_loss: 0.4589 - val_accuracy: 0.7723\n",
            "Epoch 443/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8054 - val_loss: 0.4578 - val_accuracy: 0.7723\n",
            "Epoch 444/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8067 - val_loss: 0.4604 - val_accuracy: 0.7673\n",
            "Epoch 445/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8079 - val_loss: 0.4571 - val_accuracy: 0.7723\n",
            "Epoch 446/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8042 - val_loss: 0.4613 - val_accuracy: 0.7673\n",
            "Epoch 447/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8042 - val_loss: 0.4600 - val_accuracy: 0.7723\n",
            "Epoch 448/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8030 - val_loss: 0.4551 - val_accuracy: 0.7723\n",
            "Epoch 449/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8067 - val_loss: 0.4587 - val_accuracy: 0.7673\n",
            "Epoch 450/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8054 - val_loss: 0.4630 - val_accuracy: 0.7673\n",
            "Epoch 451/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8067 - val_loss: 0.4574 - val_accuracy: 0.7723\n",
            "Epoch 452/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8067 - val_loss: 0.4595 - val_accuracy: 0.7673\n",
            "Epoch 453/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8054 - val_loss: 0.4595 - val_accuracy: 0.7673\n",
            "Epoch 454/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8091 - val_loss: 0.4567 - val_accuracy: 0.7723\n",
            "Epoch 455/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8030 - val_loss: 0.4609 - val_accuracy: 0.7673\n",
            "Epoch 456/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8042 - val_loss: 0.4552 - val_accuracy: 0.7723\n",
            "Epoch 457/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8030 - val_loss: 0.4631 - val_accuracy: 0.7624\n",
            "Epoch 458/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8067 - val_loss: 0.4560 - val_accuracy: 0.7723\n",
            "Epoch 459/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8067 - val_loss: 0.4590 - val_accuracy: 0.7673\n",
            "Epoch 460/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8067 - val_loss: 0.4590 - val_accuracy: 0.7673\n",
            "Epoch 461/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8030 - val_loss: 0.4559 - val_accuracy: 0.7723\n",
            "Epoch 462/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.7993 - val_loss: 0.4529 - val_accuracy: 0.7723\n",
            "Epoch 463/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8067 - val_loss: 0.4630 - val_accuracy: 0.7673\n",
            "Epoch 464/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8067 - val_loss: 0.4622 - val_accuracy: 0.7673\n",
            "Epoch 465/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8067 - val_loss: 0.4549 - val_accuracy: 0.7723\n",
            "Epoch 466/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8091 - val_loss: 0.4572 - val_accuracy: 0.7723\n",
            "Epoch 467/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8079 - val_loss: 0.4560 - val_accuracy: 0.7723\n",
            "Epoch 468/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8030 - val_loss: 0.4548 - val_accuracy: 0.7723\n",
            "Epoch 469/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8030 - val_loss: 0.4573 - val_accuracy: 0.7673\n",
            "Epoch 470/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8091 - val_loss: 0.4583 - val_accuracy: 0.7673\n",
            "Epoch 471/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8042 - val_loss: 0.4538 - val_accuracy: 0.7723\n",
            "Epoch 472/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8017 - val_loss: 0.4540 - val_accuracy: 0.7723\n",
            "Epoch 473/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8067 - val_loss: 0.4588 - val_accuracy: 0.7673\n",
            "Epoch 474/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8042 - val_loss: 0.4553 - val_accuracy: 0.7772\n",
            "Epoch 475/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8042 - val_loss: 0.4597 - val_accuracy: 0.7673\n",
            "Epoch 476/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8067 - val_loss: 0.4542 - val_accuracy: 0.7723\n",
            "Epoch 477/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8042 - val_loss: 0.4545 - val_accuracy: 0.7723\n",
            "Epoch 478/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8067 - val_loss: 0.4568 - val_accuracy: 0.7723\n",
            "Epoch 479/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8017 - val_loss: 0.4570 - val_accuracy: 0.7673\n",
            "Epoch 480/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8091 - val_loss: 0.4567 - val_accuracy: 0.7723\n",
            "Epoch 481/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8042 - val_loss: 0.4571 - val_accuracy: 0.7673\n",
            "Epoch 482/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8030 - val_loss: 0.4584 - val_accuracy: 0.7673\n",
            "Epoch 483/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8103 - val_loss: 0.4571 - val_accuracy: 0.7673\n",
            "Epoch 484/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8030 - val_loss: 0.4580 - val_accuracy: 0.7673\n",
            "Epoch 485/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8017 - val_loss: 0.4571 - val_accuracy: 0.7673\n",
            "Epoch 486/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8030 - val_loss: 0.4573 - val_accuracy: 0.7673\n",
            "Epoch 487/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8017 - val_loss: 0.4558 - val_accuracy: 0.7723\n",
            "Epoch 488/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8067 - val_loss: 0.4535 - val_accuracy: 0.7723\n",
            "Epoch 489/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8042 - val_loss: 0.4545 - val_accuracy: 0.7723\n",
            "Epoch 490/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8091 - val_loss: 0.4573 - val_accuracy: 0.7673\n",
            "Epoch 491/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8042 - val_loss: 0.4562 - val_accuracy: 0.7673\n",
            "Epoch 492/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8091 - val_loss: 0.4567 - val_accuracy: 0.7673\n",
            "Epoch 493/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8042 - val_loss: 0.4560 - val_accuracy: 0.7673\n",
            "Epoch 494/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8054 - val_loss: 0.4535 - val_accuracy: 0.7723\n",
            "Epoch 495/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8017 - val_loss: 0.4528 - val_accuracy: 0.7723\n",
            "Epoch 496/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8079 - val_loss: 0.4509 - val_accuracy: 0.7772\n",
            "Epoch 497/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8017 - val_loss: 0.4609 - val_accuracy: 0.7673\n",
            "Epoch 498/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8067 - val_loss: 0.4576 - val_accuracy: 0.7673\n",
            "Epoch 499/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8067 - val_loss: 0.4596 - val_accuracy: 0.7673\n",
            "Epoch 500/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8067 - val_loss: 0.4556 - val_accuracy: 0.7673\n",
            "Epoch 501/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8079 - val_loss: 0.4542 - val_accuracy: 0.7723\n",
            "Epoch 502/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8067 - val_loss: 0.4537 - val_accuracy: 0.7723\n",
            "Epoch 503/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8067 - val_loss: 0.4532 - val_accuracy: 0.7723\n",
            "Epoch 504/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8067 - val_loss: 0.4557 - val_accuracy: 0.7673\n",
            "Epoch 505/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8042 - val_loss: 0.4550 - val_accuracy: 0.7673\n",
            "Epoch 506/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8030 - val_loss: 0.4529 - val_accuracy: 0.7723\n",
            "Epoch 507/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8091 - val_loss: 0.4526 - val_accuracy: 0.7673\n",
            "Epoch 508/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8067 - val_loss: 0.4548 - val_accuracy: 0.7673\n",
            "Epoch 509/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8067 - val_loss: 0.4611 - val_accuracy: 0.7624\n",
            "Epoch 510/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8054 - val_loss: 0.4569 - val_accuracy: 0.7673\n",
            "Epoch 511/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8091 - val_loss: 0.4499 - val_accuracy: 0.7772\n",
            "Epoch 512/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8030 - val_loss: 0.4538 - val_accuracy: 0.7723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history3.params)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "history = history3\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "Jz_alSMzqoHq",
        "outputId": "0428db00-07fc-449c-b92d-e6a90f109325"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 512, 'steps': 26}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the train set\n",
        "P3 = model3.predict(XTRAIN)\n",
        "accuracy = model3.evaluate(XTRAIN, YTRAIN)\n",
        "my_f1 = f1_score(YTRAIN, P3.round())\n",
        "my_precision = precision_score(YTRAIN, P3.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA2xj7KDqobD",
        "outputId": "555f7ee4-db80-4934-b646-839aa9e66f6c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8079\n",
            "f1:  0.8235294117647058\n",
            "precision:  0.9077306733167082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the validation set\n",
        "P3 = model3.predict(XVALID)\n",
        "accuracy = model3.evaluate(XVALID, YVALID)\n",
        "my_f1 = f1_score(YVALID, P3.round())\n",
        "my_precision = precision_score(YVALID, P3.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGtTma6Bqoq1",
        "outputId": "b2729883-6b1d-4099-e179-c2582d6fe6aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7723\n",
            "f1:  0.7946428571428571\n",
            "precision:  0.898989898989899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4= Sequential() # multi-layer network\n",
        "model4.add(Dense(4, input_dim= len(XTRAIN[0,:]), activation = 'relu' ))\n",
        "model4.add(Dense(1, activation = 'sigmoid')) \n",
        "model4.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics='accuracy' )\n",
        "# activation and optimizer are changing in order to find highest validation accuracy"
      ],
      "metadata": {
        "id": "HrPO8OLPqpEG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history4 = model4.fit(x= XTRAIN, y=YTRAIN, validation_data = (XVALID, YVALID), epochs = 256, verbose = 1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2SOTAr9zs_f",
        "outputId": "9aaeeca4-3d7f-48a0-9d0f-3fa81886f979"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "26/26 [==============================] - 1s 8ms/step - loss: 0.6774 - accuracy: 0.5727 - val_loss: 0.6786 - val_accuracy: 0.5891\n",
            "Epoch 2/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6170 - val_loss: 0.6706 - val_accuracy: 0.5990\n",
            "Epoch 3/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6441 - val_loss: 0.6628 - val_accuracy: 0.6337\n",
            "Epoch 4/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6638 - val_loss: 0.6553 - val_accuracy: 0.6386\n",
            "Epoch 5/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6749 - val_loss: 0.6481 - val_accuracy: 0.6584\n",
            "Epoch 6/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6872 - val_loss: 0.6414 - val_accuracy: 0.6584\n",
            "Epoch 7/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6884 - val_loss: 0.6355 - val_accuracy: 0.6733\n",
            "Epoch 8/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6884 - val_loss: 0.6293 - val_accuracy: 0.6782\n",
            "Epoch 9/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.6946 - val_loss: 0.6236 - val_accuracy: 0.6832\n",
            "Epoch 10/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6970 - val_loss: 0.6184 - val_accuracy: 0.6881\n",
            "Epoch 11/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7020 - val_loss: 0.6130 - val_accuracy: 0.6881\n",
            "Epoch 12/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7094 - val_loss: 0.6076 - val_accuracy: 0.6881\n",
            "Epoch 13/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7094 - val_loss: 0.6025 - val_accuracy: 0.6980\n",
            "Epoch 14/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7069 - val_loss: 0.5978 - val_accuracy: 0.6980\n",
            "Epoch 15/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7069 - val_loss: 0.5930 - val_accuracy: 0.6980\n",
            "Epoch 16/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7069 - val_loss: 0.5886 - val_accuracy: 0.6980\n",
            "Epoch 17/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7069 - val_loss: 0.5845 - val_accuracy: 0.7030\n",
            "Epoch 18/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7069 - val_loss: 0.5805 - val_accuracy: 0.7079\n",
            "Epoch 19/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7057 - val_loss: 0.5769 - val_accuracy: 0.6881\n",
            "Epoch 20/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7094 - val_loss: 0.5736 - val_accuracy: 0.6782\n",
            "Epoch 21/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7106 - val_loss: 0.5705 - val_accuracy: 0.6832\n",
            "Epoch 22/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7106 - val_loss: 0.5676 - val_accuracy: 0.6832\n",
            "Epoch 23/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7069 - val_loss: 0.5648 - val_accuracy: 0.6782\n",
            "Epoch 24/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7131 - val_loss: 0.5625 - val_accuracy: 0.6881\n",
            "Epoch 25/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7155 - val_loss: 0.5605 - val_accuracy: 0.6832\n",
            "Epoch 26/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7167 - val_loss: 0.5583 - val_accuracy: 0.6832\n",
            "Epoch 27/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7266 - val_loss: 0.5564 - val_accuracy: 0.6832\n",
            "Epoch 28/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7106 - val_loss: 0.5546 - val_accuracy: 0.6782\n",
            "Epoch 29/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7155 - val_loss: 0.5528 - val_accuracy: 0.6782\n",
            "Epoch 30/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7057 - val_loss: 0.5513 - val_accuracy: 0.6782\n",
            "Epoch 31/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7094 - val_loss: 0.5505 - val_accuracy: 0.6931\n",
            "Epoch 32/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7131 - val_loss: 0.5488 - val_accuracy: 0.6931\n",
            "Epoch 33/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7180 - val_loss: 0.5477 - val_accuracy: 0.6980\n",
            "Epoch 34/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7118 - val_loss: 0.5464 - val_accuracy: 0.6980\n",
            "Epoch 35/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7106 - val_loss: 0.5455 - val_accuracy: 0.7079\n",
            "Epoch 36/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7094 - val_loss: 0.5443 - val_accuracy: 0.6980\n",
            "Epoch 37/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7081 - val_loss: 0.5436 - val_accuracy: 0.6931\n",
            "Epoch 38/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7118 - val_loss: 0.5430 - val_accuracy: 0.6980\n",
            "Epoch 39/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7081 - val_loss: 0.5421 - val_accuracy: 0.6931\n",
            "Epoch 40/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7069 - val_loss: 0.5414 - val_accuracy: 0.6980\n",
            "Epoch 41/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7081 - val_loss: 0.5406 - val_accuracy: 0.6931\n",
            "Epoch 42/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7081 - val_loss: 0.5402 - val_accuracy: 0.6881\n",
            "Epoch 43/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7057 - val_loss: 0.5394 - val_accuracy: 0.6931\n",
            "Epoch 44/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7094 - val_loss: 0.5392 - val_accuracy: 0.6832\n",
            "Epoch 45/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7069 - val_loss: 0.5384 - val_accuracy: 0.6832\n",
            "Epoch 46/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7069 - val_loss: 0.5375 - val_accuracy: 0.6881\n",
            "Epoch 47/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7106 - val_loss: 0.5369 - val_accuracy: 0.6881\n",
            "Epoch 48/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7081 - val_loss: 0.5370 - val_accuracy: 0.6832\n",
            "Epoch 49/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7081 - val_loss: 0.5363 - val_accuracy: 0.6832\n",
            "Epoch 50/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7081 - val_loss: 0.5359 - val_accuracy: 0.6832\n",
            "Epoch 51/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7143 - val_loss: 0.5359 - val_accuracy: 0.6881\n",
            "Epoch 52/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7167 - val_loss: 0.5354 - val_accuracy: 0.6881\n",
            "Epoch 53/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7143 - val_loss: 0.5350 - val_accuracy: 0.6881\n",
            "Epoch 54/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7155 - val_loss: 0.5345 - val_accuracy: 0.6881\n",
            "Epoch 55/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7241 - val_loss: 0.5345 - val_accuracy: 0.6931\n",
            "Epoch 56/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7155 - val_loss: 0.5340 - val_accuracy: 0.6931\n",
            "Epoch 57/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7266 - val_loss: 0.5338 - val_accuracy: 0.6931\n",
            "Epoch 58/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7266 - val_loss: 0.5334 - val_accuracy: 0.6980\n",
            "Epoch 59/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7278 - val_loss: 0.5330 - val_accuracy: 0.6980\n",
            "Epoch 60/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7254 - val_loss: 0.5329 - val_accuracy: 0.6980\n",
            "Epoch 61/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7254 - val_loss: 0.5326 - val_accuracy: 0.6980\n",
            "Epoch 62/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7278 - val_loss: 0.5329 - val_accuracy: 0.6980\n",
            "Epoch 63/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7266 - val_loss: 0.5329 - val_accuracy: 0.6980\n",
            "Epoch 64/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7266 - val_loss: 0.5321 - val_accuracy: 0.6980\n",
            "Epoch 65/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7278 - val_loss: 0.5323 - val_accuracy: 0.6931\n",
            "Epoch 66/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7266 - val_loss: 0.5317 - val_accuracy: 0.6980\n",
            "Epoch 67/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7266 - val_loss: 0.5320 - val_accuracy: 0.7030\n",
            "Epoch 68/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7254 - val_loss: 0.5310 - val_accuracy: 0.6931\n",
            "Epoch 69/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7254 - val_loss: 0.5311 - val_accuracy: 0.7030\n",
            "Epoch 70/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7266 - val_loss: 0.5309 - val_accuracy: 0.7030\n",
            "Epoch 71/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7278 - val_loss: 0.5310 - val_accuracy: 0.7030\n",
            "Epoch 72/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7291 - val_loss: 0.5307 - val_accuracy: 0.7030\n",
            "Epoch 73/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7291 - val_loss: 0.5307 - val_accuracy: 0.7030\n",
            "Epoch 74/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7278 - val_loss: 0.5299 - val_accuracy: 0.7030\n",
            "Epoch 75/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7365 - val_loss: 0.5307 - val_accuracy: 0.7129\n",
            "Epoch 76/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7340 - val_loss: 0.5302 - val_accuracy: 0.7030\n",
            "Epoch 77/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7315 - val_loss: 0.5300 - val_accuracy: 0.7079\n",
            "Epoch 78/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7352 - val_loss: 0.5303 - val_accuracy: 0.7079\n",
            "Epoch 79/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7389 - val_loss: 0.5302 - val_accuracy: 0.7129\n",
            "Epoch 80/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7365 - val_loss: 0.5299 - val_accuracy: 0.7079\n",
            "Epoch 81/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7340 - val_loss: 0.5298 - val_accuracy: 0.7079\n",
            "Epoch 82/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7365 - val_loss: 0.5301 - val_accuracy: 0.7129\n",
            "Epoch 83/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7315 - val_loss: 0.5293 - val_accuracy: 0.7030\n",
            "Epoch 84/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7315 - val_loss: 0.5300 - val_accuracy: 0.7129\n",
            "Epoch 85/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7352 - val_loss: 0.5299 - val_accuracy: 0.7079\n",
            "Epoch 86/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7365 - val_loss: 0.5296 - val_accuracy: 0.7079\n",
            "Epoch 87/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7340 - val_loss: 0.5302 - val_accuracy: 0.7079\n",
            "Epoch 88/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7365 - val_loss: 0.5304 - val_accuracy: 0.7030\n",
            "Epoch 89/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7389 - val_loss: 0.5308 - val_accuracy: 0.6980\n",
            "Epoch 90/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7401 - val_loss: 0.5310 - val_accuracy: 0.6980\n",
            "Epoch 91/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7389 - val_loss: 0.5303 - val_accuracy: 0.7030\n",
            "Epoch 92/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7365 - val_loss: 0.5302 - val_accuracy: 0.7030\n",
            "Epoch 93/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7389 - val_loss: 0.5305 - val_accuracy: 0.7030\n",
            "Epoch 94/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7377 - val_loss: 0.5300 - val_accuracy: 0.7030\n",
            "Epoch 95/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7365 - val_loss: 0.5304 - val_accuracy: 0.6980\n",
            "Epoch 96/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7389 - val_loss: 0.5304 - val_accuracy: 0.6980\n",
            "Epoch 97/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7377 - val_loss: 0.5304 - val_accuracy: 0.6980\n",
            "Epoch 98/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7365 - val_loss: 0.5297 - val_accuracy: 0.6980\n",
            "Epoch 99/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7377 - val_loss: 0.5298 - val_accuracy: 0.7030\n",
            "Epoch 100/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7352 - val_loss: 0.5299 - val_accuracy: 0.6980\n",
            "Epoch 101/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7352 - val_loss: 0.5295 - val_accuracy: 0.6980\n",
            "Epoch 102/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7352 - val_loss: 0.5297 - val_accuracy: 0.6931\n",
            "Epoch 103/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7365 - val_loss: 0.5294 - val_accuracy: 0.6980\n",
            "Epoch 104/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7377 - val_loss: 0.5295 - val_accuracy: 0.6931\n",
            "Epoch 105/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7352 - val_loss: 0.5293 - val_accuracy: 0.6980\n",
            "Epoch 106/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7352 - val_loss: 0.5298 - val_accuracy: 0.6931\n",
            "Epoch 107/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7352 - val_loss: 0.5294 - val_accuracy: 0.6931\n",
            "Epoch 108/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7340 - val_loss: 0.5294 - val_accuracy: 0.6980\n",
            "Epoch 109/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7340 - val_loss: 0.5290 - val_accuracy: 0.7129\n",
            "Epoch 110/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7414 - val_loss: 0.5298 - val_accuracy: 0.6980\n",
            "Epoch 111/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7352 - val_loss: 0.5299 - val_accuracy: 0.7030\n",
            "Epoch 112/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7365 - val_loss: 0.5295 - val_accuracy: 0.6881\n",
            "Epoch 113/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7377 - val_loss: 0.5290 - val_accuracy: 0.7030\n",
            "Epoch 114/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7352 - val_loss: 0.5296 - val_accuracy: 0.7030\n",
            "Epoch 115/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7389 - val_loss: 0.5288 - val_accuracy: 0.7129\n",
            "Epoch 116/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7389 - val_loss: 0.5288 - val_accuracy: 0.7030\n",
            "Epoch 117/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7377 - val_loss: 0.5292 - val_accuracy: 0.7030\n",
            "Epoch 118/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7414 - val_loss: 0.5285 - val_accuracy: 0.7129\n",
            "Epoch 119/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7365 - val_loss: 0.5294 - val_accuracy: 0.7030\n",
            "Epoch 120/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7352 - val_loss: 0.5293 - val_accuracy: 0.7030\n",
            "Epoch 121/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7377 - val_loss: 0.5285 - val_accuracy: 0.7129\n",
            "Epoch 122/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7365 - val_loss: 0.5290 - val_accuracy: 0.7030\n",
            "Epoch 123/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7340 - val_loss: 0.5290 - val_accuracy: 0.7030\n",
            "Epoch 124/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7401 - val_loss: 0.5283 - val_accuracy: 0.7129\n",
            "Epoch 125/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7315 - val_loss: 0.5292 - val_accuracy: 0.6980\n",
            "Epoch 126/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7389 - val_loss: 0.5287 - val_accuracy: 0.7178\n",
            "Epoch 127/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7365 - val_loss: 0.5288 - val_accuracy: 0.7030\n",
            "Epoch 128/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7352 - val_loss: 0.5292 - val_accuracy: 0.6980\n",
            "Epoch 129/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7340 - val_loss: 0.5290 - val_accuracy: 0.6980\n",
            "Epoch 130/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7389 - val_loss: 0.5283 - val_accuracy: 0.7178\n",
            "Epoch 131/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7340 - val_loss: 0.5288 - val_accuracy: 0.6980\n",
            "Epoch 132/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7352 - val_loss: 0.5295 - val_accuracy: 0.6980\n",
            "Epoch 133/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7340 - val_loss: 0.5291 - val_accuracy: 0.6980\n",
            "Epoch 134/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7340 - val_loss: 0.5291 - val_accuracy: 0.6980\n",
            "Epoch 135/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7389 - val_loss: 0.5296 - val_accuracy: 0.6980\n",
            "Epoch 136/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7340 - val_loss: 0.5289 - val_accuracy: 0.6980\n",
            "Epoch 137/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7352 - val_loss: 0.5299 - val_accuracy: 0.6980\n",
            "Epoch 138/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7365 - val_loss: 0.5296 - val_accuracy: 0.6980\n",
            "Epoch 139/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7389 - val_loss: 0.5299 - val_accuracy: 0.6980\n",
            "Epoch 140/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7414 - val_loss: 0.5301 - val_accuracy: 0.6980\n",
            "Epoch 141/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7365 - val_loss: 0.5288 - val_accuracy: 0.6980\n",
            "Epoch 142/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7352 - val_loss: 0.5290 - val_accuracy: 0.6980\n",
            "Epoch 143/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7365 - val_loss: 0.5295 - val_accuracy: 0.6980\n",
            "Epoch 144/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7389 - val_loss: 0.5293 - val_accuracy: 0.6980\n",
            "Epoch 145/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7377 - val_loss: 0.5294 - val_accuracy: 0.6980\n",
            "Epoch 146/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7377 - val_loss: 0.5293 - val_accuracy: 0.6980\n",
            "Epoch 147/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7377 - val_loss: 0.5292 - val_accuracy: 0.6980\n",
            "Epoch 148/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7389 - val_loss: 0.5297 - val_accuracy: 0.6980\n",
            "Epoch 149/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7377 - val_loss: 0.5291 - val_accuracy: 0.6980\n",
            "Epoch 150/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7438 - val_loss: 0.5297 - val_accuracy: 0.7030\n",
            "Epoch 151/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7488 - val_loss: 0.5298 - val_accuracy: 0.6980\n",
            "Epoch 152/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7463 - val_loss: 0.5289 - val_accuracy: 0.6980\n",
            "Epoch 153/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7475 - val_loss: 0.5299 - val_accuracy: 0.7030\n",
            "Epoch 154/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7512 - val_loss: 0.5296 - val_accuracy: 0.6931\n",
            "Epoch 155/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7574 - val_loss: 0.5303 - val_accuracy: 0.6980\n",
            "Epoch 156/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7586 - val_loss: 0.5297 - val_accuracy: 0.6931\n",
            "Epoch 157/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7525 - val_loss: 0.5292 - val_accuracy: 0.6980\n",
            "Epoch 158/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7512 - val_loss: 0.5283 - val_accuracy: 0.6832\n",
            "Epoch 159/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7525 - val_loss: 0.5290 - val_accuracy: 0.6881\n",
            "Epoch 160/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7537 - val_loss: 0.5282 - val_accuracy: 0.6881\n",
            "Epoch 161/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7525 - val_loss: 0.5281 - val_accuracy: 0.6881\n",
            "Epoch 162/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7525 - val_loss: 0.5281 - val_accuracy: 0.6980\n",
            "Epoch 163/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7525 - val_loss: 0.5282 - val_accuracy: 0.6980\n",
            "Epoch 164/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7549 - val_loss: 0.5283 - val_accuracy: 0.6881\n",
            "Epoch 165/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7537 - val_loss: 0.5273 - val_accuracy: 0.6931\n",
            "Epoch 166/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7525 - val_loss: 0.5276 - val_accuracy: 0.6980\n",
            "Epoch 167/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7525 - val_loss: 0.5275 - val_accuracy: 0.6980\n",
            "Epoch 168/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7525 - val_loss: 0.5273 - val_accuracy: 0.6980\n",
            "Epoch 169/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7549 - val_loss: 0.5281 - val_accuracy: 0.6881\n",
            "Epoch 170/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7549 - val_loss: 0.5275 - val_accuracy: 0.6881\n",
            "Epoch 171/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7525 - val_loss: 0.5268 - val_accuracy: 0.6931\n",
            "Epoch 172/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7525 - val_loss: 0.5275 - val_accuracy: 0.6881\n",
            "Epoch 173/256\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7562 - val_loss: 0.5275 - val_accuracy: 0.6881\n",
            "Epoch 174/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7525 - val_loss: 0.5271 - val_accuracy: 0.6980\n",
            "Epoch 175/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7525 - val_loss: 0.5273 - val_accuracy: 0.6881\n",
            "Epoch 176/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7549 - val_loss: 0.5272 - val_accuracy: 0.6881\n",
            "Epoch 177/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7562 - val_loss: 0.5273 - val_accuracy: 0.6931\n",
            "Epoch 178/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7562 - val_loss: 0.5271 - val_accuracy: 0.6881\n",
            "Epoch 179/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7562 - val_loss: 0.5271 - val_accuracy: 0.6931\n",
            "Epoch 180/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7574 - val_loss: 0.5272 - val_accuracy: 0.6931\n",
            "Epoch 181/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7574 - val_loss: 0.5269 - val_accuracy: 0.6931\n",
            "Epoch 182/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7537 - val_loss: 0.5270 - val_accuracy: 0.6931\n",
            "Epoch 183/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7562 - val_loss: 0.5266 - val_accuracy: 0.6881\n",
            "Epoch 184/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7599 - val_loss: 0.5275 - val_accuracy: 0.6931\n",
            "Epoch 185/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7574 - val_loss: 0.5270 - val_accuracy: 0.6931\n",
            "Epoch 186/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7574 - val_loss: 0.5271 - val_accuracy: 0.6931\n",
            "Epoch 187/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7574 - val_loss: 0.5274 - val_accuracy: 0.6931\n",
            "Epoch 188/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7599 - val_loss: 0.5277 - val_accuracy: 0.6931\n",
            "Epoch 189/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7611 - val_loss: 0.5277 - val_accuracy: 0.6931\n",
            "Epoch 190/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7611 - val_loss: 0.5274 - val_accuracy: 0.6931\n",
            "Epoch 191/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7611 - val_loss: 0.5271 - val_accuracy: 0.6931\n",
            "Epoch 192/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7599 - val_loss: 0.5272 - val_accuracy: 0.6931\n",
            "Epoch 193/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7586 - val_loss: 0.5264 - val_accuracy: 0.6931\n",
            "Epoch 194/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7574 - val_loss: 0.5268 - val_accuracy: 0.6931\n",
            "Epoch 195/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7586 - val_loss: 0.5269 - val_accuracy: 0.6931\n",
            "Epoch 196/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7599 - val_loss: 0.5274 - val_accuracy: 0.6931\n",
            "Epoch 197/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7599 - val_loss: 0.5268 - val_accuracy: 0.6931\n",
            "Epoch 198/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7611 - val_loss: 0.5272 - val_accuracy: 0.6931\n",
            "Epoch 199/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7611 - val_loss: 0.5265 - val_accuracy: 0.6931\n",
            "Epoch 200/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7599 - val_loss: 0.5269 - val_accuracy: 0.6931\n",
            "Epoch 201/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7599 - val_loss: 0.5266 - val_accuracy: 0.6931\n",
            "Epoch 202/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7586 - val_loss: 0.5268 - val_accuracy: 0.6931\n",
            "Epoch 203/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7611 - val_loss: 0.5269 - val_accuracy: 0.6931\n",
            "Epoch 204/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7599 - val_loss: 0.5264 - val_accuracy: 0.6931\n",
            "Epoch 205/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7599 - val_loss: 0.5264 - val_accuracy: 0.6931\n",
            "Epoch 206/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7586 - val_loss: 0.5264 - val_accuracy: 0.6980\n",
            "Epoch 207/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7549 - val_loss: 0.5266 - val_accuracy: 0.6980\n",
            "Epoch 208/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7574 - val_loss: 0.5262 - val_accuracy: 0.6931\n",
            "Epoch 209/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7611 - val_loss: 0.5267 - val_accuracy: 0.6980\n",
            "Epoch 210/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7611 - val_loss: 0.5267 - val_accuracy: 0.6980\n",
            "Epoch 211/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7611 - val_loss: 0.5270 - val_accuracy: 0.6980\n",
            "Epoch 212/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7611 - val_loss: 0.5265 - val_accuracy: 0.6980\n",
            "Epoch 213/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7623 - val_loss: 0.5270 - val_accuracy: 0.6980\n",
            "Epoch 214/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7611 - val_loss: 0.5267 - val_accuracy: 0.6980\n",
            "Epoch 215/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7599 - val_loss: 0.5267 - val_accuracy: 0.6980\n",
            "Epoch 216/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7623 - val_loss: 0.5270 - val_accuracy: 0.7030\n",
            "Epoch 217/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7648 - val_loss: 0.5266 - val_accuracy: 0.6980\n",
            "Epoch 218/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7635 - val_loss: 0.5268 - val_accuracy: 0.7030\n",
            "Epoch 219/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7599 - val_loss: 0.5266 - val_accuracy: 0.6980\n",
            "Epoch 220/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7599 - val_loss: 0.5266 - val_accuracy: 0.6980\n",
            "Epoch 221/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7599 - val_loss: 0.5266 - val_accuracy: 0.7030\n",
            "Epoch 222/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7611 - val_loss: 0.5264 - val_accuracy: 0.6980\n",
            "Epoch 223/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7635 - val_loss: 0.5268 - val_accuracy: 0.7030\n",
            "Epoch 224/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7599 - val_loss: 0.5263 - val_accuracy: 0.6980\n",
            "Epoch 225/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7611 - val_loss: 0.5267 - val_accuracy: 0.7030\n",
            "Epoch 226/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7599 - val_loss: 0.5268 - val_accuracy: 0.6980\n",
            "Epoch 227/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7635 - val_loss: 0.5270 - val_accuracy: 0.7030\n",
            "Epoch 228/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7685 - val_loss: 0.5267 - val_accuracy: 0.7030\n",
            "Epoch 229/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7623 - val_loss: 0.5262 - val_accuracy: 0.6980\n",
            "Epoch 230/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7623 - val_loss: 0.5264 - val_accuracy: 0.6980\n",
            "Epoch 231/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7660 - val_loss: 0.5264 - val_accuracy: 0.7030\n",
            "Epoch 232/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7660 - val_loss: 0.5263 - val_accuracy: 0.7030\n",
            "Epoch 233/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7623 - val_loss: 0.5263 - val_accuracy: 0.7030\n",
            "Epoch 234/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7709 - val_loss: 0.5272 - val_accuracy: 0.7030\n",
            "Epoch 235/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7722 - val_loss: 0.5270 - val_accuracy: 0.7030\n",
            "Epoch 236/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7697 - val_loss: 0.5263 - val_accuracy: 0.7030\n",
            "Epoch 237/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7709 - val_loss: 0.5270 - val_accuracy: 0.7030\n",
            "Epoch 238/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7709 - val_loss: 0.5266 - val_accuracy: 0.7030\n",
            "Epoch 239/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7685 - val_loss: 0.5266 - val_accuracy: 0.7030\n",
            "Epoch 240/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7709 - val_loss: 0.5271 - val_accuracy: 0.7030\n",
            "Epoch 241/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7709 - val_loss: 0.5265 - val_accuracy: 0.7030\n",
            "Epoch 242/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7697 - val_loss: 0.5269 - val_accuracy: 0.7030\n",
            "Epoch 243/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7709 - val_loss: 0.5267 - val_accuracy: 0.7030\n",
            "Epoch 244/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7709 - val_loss: 0.5266 - val_accuracy: 0.7030\n",
            "Epoch 245/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7709 - val_loss: 0.5266 - val_accuracy: 0.7030\n",
            "Epoch 246/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7709 - val_loss: 0.5268 - val_accuracy: 0.7030\n",
            "Epoch 247/256\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7697 - val_loss: 0.5260 - val_accuracy: 0.7030\n",
            "Epoch 248/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7697 - val_loss: 0.5268 - val_accuracy: 0.7030\n",
            "Epoch 249/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7709 - val_loss: 0.5266 - val_accuracy: 0.7030\n",
            "Epoch 250/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7709 - val_loss: 0.5267 - val_accuracy: 0.7030\n",
            "Epoch 251/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7709 - val_loss: 0.5268 - val_accuracy: 0.7030\n",
            "Epoch 252/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7709 - val_loss: 0.5269 - val_accuracy: 0.7030\n",
            "Epoch 253/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7709 - val_loss: 0.5268 - val_accuracy: 0.7030\n",
            "Epoch 254/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7660 - val_loss: 0.5263 - val_accuracy: 0.7030\n",
            "Epoch 255/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7709 - val_loss: 0.5270 - val_accuracy: 0.7030\n",
            "Epoch 256/256\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7697 - val_loss: 0.5265 - val_accuracy: 0.7030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history4.params)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "history = history4\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "8NyRuZzzzw8j",
        "outputId": "a891ff22-0d0f-4642-ca3f-f75b443d7acf"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 256, 'steps': 26}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the train set\n",
        "P4 = model4.predict(XTRAIN)\n",
        "accuracy = model4.evaluate(XTRAIN, YTRAIN)\n",
        "my_f1 = f1_score(YTRAIN, P4.round())\n",
        "my_precision = precision_score(YTRAIN, P4.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Y5mw0fzyxM",
        "outputId": "ed71e46c-14af-496f-f336-3e7d4da852a1"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7660\n",
            "f1:  0.7898230088495576\n",
            "precision:  0.8602409638554217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the validation set\n",
        "P4 = model4.predict(XVALID)\n",
        "accuracy = model4.evaluate(XVALID, YVALID)\n",
        "my_f1 = f1_score(YVALID, P4.round())\n",
        "my_precision = precision_score(YVALID, P4.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_fWmUJ9z0bV",
        "outputId": "3fef21bc-095c-4150-e959-d0db3dec2bef"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7079\n",
            "f1:  0.748936170212766\n",
            "precision:  0.7586206896551724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# File name must be in quotes\n",
        "callback_a = ModelCheckpoint(filepath = 'Maternal_Health_Risk_Data_Set.csv', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "# The patience value can be 10, 20, 100, etc. depending on when your model starts to overfit\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)"
      ],
      "metadata": {
        "id": "sdI74In-brKL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), batch_size=1,epochs=50, callbacks = [callback_a, callback_b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmbBTicUb2_w",
        "outputId": "e5939e4f-3daa-45d8-efed-b616d9e334ad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "793/812 [============================>.] - ETA: 0s - loss: 0.4341 - accuracy: 0.7680\n",
            "Epoch 1: val_loss improved from inf to 0.54722, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 3ms/step - loss: 0.4307 - accuracy: 0.7709 - val_loss: 0.5472 - val_accuracy: 0.7079\n",
            "Epoch 2/50\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.7963\n",
            "Epoch 2: val_loss improved from 0.54722 to 0.54328, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4162 - accuracy: 0.7943 - val_loss: 0.5433 - val_accuracy: 0.6931\n",
            "Epoch 3/50\n",
            "804/812 [============================>.] - ETA: 0s - loss: 0.4131 - accuracy: 0.7998\n",
            "Epoch 3: val_loss improved from 0.54328 to 0.54295, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4116 - accuracy: 0.8005 - val_loss: 0.5430 - val_accuracy: 0.6980\n",
            "Epoch 4/50\n",
            "785/812 [============================>.] - ETA: 0s - loss: 0.4104 - accuracy: 0.7987\n",
            "Epoch 4: val_loss improved from 0.54295 to 0.52887, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 3ms/step - loss: 0.4121 - accuracy: 0.7968 - val_loss: 0.5289 - val_accuracy: 0.6980\n",
            "Epoch 5/50\n",
            "800/812 [============================>.] - ETA: 0s - loss: 0.4153 - accuracy: 0.7962\n",
            "Epoch 5: val_loss did not improve from 0.52887\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4120 - accuracy: 0.7993 - val_loss: 0.5332 - val_accuracy: 0.7079\n",
            "Epoch 6/50\n",
            "805/812 [============================>.] - ETA: 0s - loss: 0.4112 - accuracy: 0.8012\n",
            "Epoch 6: val_loss improved from 0.52887 to 0.52300, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 3ms/step - loss: 0.4102 - accuracy: 0.8017 - val_loss: 0.5230 - val_accuracy: 0.7079\n",
            "Epoch 7/50\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4123 - accuracy: 0.7980\n",
            "Epoch 7: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4120 - accuracy: 0.7980 - val_loss: 0.5259 - val_accuracy: 0.7079\n",
            "Epoch 8/50\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4119 - accuracy: 0.8000\n",
            "Epoch 8: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 3ms/step - loss: 0.4113 - accuracy: 0.8005 - val_loss: 0.5246 - val_accuracy: 0.7079\n",
            "Epoch 9/50\n",
            "794/812 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.7972\n",
            "Epoch 9: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4134 - accuracy: 0.7980 - val_loss: 0.5308 - val_accuracy: 0.6881\n",
            "Epoch 10/50\n",
            "806/812 [============================>.] - ETA: 0s - loss: 0.4099 - accuracy: 0.7965\n",
            "Epoch 10: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4108 - accuracy: 0.7956 - val_loss: 0.5439 - val_accuracy: 0.7079\n",
            "Epoch 11/50\n",
            "803/812 [============================>.] - ETA: 0s - loss: 0.4097 - accuracy: 0.7995\n",
            "Epoch 11: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4115 - accuracy: 0.7980 - val_loss: 0.5237 - val_accuracy: 0.7178\n",
            "Epoch 12/50\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4101 - accuracy: 0.8049\n",
            "Epoch 12: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4091 - accuracy: 0.8054 - val_loss: 0.5470 - val_accuracy: 0.6832\n",
            "Epoch 13/50\n",
            "788/812 [============================>.] - ETA: 0s - loss: 0.4146 - accuracy: 0.7906\n",
            "Epoch 13: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4133 - accuracy: 0.7906 - val_loss: 0.5324 - val_accuracy: 0.6980\n",
            "Epoch 14/50\n",
            "790/812 [============================>.] - ETA: 0s - loss: 0.4142 - accuracy: 0.7937\n",
            "Epoch 14: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 3ms/step - loss: 0.4103 - accuracy: 0.7968 - val_loss: 0.5341 - val_accuracy: 0.6931\n",
            "Epoch 15/50\n",
            "793/812 [============================>.] - ETA: 0s - loss: 0.4061 - accuracy: 0.7970\n",
            "Epoch 15: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4107 - accuracy: 0.7943 - val_loss: 0.5299 - val_accuracy: 0.6931\n",
            "Epoch 16/50\n",
            "802/812 [============================>.] - ETA: 0s - loss: 0.4080 - accuracy: 0.8030\n",
            "Epoch 16: val_loss did not improve from 0.52300\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4088 - accuracy: 0.8017 - val_loss: 0.5259 - val_accuracy: 0.6881\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File name must be in quotes\n",
        "model3.load_weights('Maternal_Health_Risk_Data_Set.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UYU4aXab5rx",
        "outputId": "acb7a4e4-32d8-41b1-bde2-d1b985a39c94"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f01aba86ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history3.params)\n",
        "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
        "plt.plot(history.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "ew231bKueJG-",
        "outputId": "a671701e-e09f-4f8f-be9a-17cd0aab8e12"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 512, 'steps': 26}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graduate student requirement question 1\n",
        "\n",
        "XV = dataset[:index_20percent, :]\n",
        "YV = dataset[:index_20percent, -1]\n",
        "XT = dataset[index_20percent:, :]\n",
        "YT = dataset[index_20percent:, -1]\n",
        "# nomalization\n",
        "# XT -= mean\n",
        "# XT /= range\n",
        "# XV -= mean\n",
        "# XV /= range"
      ],
      "metadata": {
        "id": "xl3mQhMku-yY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = Sequential() # Logistic regression model\n",
        "model5.add(Dense(1, input_dim=len(XT[0,:]), activation='sigmoid'))\n",
        "model5.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics='accuracy' )\n",
        "# activation and optimizer are changing in order to find highest validation accuracy"
      ],
      "metadata": {
        "id": "NAOHT3OEZAKM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model5.fit(x= XT, y=YT, validation_data = (XV, YV), epochs = 512, verbose = 1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqoC7eVNZkbR",
        "outputId": "9e3ee915-9e1a-408a-896e-fd08f0f10cdd"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/512\n",
            "26/26 [==============================] - 1s 12ms/step - loss: 0.9457 - accuracy: 0.2167 - val_loss: 0.9493 - val_accuracy: 0.2327\n",
            "Epoch 2/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.9271 - accuracy: 0.2044 - val_loss: 0.9320 - val_accuracy: 0.2376\n",
            "Epoch 3/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.9094 - accuracy: 0.2069 - val_loss: 0.9158 - val_accuracy: 0.2376\n",
            "Epoch 4/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.8923 - accuracy: 0.2044 - val_loss: 0.9006 - val_accuracy: 0.2327\n",
            "Epoch 5/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8762 - accuracy: 0.2094 - val_loss: 0.8849 - val_accuracy: 0.2277\n",
            "Epoch 6/512\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.8601 - accuracy: 0.2340 - val_loss: 0.8706 - val_accuracy: 0.2327\n",
            "Epoch 7/512\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.8450 - accuracy: 0.2574 - val_loss: 0.8561 - val_accuracy: 0.2673\n",
            "Epoch 8/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.8303 - accuracy: 0.3005 - val_loss: 0.8425 - val_accuracy: 0.2921\n",
            "Epoch 9/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.8164 - accuracy: 0.3165 - val_loss: 0.8296 - val_accuracy: 0.2921\n",
            "Epoch 10/512\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.8030 - accuracy: 0.3325 - val_loss: 0.8174 - val_accuracy: 0.3069\n",
            "Epoch 11/512\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7903 - accuracy: 0.3424 - val_loss: 0.8053 - val_accuracy: 0.3168\n",
            "Epoch 12/512\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.7781 - accuracy: 0.3559 - val_loss: 0.7935 - val_accuracy: 0.3317\n",
            "Epoch 13/512\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.7664 - accuracy: 0.3645 - val_loss: 0.7825 - val_accuracy: 0.3515\n",
            "Epoch 14/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.3867 - val_loss: 0.7721 - val_accuracy: 0.3762\n",
            "Epoch 15/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.4249 - val_loss: 0.7620 - val_accuracy: 0.4356\n",
            "Epoch 16/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.4495 - val_loss: 0.7521 - val_accuracy: 0.4257\n",
            "Epoch 17/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.4544 - val_loss: 0.7428 - val_accuracy: 0.4406\n",
            "Epoch 18/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.4667 - val_loss: 0.7336 - val_accuracy: 0.4505\n",
            "Epoch 19/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7060 - accuracy: 0.4692 - val_loss: 0.7251 - val_accuracy: 0.4505\n",
            "Epoch 20/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.4901 - val_loss: 0.7166 - val_accuracy: 0.4604\n",
            "Epoch 21/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5197 - val_loss: 0.7086 - val_accuracy: 0.5099\n",
            "Epoch 22/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5665 - val_loss: 0.7007 - val_accuracy: 0.5248\n",
            "Epoch 23/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.5862 - val_loss: 0.6933 - val_accuracy: 0.5495\n",
            "Epoch 24/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.5973 - val_loss: 0.6859 - val_accuracy: 0.5495\n",
            "Epoch 25/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.5985 - val_loss: 0.6788 - val_accuracy: 0.5545\n",
            "Epoch 26/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6071 - val_loss: 0.6721 - val_accuracy: 0.5644\n",
            "Epoch 27/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6133 - val_loss: 0.6654 - val_accuracy: 0.5594\n",
            "Epoch 28/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6195 - val_loss: 0.6588 - val_accuracy: 0.5545\n",
            "Epoch 29/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6305 - val_loss: 0.6526 - val_accuracy: 0.5693\n",
            "Epoch 30/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6367 - val_loss: 0.6464 - val_accuracy: 0.5693\n",
            "Epoch 31/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6355 - val_loss: 0.6405 - val_accuracy: 0.5891\n",
            "Epoch 32/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6564 - val_loss: 0.6346 - val_accuracy: 0.5891\n",
            "Epoch 33/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6626 - val_loss: 0.6288 - val_accuracy: 0.5990\n",
            "Epoch 34/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6638 - val_loss: 0.6234 - val_accuracy: 0.6040\n",
            "Epoch 35/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6675 - val_loss: 0.6179 - val_accuracy: 0.6139\n",
            "Epoch 36/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.6786 - val_loss: 0.6125 - val_accuracy: 0.6337\n",
            "Epoch 37/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6835 - val_loss: 0.6071 - val_accuracy: 0.6337\n",
            "Epoch 38/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6995 - val_loss: 0.6020 - val_accuracy: 0.6733\n",
            "Epoch 39/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7057 - val_loss: 0.5969 - val_accuracy: 0.6881\n",
            "Epoch 40/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7131 - val_loss: 0.5920 - val_accuracy: 0.6980\n",
            "Epoch 41/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7217 - val_loss: 0.5871 - val_accuracy: 0.6980\n",
            "Epoch 42/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7266 - val_loss: 0.5822 - val_accuracy: 0.7079\n",
            "Epoch 43/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7278 - val_loss: 0.5774 - val_accuracy: 0.7079\n",
            "Epoch 44/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7278 - val_loss: 0.5727 - val_accuracy: 0.7079\n",
            "Epoch 45/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7291 - val_loss: 0.5682 - val_accuracy: 0.7129\n",
            "Epoch 46/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7291 - val_loss: 0.5635 - val_accuracy: 0.7129\n",
            "Epoch 47/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7291 - val_loss: 0.5590 - val_accuracy: 0.7129\n",
            "Epoch 48/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7291 - val_loss: 0.5545 - val_accuracy: 0.7129\n",
            "Epoch 49/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7291 - val_loss: 0.5501 - val_accuracy: 0.7129\n",
            "Epoch 50/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7315 - val_loss: 0.5457 - val_accuracy: 0.7277\n",
            "Epoch 51/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7340 - val_loss: 0.5414 - val_accuracy: 0.7277\n",
            "Epoch 52/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7352 - val_loss: 0.5371 - val_accuracy: 0.7277\n",
            "Epoch 53/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7365 - val_loss: 0.5329 - val_accuracy: 0.7277\n",
            "Epoch 54/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7377 - val_loss: 0.5287 - val_accuracy: 0.7376\n",
            "Epoch 55/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7377 - val_loss: 0.5245 - val_accuracy: 0.7376\n",
            "Epoch 56/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7377 - val_loss: 0.5204 - val_accuracy: 0.7475\n",
            "Epoch 57/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7475 - val_loss: 0.5163 - val_accuracy: 0.7475\n",
            "Epoch 58/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7537 - val_loss: 0.5123 - val_accuracy: 0.7475\n",
            "Epoch 59/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7549 - val_loss: 0.5082 - val_accuracy: 0.7475\n",
            "Epoch 60/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7562 - val_loss: 0.5043 - val_accuracy: 0.7475\n",
            "Epoch 61/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7562 - val_loss: 0.5003 - val_accuracy: 0.7475\n",
            "Epoch 62/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7611 - val_loss: 0.4964 - val_accuracy: 0.7525\n",
            "Epoch 63/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7635 - val_loss: 0.4925 - val_accuracy: 0.7574\n",
            "Epoch 64/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7635 - val_loss: 0.4886 - val_accuracy: 0.7574\n",
            "Epoch 65/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7660 - val_loss: 0.4848 - val_accuracy: 0.7624\n",
            "Epoch 66/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7660 - val_loss: 0.4810 - val_accuracy: 0.7624\n",
            "Epoch 67/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7734 - val_loss: 0.4772 - val_accuracy: 0.7723\n",
            "Epoch 68/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7845 - val_loss: 0.4735 - val_accuracy: 0.7822\n",
            "Epoch 69/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7894 - val_loss: 0.4698 - val_accuracy: 0.7822\n",
            "Epoch 70/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7931 - val_loss: 0.4661 - val_accuracy: 0.7871\n",
            "Epoch 71/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7968 - val_loss: 0.4624 - val_accuracy: 0.8020\n",
            "Epoch 72/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8054 - val_loss: 0.4587 - val_accuracy: 0.8069\n",
            "Epoch 73/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8103 - val_loss: 0.4552 - val_accuracy: 0.8119\n",
            "Epoch 74/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8177 - val_loss: 0.4516 - val_accuracy: 0.8168\n",
            "Epoch 75/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8214 - val_loss: 0.4481 - val_accuracy: 0.8168\n",
            "Epoch 76/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8239 - val_loss: 0.4445 - val_accuracy: 0.8168\n",
            "Epoch 77/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8264 - val_loss: 0.4410 - val_accuracy: 0.8218\n",
            "Epoch 78/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8288 - val_loss: 0.4376 - val_accuracy: 0.8366\n",
            "Epoch 79/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8411 - val_loss: 0.4341 - val_accuracy: 0.8416\n",
            "Epoch 80/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8448 - val_loss: 0.4308 - val_accuracy: 0.8416\n",
            "Epoch 81/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8473 - val_loss: 0.4274 - val_accuracy: 0.8465\n",
            "Epoch 82/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8498 - val_loss: 0.4240 - val_accuracy: 0.8515\n",
            "Epoch 83/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8547 - val_loss: 0.4207 - val_accuracy: 0.8663\n",
            "Epoch 84/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8633 - val_loss: 0.4174 - val_accuracy: 0.8713\n",
            "Epoch 85/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8658 - val_loss: 0.4141 - val_accuracy: 0.8713\n",
            "Epoch 86/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8695 - val_loss: 0.4109 - val_accuracy: 0.8960\n",
            "Epoch 87/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8805 - val_loss: 0.4077 - val_accuracy: 0.9059\n",
            "Epoch 88/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8879 - val_loss: 0.4045 - val_accuracy: 0.9059\n",
            "Epoch 89/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8879 - val_loss: 0.4013 - val_accuracy: 0.9059\n",
            "Epoch 90/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8904 - val_loss: 0.3981 - val_accuracy: 0.9059\n",
            "Epoch 91/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.9002 - val_loss: 0.3950 - val_accuracy: 0.9158\n",
            "Epoch 92/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.9015 - val_loss: 0.3919 - val_accuracy: 0.9158\n",
            "Epoch 93/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.9039 - val_loss: 0.3889 - val_accuracy: 0.9158\n",
            "Epoch 94/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.9101 - val_loss: 0.3858 - val_accuracy: 0.9208\n",
            "Epoch 95/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.9200 - val_loss: 0.3828 - val_accuracy: 0.9208\n",
            "Epoch 96/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.9249 - val_loss: 0.3797 - val_accuracy: 0.9257\n",
            "Epoch 97/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.9261 - val_loss: 0.3768 - val_accuracy: 0.9307\n",
            "Epoch 98/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.9261 - val_loss: 0.3738 - val_accuracy: 0.9356\n",
            "Epoch 99/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.9298 - val_loss: 0.3709 - val_accuracy: 0.9356\n",
            "Epoch 100/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.9360 - val_loss: 0.3680 - val_accuracy: 0.9356\n",
            "Epoch 101/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.9360 - val_loss: 0.3651 - val_accuracy: 0.9356\n",
            "Epoch 102/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.9372 - val_loss: 0.3622 - val_accuracy: 0.9356\n",
            "Epoch 103/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.9421 - val_loss: 0.3594 - val_accuracy: 0.9455\n",
            "Epoch 104/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.9433 - val_loss: 0.3565 - val_accuracy: 0.9455\n",
            "Epoch 105/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.9458 - val_loss: 0.3537 - val_accuracy: 0.9455\n",
            "Epoch 106/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.9483 - val_loss: 0.3509 - val_accuracy: 0.9455\n",
            "Epoch 107/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.9495 - val_loss: 0.3481 - val_accuracy: 0.9455\n",
            "Epoch 108/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.9507 - val_loss: 0.3454 - val_accuracy: 0.9554\n",
            "Epoch 109/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.9532 - val_loss: 0.3427 - val_accuracy: 0.9554\n",
            "Epoch 110/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.9569 - val_loss: 0.3400 - val_accuracy: 0.9554\n",
            "Epoch 111/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.9569 - val_loss: 0.3373 - val_accuracy: 0.9554\n",
            "Epoch 112/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.9581 - val_loss: 0.3346 - val_accuracy: 0.9554\n",
            "Epoch 113/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.9631 - val_loss: 0.3320 - val_accuracy: 0.9554\n",
            "Epoch 114/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.9631 - val_loss: 0.3294 - val_accuracy: 0.9554\n",
            "Epoch 115/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.9655 - val_loss: 0.3268 - val_accuracy: 0.9604\n",
            "Epoch 116/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.9667 - val_loss: 0.3242 - val_accuracy: 0.9703\n",
            "Epoch 117/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.9692 - val_loss: 0.3216 - val_accuracy: 0.9703\n",
            "Epoch 118/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.9692 - val_loss: 0.3191 - val_accuracy: 0.9851\n",
            "Epoch 119/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.9729 - val_loss: 0.3166 - val_accuracy: 0.9851\n",
            "Epoch 120/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.9729 - val_loss: 0.3141 - val_accuracy: 0.9851\n",
            "Epoch 121/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.9729 - val_loss: 0.3116 - val_accuracy: 0.9851\n",
            "Epoch 122/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.9729 - val_loss: 0.3092 - val_accuracy: 0.9851\n",
            "Epoch 123/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.9729 - val_loss: 0.3067 - val_accuracy: 0.9851\n",
            "Epoch 124/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.9729 - val_loss: 0.3043 - val_accuracy: 0.9851\n",
            "Epoch 125/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.9729 - val_loss: 0.3019 - val_accuracy: 0.9851\n",
            "Epoch 126/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.9729 - val_loss: 0.2995 - val_accuracy: 0.9851\n",
            "Epoch 127/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.9741 - val_loss: 0.2972 - val_accuracy: 0.9901\n",
            "Epoch 128/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.9791 - val_loss: 0.2948 - val_accuracy: 0.9901\n",
            "Epoch 129/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.9791 - val_loss: 0.2924 - val_accuracy: 0.9901\n",
            "Epoch 130/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.9791 - val_loss: 0.2901 - val_accuracy: 0.9901\n",
            "Epoch 131/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.9791 - val_loss: 0.2878 - val_accuracy: 0.9901\n",
            "Epoch 132/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.9791 - val_loss: 0.2855 - val_accuracy: 0.9901\n",
            "Epoch 133/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9791 - val_loss: 0.2833 - val_accuracy: 0.9901\n",
            "Epoch 134/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9791 - val_loss: 0.2810 - val_accuracy: 0.9901\n",
            "Epoch 135/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9791 - val_loss: 0.2788 - val_accuracy: 0.9901\n",
            "Epoch 136/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9791 - val_loss: 0.2766 - val_accuracy: 0.9901\n",
            "Epoch 137/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.9791 - val_loss: 0.2744 - val_accuracy: 0.9901\n",
            "Epoch 138/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.9791 - val_loss: 0.2723 - val_accuracy: 0.9901\n",
            "Epoch 139/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.9791 - val_loss: 0.2701 - val_accuracy: 0.9901\n",
            "Epoch 140/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.9791 - val_loss: 0.2680 - val_accuracy: 0.9901\n",
            "Epoch 141/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.9791 - val_loss: 0.2658 - val_accuracy: 0.9901\n",
            "Epoch 142/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9791 - val_loss: 0.2637 - val_accuracy: 0.9901\n",
            "Epoch 143/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9791 - val_loss: 0.2616 - val_accuracy: 0.9901\n",
            "Epoch 144/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9791 - val_loss: 0.2596 - val_accuracy: 0.9901\n",
            "Epoch 145/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9791 - val_loss: 0.2575 - val_accuracy: 0.9901\n",
            "Epoch 146/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9791 - val_loss: 0.2554 - val_accuracy: 0.9901\n",
            "Epoch 147/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2410 - accuracy: 0.9791 - val_loss: 0.2534 - val_accuracy: 0.9901\n",
            "Epoch 148/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9791 - val_loss: 0.2514 - val_accuracy: 0.9901\n",
            "Epoch 149/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9803 - val_loss: 0.2494 - val_accuracy: 0.9901\n",
            "Epoch 150/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9803 - val_loss: 0.2474 - val_accuracy: 0.9901\n",
            "Epoch 151/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.9803 - val_loss: 0.2454 - val_accuracy: 0.9901\n",
            "Epoch 152/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2315 - accuracy: 0.9803 - val_loss: 0.2435 - val_accuracy: 0.9901\n",
            "Epoch 153/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9803 - val_loss: 0.2416 - val_accuracy: 0.9901\n",
            "Epoch 154/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9803 - val_loss: 0.2396 - val_accuracy: 0.9901\n",
            "Epoch 155/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9803 - val_loss: 0.2377 - val_accuracy: 0.9901\n",
            "Epoch 156/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.9803 - val_loss: 0.2359 - val_accuracy: 0.9901\n",
            "Epoch 157/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9803 - val_loss: 0.2340 - val_accuracy: 0.9901\n",
            "Epoch 158/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9803 - val_loss: 0.2321 - val_accuracy: 0.9901\n",
            "Epoch 159/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9803 - val_loss: 0.2303 - val_accuracy: 0.9901\n",
            "Epoch 160/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2171 - accuracy: 0.9803 - val_loss: 0.2284 - val_accuracy: 0.9901\n",
            "Epoch 161/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9803 - val_loss: 0.2266 - val_accuracy: 0.9901\n",
            "Epoch 162/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9803 - val_loss: 0.2248 - val_accuracy: 0.9901\n",
            "Epoch 163/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9803 - val_loss: 0.2230 - val_accuracy: 0.9901\n",
            "Epoch 164/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9803 - val_loss: 0.2212 - val_accuracy: 0.9901\n",
            "Epoch 165/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9815 - val_loss: 0.2195 - val_accuracy: 0.9901\n",
            "Epoch 166/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9828 - val_loss: 0.2177 - val_accuracy: 0.9901\n",
            "Epoch 167/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9828 - val_loss: 0.2160 - val_accuracy: 0.9901\n",
            "Epoch 168/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9828 - val_loss: 0.2143 - val_accuracy: 0.9901\n",
            "Epoch 169/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9828 - val_loss: 0.2126 - val_accuracy: 0.9901\n",
            "Epoch 170/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9828 - val_loss: 0.2109 - val_accuracy: 0.9901\n",
            "Epoch 171/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9828 - val_loss: 0.2092 - val_accuracy: 0.9901\n",
            "Epoch 172/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9828 - val_loss: 0.2075 - val_accuracy: 0.9901\n",
            "Epoch 173/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9828 - val_loss: 0.2059 - val_accuracy: 0.9901\n",
            "Epoch 174/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9828 - val_loss: 0.2042 - val_accuracy: 0.9901\n",
            "Epoch 175/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9828 - val_loss: 0.2026 - val_accuracy: 0.9901\n",
            "Epoch 176/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9828 - val_loss: 0.2010 - val_accuracy: 0.9901\n",
            "Epoch 177/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9828 - val_loss: 0.1994 - val_accuracy: 0.9901\n",
            "Epoch 178/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9828 - val_loss: 0.1978 - val_accuracy: 0.9901\n",
            "Epoch 179/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9828 - val_loss: 0.1962 - val_accuracy: 0.9901\n",
            "Epoch 180/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9828 - val_loss: 0.1947 - val_accuracy: 0.9901\n",
            "Epoch 181/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9828 - val_loss: 0.1931 - val_accuracy: 0.9901\n",
            "Epoch 182/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9828 - val_loss: 0.1916 - val_accuracy: 0.9901\n",
            "Epoch 183/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 0.9828 - val_loss: 0.1901 - val_accuracy: 0.9901\n",
            "Epoch 184/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9828 - val_loss: 0.1885 - val_accuracy: 0.9901\n",
            "Epoch 185/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9828 - val_loss: 0.1870 - val_accuracy: 0.9901\n",
            "Epoch 186/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9828 - val_loss: 0.1856 - val_accuracy: 0.9901\n",
            "Epoch 187/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9828 - val_loss: 0.1841 - val_accuracy: 0.9901\n",
            "Epoch 188/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9828 - val_loss: 0.1826 - val_accuracy: 0.9901\n",
            "Epoch 189/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9828 - val_loss: 0.1811 - val_accuracy: 0.9901\n",
            "Epoch 190/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9828 - val_loss: 0.1797 - val_accuracy: 0.9901\n",
            "Epoch 191/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9828 - val_loss: 0.1783 - val_accuracy: 0.9901\n",
            "Epoch 192/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9852 - val_loss: 0.1769 - val_accuracy: 0.9901\n",
            "Epoch 193/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9865 - val_loss: 0.1754 - val_accuracy: 0.9950\n",
            "Epoch 194/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9865 - val_loss: 0.1740 - val_accuracy: 0.9950\n",
            "Epoch 195/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9865 - val_loss: 0.1727 - val_accuracy: 0.9950\n",
            "Epoch 196/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9865 - val_loss: 0.1713 - val_accuracy: 0.9950\n",
            "Epoch 197/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9865 - val_loss: 0.1700 - val_accuracy: 0.9950\n",
            "Epoch 198/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9865 - val_loss: 0.1686 - val_accuracy: 0.9950\n",
            "Epoch 199/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9865 - val_loss: 0.1673 - val_accuracy: 0.9950\n",
            "Epoch 200/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9865 - val_loss: 0.1659 - val_accuracy: 0.9950\n",
            "Epoch 201/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9889 - val_loss: 0.1646 - val_accuracy: 0.9950\n",
            "Epoch 202/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9889 - val_loss: 0.1633 - val_accuracy: 0.9950\n",
            "Epoch 203/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9914 - val_loss: 0.1620 - val_accuracy: 1.0000\n",
            "Epoch 204/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1523 - accuracy: 0.9926 - val_loss: 0.1607 - val_accuracy: 1.0000\n",
            "Epoch 205/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9926 - val_loss: 0.1594 - val_accuracy: 1.0000\n",
            "Epoch 206/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9926 - val_loss: 0.1581 - val_accuracy: 1.0000\n",
            "Epoch 207/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9926 - val_loss: 0.1569 - val_accuracy: 1.0000\n",
            "Epoch 208/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9951 - val_loss: 0.1556 - val_accuracy: 1.0000\n",
            "Epoch 209/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9951 - val_loss: 0.1544 - val_accuracy: 1.0000\n",
            "Epoch 210/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9951 - val_loss: 0.1532 - val_accuracy: 1.0000\n",
            "Epoch 211/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9951 - val_loss: 0.1519 - val_accuracy: 1.0000\n",
            "Epoch 212/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9963 - val_loss: 0.1507 - val_accuracy: 1.0000\n",
            "Epoch 213/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9963 - val_loss: 0.1495 - val_accuracy: 1.0000\n",
            "Epoch 214/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9975 - val_loss: 0.1483 - val_accuracy: 1.0000\n",
            "Epoch 215/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9975 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
            "Epoch 216/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9975 - val_loss: 0.1460 - val_accuracy: 1.0000\n",
            "Epoch 217/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9975 - val_loss: 0.1448 - val_accuracy: 1.0000\n",
            "Epoch 218/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9975 - val_loss: 0.1436 - val_accuracy: 1.0000\n",
            "Epoch 219/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9975 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
            "Epoch 220/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9975 - val_loss: 0.1414 - val_accuracy: 1.0000\n",
            "Epoch 221/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9975 - val_loss: 0.1402 - val_accuracy: 1.0000\n",
            "Epoch 222/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9975 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
            "Epoch 223/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9975 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
            "Epoch 224/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9988 - val_loss: 0.1369 - val_accuracy: 1.0000\n",
            "Epoch 225/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9988 - val_loss: 0.1358 - val_accuracy: 1.0000\n",
            "Epoch 226/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9988 - val_loss: 0.1347 - val_accuracy: 1.0000\n",
            "Epoch 227/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9988 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
            "Epoch 228/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9988 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
            "Epoch 229/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9988 - val_loss: 0.1315 - val_accuracy: 1.0000\n",
            "Epoch 230/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9988 - val_loss: 0.1304 - val_accuracy: 1.0000\n",
            "Epoch 231/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 1.0000\n",
            "Epoch 232/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 1.0000\n",
            "Epoch 233/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
            "Epoch 234/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 1.0000\n",
            "Epoch 235/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
            "Epoch 236/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
            "Epoch 237/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
            "Epoch 238/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
            "Epoch 239/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
            "Epoch 240/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 1.0000\n",
            "Epoch 241/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
            "Epoch 242/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
            "Epoch 243/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
            "Epoch 244/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
            "Epoch 245/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
            "Epoch 246/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
            "Epoch 247/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 1.0000\n",
            "Epoch 248/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
            "Epoch 249/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
            "Epoch 250/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 1.0000\n",
            "Epoch 251/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 1.0000\n",
            "Epoch 252/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
            "Epoch 253/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
            "Epoch 254/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
            "Epoch 255/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 1.0000\n",
            "Epoch 256/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
            "Epoch 257/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 1.0000\n",
            "Epoch 258/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
            "Epoch 259/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
            "Epoch 260/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 1.0000\n",
            "Epoch 261/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
            "Epoch 262/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 1.0000\n",
            "Epoch 263/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
            "Epoch 264/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 1.0000\n",
            "Epoch 265/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
            "Epoch 266/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 1.0000\n",
            "Epoch 267/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 1.0000\n",
            "Epoch 268/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
            "Epoch 269/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 1.0000\n",
            "Epoch 270/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 1.0000\n",
            "Epoch 271/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 1.0000\n",
            "Epoch 272/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
            "Epoch 273/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
            "Epoch 274/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 1.0000\n",
            "Epoch 275/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 1.0000\n",
            "Epoch 276/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 1.0000\n",
            "Epoch 277/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
            "Epoch 278/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
            "Epoch 279/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 1.0000\n",
            "Epoch 280/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
            "Epoch 281/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 1.0000\n",
            "Epoch 282/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
            "Epoch 283/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
            "Epoch 284/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
            "Epoch 285/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
            "Epoch 286/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
            "Epoch 287/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
            "Epoch 288/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
            "Epoch 289/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
            "Epoch 290/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 1.0000\n",
            "Epoch 291/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 1.0000\n",
            "Epoch 292/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 1.0000\n",
            "Epoch 293/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
            "Epoch 294/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
            "Epoch 295/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 296/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 297/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 298/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 299/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 300/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 301/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 302/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
            "Epoch 303/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
            "Epoch 304/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
            "Epoch 305/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
            "Epoch 306/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
            "Epoch 307/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
            "Epoch 308/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
            "Epoch 309/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
            "Epoch 310/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
            "Epoch 311/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
            "Epoch 312/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
            "Epoch 313/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
            "Epoch 314/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
            "Epoch 315/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
            "Epoch 316/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
            "Epoch 317/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 1.0000\n",
            "Epoch 318/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
            "Epoch 319/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
            "Epoch 320/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
            "Epoch 321/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
            "Epoch 322/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
            "Epoch 323/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 324/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
            "Epoch 325/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
            "Epoch 326/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 1.0000\n",
            "Epoch 327/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
            "Epoch 328/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
            "Epoch 329/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
            "Epoch 330/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
            "Epoch 331/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 332/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
            "Epoch 333/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
            "Epoch 334/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 1.0000\n",
            "Epoch 335/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
            "Epoch 336/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 337/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
            "Epoch 338/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
            "Epoch 339/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
            "Epoch 340/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
            "Epoch 341/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
            "Epoch 342/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
            "Epoch 343/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
            "Epoch 344/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
            "Epoch 345/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
            "Epoch 346/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 347/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
            "Epoch 348/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
            "Epoch 349/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
            "Epoch 350/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
            "Epoch 351/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
            "Epoch 352/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
            "Epoch 353/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
            "Epoch 354/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
            "Epoch 355/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
            "Epoch 356/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "Epoch 357/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
            "Epoch 358/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
            "Epoch 359/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
            "Epoch 360/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
            "Epoch 361/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
            "Epoch 362/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 363/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
            "Epoch 364/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
            "Epoch 365/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
            "Epoch 366/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
            "Epoch 367/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
            "Epoch 368/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
            "Epoch 369/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
            "Epoch 370/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
            "Epoch 371/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
            "Epoch 372/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 373/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
            "Epoch 374/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
            "Epoch 375/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
            "Epoch 376/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
            "Epoch 377/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
            "Epoch 378/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
            "Epoch 379/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
            "Epoch 380/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
            "Epoch 381/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
            "Epoch 382/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
            "Epoch 383/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
            "Epoch 384/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
            "Epoch 385/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
            "Epoch 386/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
            "Epoch 387/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
            "Epoch 388/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 389/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
            "Epoch 390/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
            "Epoch 391/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
            "Epoch 392/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
            "Epoch 393/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 394/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
            "Epoch 395/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
            "Epoch 396/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
            "Epoch 397/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 398/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 399/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
            "Epoch 400/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
            "Epoch 401/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
            "Epoch 402/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 403/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
            "Epoch 404/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
            "Epoch 405/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
            "Epoch 406/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
            "Epoch 407/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 408/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
            "Epoch 409/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
            "Epoch 410/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
            "Epoch 411/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 412/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 413/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
            "Epoch 414/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
            "Epoch 415/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 416/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
            "Epoch 417/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 418/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 419/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
            "Epoch 420/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 421/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 422/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
            "Epoch 423/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
            "Epoch 424/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 425/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 426/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
            "Epoch 427/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 428/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 429/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 430/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
            "Epoch 431/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 432/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 433/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 434/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 435/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
            "Epoch 436/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
            "Epoch 437/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 438/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 439/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
            "Epoch 440/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
            "Epoch 441/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 442/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 443/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 444/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 445/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
            "Epoch 446/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 447/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
            "Epoch 448/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
            "Epoch 449/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 450/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
            "Epoch 451/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 452/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 453/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
            "Epoch 454/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 455/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 456/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "Epoch 457/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 458/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 459/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
            "Epoch 460/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 461/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
            "Epoch 462/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
            "Epoch 463/512\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 464/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
            "Epoch 465/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 466/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 467/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 468/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 469/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 470/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 471/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 472/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 473/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 474/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 475/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 476/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 477/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 478/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 479/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 480/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 481/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 482/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 483/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
            "Epoch 484/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 485/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 486/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 487/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 488/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 489/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 490/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 491/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 492/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 493/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 494/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 495/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 496/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 497/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 498/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 499/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 500/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 501/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 502/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 503/512\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 504/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 505/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 506/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 507/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 508/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 509/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 510/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 511/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 512/512\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.params)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(history.history['accuracy']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_accuracy']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "fhUSJdY4blpA",
        "outputId": "fc99341a-13ee-4305-fa29-adde553878c1"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 512, 'steps': 26}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFzCAYAAAAuSjCuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhU5Zn///fdG013szR0szarorIK2IIGjbiGON/gviUmMYkxMZroN5NkNJNR4sxck2/GMctvMMYYE5OoqCQkmBB31GjUAIrIJiCyNGtD7/t2//6oApumG4qmT5+qrs/ruvrqOs95ququo/DhOeep85i7IyIiIoknJewCREREpHMU4iIiIglKIS4iIpKgFOIiIiIJSiEuIiKSoBTiIiIiCSot7AKOVV5eno8ePTrsMkRERLrFihUr9rl7fnv7Ei7ER48ezfLly8MuQ0REpFuY2daO9ul0uoiISIJSiIuIiCQohbiIiEiCUoiLiIgkKIW4iIhIglKIi4iIJCiFuIiISIJSiIuIiCQohbiIiEiCCizEzexhM9trZqs72G9m9lMz22Rmq8xselC1iIiI9ERBjsR/Dcw5wv5PAuOiPzcBPwuwFhERkR4nsHunu/urZjb6CF0uAX7j7g68aWb9zWyou+8KqiaRuLN3PZRv7/KX3V9VT1FZbZe/rogcXUpqGpM/flm3vFeYC6AMB1r/7VUUbTssxM3sJiKjdUaOHNktxYkErnofPDgbmro+bAdGf0Sk+1WQDUkQ4jFz9weBBwEKCws95HJEYvfBS7B3Xfv7ipZHAvzaxyBnMABvfVjCrrJaHGfF1lI+KK6mtqH5iG8xNj+bQX0yD2kbkJ3O2ePySDHrko8hIrFLSU2jbze9V5ghvgMY0Wq7INom0jNUFcNj10BzQ4dd6k/4BL/YeRJV9c3sr6rnqRWNHPhjmZczgk9MHcwFEwZzQl5Ou89PSYHh/XtjCmuRpBRmiC8GbjWzBcBMoFzXw5Nc9T549b+hqT7sSrpGyQeRAL/pFRgw5pBdLS3Osq2l3PLUBvat2UBGWmSO6dxTh/Efl00ixYzMtBTSUvUtUBHpWGAhbmaPA7OBPDMrAu4G0gHc/QFgCXAxsAmoAb4QVC2SIP7+U3jr55CdH3YlXaZqwnWsaxgJuw89Jf7zVz7ghXV76Z+VzjO3n80pQ7rr5JuI9CRBzk6/7ij7HbglqPeXOFW0HF78PrS0HL5v5zswYS5c/ZvurysA//vSRu57fgMtb7/R7v4vzhrDF2aNZsSArG6uTER6ioSY2CY9yJpFsPXvMOKMw/eNOB0+/p1uL6m+qZlfv76FJ5dvp6mla+ZNtrizvaSWuacO46rCAoxDr1nnZqczcVi/LnkvEUleCnHpXvs/gLyT4At/aXf39pIaFi/dROREzbFzhxfW7WFzcXXMz2lobqG+qYUzxg5gSN/Moz8hRpdNHc43zh+n69oiEhiFuHSvks2QN67D3fMWr+HF9XuP6y0KcntzZTuj346YwTkn5fPxk3rOtXgRSQ4Kcek+Lc1Q+iHN4y5i/c7yw3bvLKvjpff3cuu5J3LbBR0H/dGkpZi+ciUiSUEhLt1n6+vQ3MCv1qXwH0tfa7fL8P69+fzHRpOuU9AiIkelEJfuUVMCj3wKgCV7crl59glMHdH/kC5pKcaZJwwkK0P/W4qIxEJ/W0q3ePfNFzkV+N+Wqyg86xN866KTSU3RKW8RkeOhEJdA7S6v4/6XNzFw+V+ZnGpcdOO/c9LIoWGXJSLSIyjEJVD3Pvc+C1cUsajvVrzfKQpwEZEupNlDEoiKukaWrt/L4nd3clNhf6a1rCZ19FlhlyUi0qNoJC5da98mml78d97ZsIv6hhZ+np7Cx4oboKkOCr8YdnUiIj2KQly61ruPkbJuMYNahjOoby9yszJIcYPTvwyDJ4RdnYhIj6IQly5TXtvI/pWvUN0yksem/o7/unxy2CWJiPRouiYuXWJ7SQ1z7nuJ/Io11ORP5Z5LJoZdkohIj6eRuByfD5bij13DsOZGXsdJMWfm2Z8A3XFNRCRwCnE5LmXv/pnezc5DzZdwydThFOTnwvi5YZclIpIUFOJyXEo3vMEHPpbTv3gfBWMGhF2OiEhSUYjLsWlugg9fZmtxOat3lHNB7QZ2D7mSMxXgIiLdTiEux2bZL+CZOxgFjAIwGH/mJ0MuSkQkOSnEJXYtzfDWA1TnT+Paoiv44qzRXHr6WPoP0ve/RUTCoBCX2G18Dkq3sGjEDbyfciLnnX8B1js97KpERJKWQlxiVvnK/9KQmse8jWP53KxR9FOAi4iESl/mlZhUbltNn52vscA/wSdPHcltF4wLuyQRkaSnkbgc3cYX6P34ddR7Ohde/x1uGTs67IpERASNxOVo3OGFu0lraeB3fb7ASQpwEZG4oZG4dOyxa2H7m1Bbyp1NN5E76UthVyQiIq1oJC7tq94PG/4Kgyaya8rX+H3TLKaO6B92VSIi0opG4tK+HSsiv2ffwZ+3D6eBdUwdqRAXEYkngY7EzWyOmb1vZpvM7I529o8ysxfNbJWZvWxmBUHWIzHYtwm2vQXv/wUsBYZN4/m1ezhxUA6D+mSGXZ2IiLQS2EjczFKB+cCFQBGwzMwWu/vaVt3uBX7j7o+Y2XnAfwGfDaomOYrKPTB/BnhzZHvoqeysTeUfW0r45oUnhVubiIgcJsjT6TOATe6+GcDMFgCXAK1DfALwzejjpcAfA6xHjmb7W5EAv/heGDCWkuyx3P7EStJTjUunDg+7OhERaSPI0+nDge2ttouiba29C1wefXwZ0MfMBgZYkxzJjhWQkg7TPoufcB5XP76Nt7eWcu9VpzJyYFbY1YmISBthz07/FnCOmb0DnAPsAJrbdjKzm8xsuZktLy4u7u4ak8eOFTBkMqRnsqu8jk17q7jz4vFcolG4iEhcCjLEdwAjWm0XRNsOcved7n65u08D/jXaVtb2hdz9QXcvdPfC/Pz8AEtOcsXrYcgkAFZuj/xnKByVG2ZFIiJyBEGG+DJgnJmNMbMM4FpgcesOZpZnZgdquBN4OMB65EhamqFmP+QMBuCdbaVkpKUwfmjfkAsTEZGOBBbi7t4E3Ao8C6wDnnT3NWZ2j5nNjXabDbxvZhuAwcB/BlWPHEVtKXgL9b0G8N/PrufRt7YxY/QAMtLCvuIiIiIdCfRmL+6+BFjSpu2uVo8XAguDrEFiVB2Za7CsOI35b37AkL6Z/PDKKSEXJSIiR6I7tklENMTf3GMU5Pbmb985FzMLuSgRETkSnSuViGiIv7oDZp+crwAXEUkACnGJqN4HQFFDDmeOzQu5GBERiYVCXCKqi2khhTJymDRcM9JFRBKBQlygoRpWPUlNWl+ye2UwIld3ZxMRSQQKcYEX/x3KtlLEUCYM60tKiq6Hi4gkAoV4squrgHd+R+WQM7iq6p8560RdDxcRSRQK8WS39XVoqOTfyv4PWX1z+eJZY8KuSEREYqQQT3b7NwHwSvkg5n96Otm9dOsAEZFEoRBPdiWbqbQ+jCwooHD0gLCrERGRY6AQT3LN+z5gc/MgzhirABcRSTQK8STXuHcjm30IZ4wZGHYpIiJyjBTiyay+koyaXexNL2CWZqWLiCQchXgSe2/JA6Tg9J80R0uOiogkIP3NnaRWbNlH9sqH2Zh+MpfOvSTsckREpBMU4kmovr6OlY/+G2NtJ0Mv+r/0SksNuyQREekEhXgS2rjw+3yp8THqew8mZ9oVYZcjIiKdpBBPNk31jPrwcTYxgoyvvABpGWFXJCIinaQQTzbb3qBPUym/z/0S1n9k2NWIiMhxUIgnGd8Xuc1qytBTQ65ERESOl26UnWSqdm8gzTMYOkILnYiIJDqFeBJpaXE2r19FLx/MaaN1hzYRkUSn0+lJ5L/+uo6sqm1kDh7H+KF9wy5HRESOk0I8STyxbBuP/G0DY1L3Mmrc5LDLERGRLqAQTwIl1Q3811/WcPuQ90jzRmzsOWGXJCIiXUDXxJPAsr88xNv+XVLKHPJOghPOC7skERHpAgrxns6dkzb8gt2pQxh2zpdg3IVgFnZVIiLSBXQ6vYer2vA3xjRtZvWYL8A534ZhU8MuSUREuohG4j3cvhd/QpNnM+zsz4ddioiIdLFAR+JmNsfM3jezTWZ2Rzv7R5rZUjN7x8xWmdnFQdaTbLxsGyP2vsRL2Z9k0ughYZcjIiJdLLAQN7NUYD7wSWACcJ2ZTWjT7XvAk+4+DbgWuD+oepJR2asPgDspM24MuxQREQlAkCPxGcAmd9/s7g3AAuCSNn0cOHDXkX7AzgDrSTop7/+V11omM2WivhcuItITBRniw4HtrbaLom2tzQOuN7MiYAnw9fZeyMxuMrPlZra8uLg4iFp7npZmsmu2szV9DGPyssOuRkREAhD27PTrgF+7ewFwMfBbMzusJnd/0N0L3b0wPz+/24tMRLu2byLNG8kechKmr5SJiPRIQYb4DmBEq+2CaFtrXwKeBHD3N4BMIC/AmpLGwudeAeCcM2eGXImIiAQlyBBfBowzszFmlkFk4triNn22AecDmNl4IiGu8+XHafmWEvZsWQtA3si2cwlFRKSnCCzE3b0JuBV4FlhHZBb6GjO7x8zmRrv9M/BlM3sXeBy4wd09qJqSxc9f3czkjF14Wm/oMzTsckREJCCB3uzF3ZcQmbDWuu2uVo/XArOCrCHZ7C6vY+W695nf+xXsxPMhJexpDyIiEhTdsa2HWbd2Fct6fQ1agJlfDbscEREJkIZpPUzdppcBaJz9PRh9VrjFiIhIoBTiPUzmnpVUkU36x/9Zq5WJiPRwCvEexN0ZVrWGHdnjdS1cRCQJ6G/6HmTTjr2c6FtpHDo97FJERKQbKMR7kOVvvESqOcMm6lq4iEgy0Oz0HmBvZR3ff3otw9e8Aukw4CR9a09EJBkoxBPcM6t3cfOjb3O2vct3Mx6noc9IMrJ151oRkWSgEE9gFXWNfOupVZw8KIef8Qcoh4yzbg27LBER6SYK8QS1bX8N3/vTajLqS1jc/B9kVBXBJffDtM+EXZqIiHQThXiCcXd+9PwGHnhlMw3NLfww/w0yKovg1Otg8pVhlyciIt1Is9MTzFsflvDTlzZx4cTBvHj7x7jKn4UTzofLHoC0XmGXJyIi3Ughnkgaqln25itMS9/OvWcbJ2xZgFXt1j3SRUSSlE6nJxBf9BW+vuFpvp4K/DLaOPBEOPGCMMsSEZGQKMQThTstH77Gq82nknL6FzhnXH6kfchk3WJVRCRJKcQTRclmUutKebblCj5beDkM6xd2RSIiEjKFeALYsXcf/O6LDAfWpZzEyYP7hF2SiIjEAYV4HKtpaOKBlz9g999+zQ9TV7Lf+zJmwmmkper0uYiIKMTjVm1DM9f94i3e3V7Gb4fspKU6m4F3buHHKalhlyYiInFCIR4nKusaWbalhOaWyPYTy7axqqiMn31mOmf//YeQexoowEVEpBWFeMhWbC3hB39dz/u7K6moazrYPsPW8Y/835P/ehrsWQ2zbg+xShERiUcK8RDVNTZz4yPLycpI46KJQ7hk6jByszIAGLlsKX3f2wRDzofcUXDqtSFXKyIi8UYhHqLFK3dSWtPI/Z85jTNPGHjozpe3Qd7J8OkF4RQnIiJxT9OcQ/SX93YxNi+bM8YOOHxnyQcwcGz3FyUiIglDIR6SpuYWlm8pYdaJeZjZoTubm6B0CwxQiIuISMd0Oj0kq3dWUN3QzMwDo/Cmetj2JngzVO+DliYYcEK4RYqISFxTiIfk9U37AJg5Jnot/NX/jvy0NnhCN1clIiKJRCEeklfeL2bS8L7kl78Ha1fAsl/CCefBOf8S6ZCRHVncREREpAOBhriZzQF+AqQCD7n7D9rs/xFwbnQzCxjk7v2DrCkelNc0smJbKV+bfQI8dSWUbwMMPv4dGHlG2OWJiEiCCCzEzSwVmA9cCBQBy8xssbuvPdDH3f9vq/5fB6YFVU88eWHdHppbnAtHAn/fBuf9G8z8CvTSwiYiIhK7IGenzwA2uftmd28AFgCXHKH/dcDjAdYTNxa/u5OC3N5M9g2RhtFnK8BFROSYBRniw4HtrbaLom2HMbNRwBjgpQ7232Rmy81seXFxcZcX2p0amlp4fdM+Pje2CnvierAUGDol7LJERCQBxcv3xK8FFrp7c3s73f1Bdy9098L8/PxuLq1r7SirpanFOaduaaThzFshvXe4RYmISEIKMsR3ACNabRdE29pzLUlyKn3r/moAhlathuGnwUX/HnJFIiKSqIIM8WXAODMbY2YZRIJ6cdtOZnYKkAu8EWAtcWN7SQ2pNNNn/3swvDDsckREJIEFFuLu3gTcCjwLrAOedPc1ZnaPmc1t1fVaYIG7e1C1xJNtJTVMSNuFNdVCgUJcREQ6L9Dvibv7EmBJm7a72mzPC7KGeLOtpIbT++yDWmDQ+LDLERGRBBYvE9uSQlNzC+9uL2dK78gtV8kdE25BIiKS0BTi3ei5tXvYXVHH6X3LIGcI9MoJuyQREUlgCvFu9Mzq3Qzq04thzbtgoFYoExGR46MQ70ard5Zz6oj+WMkHMECn0kVE5PgoxLtJdX0TH+6rZvKQLKjeC/1Ghl2SiIgkOIV4N1m/uwJ3mJIfPeSZ/cItSEREEp5CvJs8/e4uUgwm5kUPuRY8ERGR46QQ7wa/ev1DfvvmVq6dMZL89IZIo2ami4jIcVKIB2xHWS3ff3otHzthIP/yiVOgvjKyQyNxERE5TgrxgP353Z0A/Melk+iXld4qxPuGWJWIiPQECvGAvbh+L5OG92XUwOxIQ4NG4iIi0jViCnEz+4OZ/ZOZKfSP0c6yWsYNahXYB0biGbomLiIixyfWUL4f+DSw0cx+YGYnB1hTj+Hu7K2oZ1DfXh816pq4iIh0kZhC3N1fcPfPANOBLcALZvZ3M/uCmaUHWWAiK6tppKG5hcF9Mj9q1EhcRES6SMynx81sIHADcCPwDvATIqH+fCCV9QB7KusAGNy3dYhXQUYfSNGVCREROT4xrSduZouAk4HfAp9y913RXU+Y2fKgikt0eyrqARh8yOn0Cp1KFxGRLhFTiAM/dfel7e1w98IurKdH2VPR3ki8Ujd6ERGRLhHrOd0JZtb/wIaZ5ZrZ1wKqqUdYvaOc7yxcBUB+nzYT2zQSFxGRLhBriH/Z3csObLh7KfDlYErqGR75+xYAxg3KITM9NdK44Vn44EWFuIiIdIlYQzzVzOzAhpmlAhnBlJT46puaeWbNbq6YXsDz3zznox2rnoj8nnJNOIWJiEiPEus18WeITGL7eXT7K9E2acfqHeVU1jVx0cTBh+6o2AWjZsHUT4dTmIiI9Cixhvi/EAnum6PbzwMPBVJRD7B6RwUAUwrarBlesQNGzAihIhER6YliCnF3bwF+Fv2Ro1izs5yB2RkMaT0r3R0qd0GfoeEVJiIiPUqs3xMfB/wXMAE4mEzuPjaguhLamp0VTBjWl1bTCKBmPzQ3QN/h4RUmIiI9SqwT235FZBTeBJwL/Ab4XVBFJbKS6gbW765k6oj+h+6oiCxJSl+NxEVEpGvEGuK93f1FwNx9q7vPA/4puLIS15L3dtHc4nxyUpuwPhjiGomLiEjXiHViW310GdKNZnYrsAPQbcfa8fS7OzlxUA7jh7b5Lnjph5Hf/Qq6vygREemRYh2J3wZkAd8ATgOuBz4fVFGJand5Hf/YUsKnpgw79Ho4wI4VkUltfYaEU5yIiPQ4Rw3x6I1drnH3KncvcvcvuPsV7v5mDM+dY2bvm9kmM7ujgz5Xm9laM1tjZo914jPEjb+8twt3+NSp7Vz3LloOBbrNvIiIdJ2jnk5392YzO+tYXzga/vOBC4EiYJmZLXb3ta36jAPuBGa5e6mZDTrW94knr20sZmx+NmPz21xpqN4fOZ1+2g2h1CUiIj1TrNfE3zGzxcBTQPWBRnf/wxGeMwPY5O6bAcxsAXAJsLZVny8D86P3Ysfd9x5D7XGlqbmFZVtKmTt12OE733sq8nvs7O4sSUREerhYQzwT2A+c16rNgSOF+HBge6vtImBmmz4nAZjZ60AqMM/dE/J2ri+u30tVfRNnjB146A53+MeDUDADhk0NpzgREemRYr1j2xcCfP9xwGygAHjVzCa3XjENwMxuAm4CGDlyZECldN7u8jpufextCnJ78/FxeYfuLC+Ckg9g5lfDKU5ERHqsWO/Y9isiI+9DuPsXj/C0HcCIVtsF0bbWioC33L0R+NDMNhAJ9WVt3udB4EGAwsLCw+oI28rtZTQ2Oz+9bhr9s9os7rZjeeS3JrWJiEgXi/UrZn8G/hL9eRHoC1Qd5TnLgHFmNsbMMoBrgcVt+vyRyCgcM8sjcnp9c4w1xY01O8tJTTEmDO176I6WFlj9B0jtBYMnhVOciIj0WLGeTv99620zexx47SjPaYreGOZZIte7H3b3NWZ2D7Dc3RdH911kZmuBZuDb7r6/E58jVGt2VnBCfjaZ6amH7nj1h7BuMYw4A9K0/LqIiHStWCe2tTUOOOrXwdx9CbCkTdtdrR478M3oT8Jat6vi8AltAHvXRX5fpsXfRESk68V6TbySQ6+J7yayxnjSa2xuYXdFHSMHZB2+s3IXjD4bBmixNxER6Xqxnk7vc/ReyWlvZT3uMKRf5uE7K3bCqFndX5SIiCSFmCa2mdllZtav1XZ/M7s0uLISx+7yOqCdEG9piYzE+7Zz8xcREZEuEOvs9LvdvfzARvR73HcHU1JiORjifduEeHUxtDQpxEVEJDCxhnh7/To7Ka5H2VVeC8DQtiPxygPrhyvERUQkGLGG+HIzu8/MToj+3AesCLKwRLGnoo5eaSn0653+UWNDDTx6VeSxQlxERAISa4h/HWgAngAWAHXALUEVlUh2ldcxtF/moeuH714VOZ2eOwbyx4dXnIiI9Gixzk6vBtpdDzzZldU0kpsdvZHLewvhnd/CxMsj29f/HtLbmbUuIiLSBWKdnf68mfVvtZ1rZs8GV1biqG5oIqdX9N9C7y2EzS/Dmz8DS4X+8bdYi4iI9Byxnk7Pa72yWHT976PesS0Z1DY0k5WRGlly9MBiJ8XrIHcUpKYf+ckiIiLHIdYQbzGzg8NKMxtNO6uaJaPqhiayMtKgbFvkOnjeyZEdA04ItzAREenxYg3xfwVeM7PfmtnvgFeAO4MrK3HU1EdH4puXRhr+6V7I6AODJ4RbmIiI9HixTmx7xswKgZuAd4gsIVobZGGJoqahmXGN6+HZ70WWGx19Nnzt79B7QNiliYhIDxfrAig3ArcBBcBK4AzgDeC84EqLf80tTm1jM1dv/DY0VsKZt4KZJrSJiEi3iPV0+m3A6cBWdz8XmAaUHfkpPV9tYzPpNJHVWAqFX4RTrw27JBERSSKxhnidu9cBmFkvd18PnBxcWYmhpqGJXCojG4MnRUbhIiIi3STW+58XRb8n/kfgeTMrBbYGV1ZiqKlvJs+i68Jk54dbjIiIJJ1YJ7ZdFn04z8yWAv2AZwKrKkFUNzQx0CoiGwpxERHpZse8Epm7vxJEIYmotqGZgSjERUQkHLFeE5d2VDc0M/Dg6fS8cIsREZGkoxA/DjX1TeRZBS0pGZDZL+xyREQkySjEj0NN9HR6S1aeZqaLiEi3U4gfh5qGJvKtTKfSRUQkFArx41Dd0MxI2wv9R4VdioiIJCGF+HGoqatjpO0lNe/EsEsREZEkdMxfMZOPWPl20q0ZBmrZURER6X4aiR+HjIroTesU4iIiEgKF+HHIqYqG+ACFuIiIdL9AQ9zM5pjZ+2a2yczuaGf/DWZWbGYroz83BllPV+tdX0wzKZAzKOxSREQkCQV2TdzMUoH5wIVAEbDMzBa7+9o2XZ9w91uDqiNI1lhNQ0pveus74iIiEoIgR+IzgE3uvtndG4AFwCUBvl+3S2mspSm1d9hliIhIkgoyxIcD21ttF0Xb2rrCzFaZ2UIzGxFgPV2qsbmF9JZamhXiIiISkrAntj0NjHb3KcDzwCPtdTKzm8xsuZktLy4u7tYCO1Je20hv6mlJzwq7FBERSVJBhvgOoPXIuiDadpC773f3+ujmQ8Bp7b2Quz/o7oXuXpifHx9LfpbVNJJFPa4QFxGRkAQZ4suAcWY2xswygGuBxa07mNnQVptzgXUB1tOlymoayLJ6LCM77FJERCRJBTY73d2bzOxW4FkgFXjY3deY2T3AcndfDHzDzOYCTUAJcENQ9XS1kuoGRlJPSi+FuIiIhCPQ2666+xJgSZu2u1o9vhO4M8gagrK3sp5TqKNX7z5hlyIiIkkq7IltCWtvRR1ZVk+vrJywSxERkSSlEO+kPRX1ZFkDKb0U4iIiEg6FeCftqaglk3rQ7HQREQmJQryTyioqSMEhQyEuIiLhUIh3UmVFeeRBumani4hIOBTindDQ1EJ9bVVkQyNxEREJiUK8E+Yv3URvojea0zVxEREJiUL8GLk7D7/2IeeNjZ5G1x3bREQkJArxY7SjrJbK+iZOH94r0qCRuIiIhEQhfow27KkEYHR2Y6RB3xMXEZGQKMSP0frdkRAvqNsIlgp5J4dckYiIJCuF+DFas6OCof0yydzzNgyeoNnpIiISGoX4MdhXVc/za/dw87BNsPllGF4YdkkiIpLEFOLH4Ol3d9LU3MT12+dFGsZdFGo9IiKS3BTix2BHaS2T0neR0lQDc/8XTrk47JJERCSJKcSPwf7qBj7We0tkY8TMUGsRERFRiB+DfVX1TE/5ADL7wcATwy5HRESSnEL8GOyramCsb4fBkyBFh05ERMKVFnYBCaNkM0+WXk0famDAZ8OuRkRERCPxWLW8/2wkwAEGnhBuMSIiIijEY1bbK++jjQEKcRERCZ9CPEZVVVUfbWgkLiIicUAhHqPqmlYhnjsmvEJERESiFOIxaqitBmDjFc/pfukiIhIXFOIxamqoBSBjkL4fLiIi8UEhHqPm+mpa3MjJyg67FBEREUAhHrOWhlrqyCCnd3rYpYiIiAAK8Zi1NNRSTwa90lLDLkVERARQiMeusZZ6ywi7ChERkYMCDXEzm2Nm75vZJjO74wj9rjAzN7PCIOs5Lk11NFqvsKsQERE5KLAQN7NUYC6XsAkAABaLSURBVD7wSWACcJ2ZTWinXx/gNuCtoGrpCilNtTSmKMRFRCR+BDkSnwFscvfN7t4ALAAuaaffvwP/D6gLsJbjltJcT5NCXERE4kiQIT4c2N5quyjadpCZTQdGuPtfjvRCZnaTmS03s+XFxcVdX2kMUlvqaE7NDOW9RURE2hPaxDYzSwHuA/75aH3d/UF3L3T3wvz8/OCLa0daSz2uEBcRkTgSZIjvAEa02i6Ith3QB5gEvGxmW4AzgMXxOrktvaUeT1OIi4hI/AgyxJcB48xsjJllANcCiw/sdPdyd89z99HuPhp4E5jr7ssDrKlT3J0Mb8DTe4ddioiIyEGBhbi7NwG3As8C64An3X2Nmd1jZnODet8g1De1kEk9phAXEZE4khbki7v7EmBJm7a7Oug7O8hajkdpTQPZNJCq1ctERCSO6I5tMdhbUU8mDfTqrRAXEZH4oRCPQXF5DRnWTO+snLBLEREROUghHoOS8goAsrK1DKmIiMQPhXgMKssiN5jJ6pcXciUiIiIfUYjHoK5sNwBpOYNCrkREROQjCvEYNFXujTzIDuducSIiIu1RiMeiel/kd7ZOp4uISPxQiB9FS4vTUqWRuIiIxB+F+FFs3FtFVmMpTSmZkKHZ6SIiEj8U4kfx5ub95FlF5FS6WdjliIiIHKQQP4oVW0sZllZFWh/NTBcRkfiiED+KjXurGJpepevhIiISdxTiR9Dc4mwurmKgl0KOQlxEROKLQvwIdpbV0tzUQE7jfug7POxyREREDqEQP4JNxVXkU47h0Gdo2OWIiIgcQiF+BBv3VDLESiIbGomLiEicUYgfwbvby5mQUxXZ6KuRuIiIxBeF+BG8s62Uaf1rIht9hoVbjIiISBsK8Q7srahjZ3kdJ/WuhNRekDUg7JJEREQOoRDvwNpdFQAMTymBvsN0tzYREYk7CvEObC+JnEbvW1sEA8aEXI2IiMjhFOId2FZSQ680I61sMwwYG3Y5IiIih1GId2BbSQ2T+jdh9RUw4ISwyxERETmMQrwD20pqmZ5TGtkYqBAXEZH4oxBvh7uzvaSGCb2KIw0aiYuISBxSiLejtKaRqvomxvkWSMuE3FFhlyQiInIYhXg7tu6vBqCgZg0MPRVS00OuSERE5HAK8XZsK6khjSb6lq6B4YVhlyMiItKuQEPczOaY2ftmtsnM7mhn/1fN7D0zW2lmr5nZhCDridX2khpOtu2kNNfD8OlhlyMiItKuwELczFKB+cAngQnAde2E9GPuPtndpwI/BO4Lqp5jsa2khmlZ0UltgyeGW4yIiEgHghyJzwA2uftmd28AFgCXtO7g7hWtNrMBD7CemG0rqWFS5j7AIFd3axMRkfiUFuBrDwe2t9ouAma27WRmtwDfBDKA89p7ITO7CbgJYOTIkV1eaFt7K+oZm7Ib+hVAembg7yciItIZoU9sc/f57n4C8C/A9zro86C7F7p7YX5+fuA1VTc0MaRpp263KiIicS3IEN8BjGi1XRBt68gC4NIA64nZifXrGFm7ViEuIiJxLcgQXwaMM7MxZpYBXAssbt3BzMa12vwnYGOA9cTE3ZnnP4tsjDjs7L+IiEjcCOyauLs3mdmtwLNAKvCwu68xs3uA5e6+GLjVzC4AGoFS4PNB1ROr2sZmBlkp64d8ilOmXhd2OSIiIh0KcmIb7r4EWNKm7a5Wj28L8v07o6qmhkFWw4c5wU+gExEROR6hT2yLN3Vlke+He1ZeyJWIiIgcmUK8jYby3ZEHOcHPghcRETkeCvE2mir2ApCqEBcRkTinEG+jpSpyOj2tz6CQKxERETkyhXgbXh0J8V79BodciYiIyJEpxNtIqSmm3tPo3Sc37FJERESOSCHeRmptCSX0JbtXetiliIiIHFGg3xNPRKkN5ZR5Nvm9UsMuRUSkUxobGykqKqKuri7sUuQYZGZmUlBQQHp67INIhXgbqQ2VVFsWaak6SSEiiamoqIg+ffowevRozCzsciQG7s7+/fspKipizJjYl8BWUrWR0VRJjeWEXYaISKfV1dUxcOBABXgCMTMGDhx4zGdPFOJtZDRVUpeqEBeRxKYATzyd+W+mEG8js6mSpoy+YZchIpKwysrKuP/++zv13IsvvpiysrIj9rnrrrt44YUXOvX6R/LrX/+aW2+99Yh9Xn75Zf7+9793+Xt3lkK8NXd6ew3eSyEuItJZRwrxpqamIz53yZIl9O/f/4h97rnnHi644IJO13c8FOLxrKGKVFqw3v3CrkREJGHdcccdfPDBB0ydOpVvf/vbvPzyy5x99tnMnTuXCRMmAHDppZdy2mmnMXHiRB588MGDzx09ejT79u1jy5YtjB8/ni9/+ctMnDiRiy66iNraWgBuuOEGFi5ceLD/3XffzfTp05k8eTLr168HoLi4mAsvvJCJEydy4403MmrUKPbt23dYrb/61a846aSTmDFjBq+//vrB9qeffpqZM2cybdo0LrjgAvbs2cOWLVt44IEH+NGPfsTUqVP529/+1m6/7qTZ6a00VZeSBqRl6UYvItIzfP/pNazdWdGlrzlhWF/u/tTEDvf/4Ac/YPXq1axcuRKIjF7ffvttVq9efXDm9cMPP8yAAQOora3l9NNP54orrmDgwIGHvM7GjRt5/PHH+cUvfsHVV1/N73//e66//vrD3i8vL4+3336b+++/n3vvvZeHHnqI73//+5x33nnceeedPPPMM/zyl7887Hm7du3i7rvvZsWKFfTr149zzz2XadOmAXDWWWfx5ptvYmY89NBD/PCHP+R//ud/+OpXv0pOTg7f+ta3ACgtLW23X3dRiLdSXr6fgUCvHIW4iEhXmjFjxiFfnfrpT3/KokWLANi+fTsbN248LMTHjBnD1KlTATjttNPYsmVLu699+eWXH+zzhz/8AYDXXnvt4OvPmTOH3NzD/15/6623mD17Nvn5kQWvrrnmGjZs2ABEvqZ3zTXXsGvXLhoaGjr82les/YKiEG9uhLJt0Hc4laWRENctV0WkpzjSiLk7ZWdnH3z88ssv88ILL/DGG2+QlZXF7Nmz2/1qVa9evQ4+Tk1NPXg6vaN+qampR73mHquvf/3rfPOb32Tu3Lm8/PLLzJs377j6BUXXxJd8G/6/6fDE9VSX7wcgu9/AozxJREQ60qdPHyorKzvcX15eTm5uLllZWaxfv54333yzy2uYNWsWTz75JADPPfccpaWlh/WZOXMmr7zyCvv376exsZGnnnrqkBqHDx8OwCOPPHKwve1n66hfd0nuEK/eDysfizze9DxpO5cD0Ke/QlxEpLMGDhzIrFmzmDRpEt/+9rcP2z9nzhyampoYP348d9xxB2eccUaX13D33Xfz3HPPMWnSJJ566imGDBlCnz59DukzdOhQ5s2bx5lnnsmsWbMYP378wX3z5s3jqquu4rTTTiMvL+9g+6c+9SkWLVp0cGJbR/26i7l7t7/p8SgsLPTly5d3zYu9MR+e/S7csAR+exkNpJHWVEPl7Rvpl5vfNe8hItLN1q1bd0ggJaP6+npSU1NJS0vjjTfe4Oabbz440S6etfffzsxWuHthe/2T+5r4jK/A0FNh9CyYfBUZK3/HSz6dc/t3/7+mRESk62zbto2rr76alpYWMjIy+MUvfhF2SYFI7hBPTYPRZ0Uen3kLtasW8VT65Zyn2xWKiCS0cePG8c4774RdRuCSO8RbGzyBrxb8kdKahrArERERiUlyT2xrY19VPQOzM8IuQ0REJCZJHeLb9tfw6FtbaW6JTO7bX9VAXk6vozxLREQkPiR1iL/14X7+ddFqtpXURBZkr64nr49CXEREEkNSh/jJQyLfGXx/dyXltY00NrtOp4uIhCAnJweAnTt3cuWVV7bbZ/bs2RztK8Y//vGPqampObgdy9KmnXGg3o4cz3KsxyKpQ/zEQTmYRUJ8X1U9APkaiYuIhGbYsGEHVyjrjLYhHsvSpkHoESFuZnPM7H0z22Rmd7Sz/5tmttbMVpnZi2Y2Ksh62srKSGPkgCx+9MIGvvF45CYA4wb1OcqzRETkSO644w7mz59/cHvevHnce++9VFVVcf755x9cNvRPf/rTYc/dsmULkyZNAqC2tpZrr72W8ePHc9lllx1y7/Sbb76ZwsJCJk6cyN133w1EFlXZuXMn5557Lueeey7w0dKmAPfddx+TJk1i0qRJ/PjHPz74fh0tedrahx9+yJlnnsnkyZP53ve+d7C9o8/UdjnWWD57ZwT2FTMzSwXmAxcCRcAyM1vs7mtbdXsHKHT3GjO7GfghcE1QNbUnp1fkEKzdVcGJg3KYMKxvd769iEiw/noH7H6va19zyGT45A863H3NNddw++23c8sttwDw5JNP8uyzz5KZmcmiRYvo27cv+/bt44wzzmDu3LlYB/fm+NnPfkZWVhbr1q1j1apVTJ8+/eC+//zP/2TAgAE0Nzdz/vnns2rVKr7xjW9w3333sXTp0sNugbpixQp+9atf8dZbb+HuzJw5k3POOYfc3NyYljy97bbbuPnmm/nc5z53yD9QOvpMbZdjbWpqOqbPHqsgR+IzgE3uvtndG4AFwCWtO7j7Unc/cN7jTaAgwHra9Z05p/CVj4/li7PGcO9Vp3b324uI9DjTpk1j79697Ny5k3fffZfc3FxGjBiBu/Pd736XKVOmcMEFF7Bjxw727NnT4eu8+uqrB8N0ypQpTJky5eC+J598kunTpzNt2jTWrFnD2rVrO3oZILI06WWXXUZ2djY5OTlcfvnl/O1vfwNiW/L09ddf57rrrgPgs5/97MH2WD/TsX72WAV5s5fhwPZW20XAzCP0/xLw1wDradc5J+Vzzkm6T7qI9FBHGDEH6aqrrmLhwoXs3r2ba66JnGB99NFHKS4uZsWKFaSnpzN69Oh2lyA9mg8//JB7772XZcuWkZubyw033NCp1zkg1iVP2xs1x/qZuuqztxUXE9vM7HqgEPjvDvbfZGbLzWx5cXFx9xYnIiLH7JprrmHBggUsXLiQq666Cogs2zlo0CDS09NZunQpW7duPeJrfPzjH+exxyIrTa5evZpVq1YBUFFRQXZ2Nv369WPPnj389a8fjf86Wgb17LPP5o9//CM1NTVUV1ezaNEizj777Jg/z6xZs1iwYAEQCeQDOvpM7S1ZeiyfPVZBhvgOYESr7YJo2yHM7ALgX4G57l7f3gu5+4PuXujuhfn5GjWLiMS7iRMnUllZyfDhwxk6dCgAn/nMZ1i+fDmTJ0/mN7/5DaeccsoRX+Pmm2+mqqqK8ePHc9ddd3HaaacBcOqppzJt2jROOeUUPv3pTzNr1qyDz7npppuYM2fOwYltB0yfPp0bbriBGTNmMHPmTG688UamTZsW8+f5yU9+wvz585k8eTI7dnwUZR19prbLsR7rZ49VYEuRmlkasAE4n0h4LwM+7e5rWvWZBiwE5rj7xlhet0uXIhUR6YG0FGniOtalSAMbibt7E3Ar8CywDnjS3deY2T1mNjfa7b+BHOApM1tpZouDqkdERKSnCXQVM3dfAixp03ZXq8cXBPn+IiIiPVlcTGwTERGRY6cQFxHpgYKa7yTB6cx/M4W4iEgPk5mZyf79+xXkCcTd2b9/P5mZmcf0vECviYuISPcrKCigqKgI3VcjsWRmZlJQcGw3LlWIi4j0MOnp6YwZMybsMqQb6HS6iIhIglKIi4iIJCiFuIiISIIK7LarQTGzYqBr7hwfkQfs68LXSzY6fp2nY3d8dPw6T8eu88I4dqPcvd2FQxIuxLuamS3v6J60cnQ6fp2nY3d8dPw6T8eu8+Lt2Ol0uoiISIJSiIuIiCQohTg8GHYBCU7Hr/N07I6Pjl/n6dh1Xlwdu6S/Ji4iIpKoNBIXERFJUEkd4mY2x8zeN7NNZnZH2PXEGzN72Mz2mtnqVm0DzOx5M9sY/Z0bbTcz+2n0WK4ys+nhVR4fzGyEmS01s7VmtsbMbou26xgehZllmtk/zOzd6LH7frR9jJm9FT1GT5hZRrS9V3R7U3T/6DDrjwdmlmpm75jZn6PbOnYxMrMtZvaema00s+XRtrj8c5u0IW5mqcB84JPABOA6M5sQblVx59fAnDZtdwAvuvs44MXoNkSO47joz03Az7qpxnjWBPyzu08AzgBuif4/pmN4dPXAee5+KjAVmGNmZwD/D/iRu58IlAJfivb/ElAabf9RtF+yuw1Y12pbx+7YnOvuU1t9nSwu/9wmbYgDM4BN7r7Z3RuABcAlIdcUV9z9VaCkTfMlwCPRx48Al7Zq/41HvAn0N7Oh3VNpfHL3Xe7+dvRxJZG/UIejY3hU0WNQFd1Mj/44cB6wMNre9tgdOKYLgfPNzLqp3LhjZgXAPwEPRbcNHbvjFZd/bpM5xIcD21ttF0Xb5MgGu/uu6OPdwODoYx3PI4ieopwGvIWOYUyip4NXAnuB54EPgDJ3b4p2aX18Dh676P5yYGD3VhxXfgx8B2iJbg9Ex+5YOPCcma0ws5uibXH551ZLkUqnububmb7ecBRmlgP8Hrjd3StaD3J0DDvm7s3AVDPrDywCTgm5pIRgZv8H2OvuK8xsdtj1JKiz3H2HmQ0Cnjez9a13xtOf22Qeie8ARrTaLoi2yZHtOXCqKPp7b7Rdx7MdZpZOJMAfdfc/RJt1DI+Bu5cBS4EziZyqPDD4aH18Dh676P5+wP5uLjVezALmmtkWIpcJzwN+go5dzNx9R/T3XiL/gJxBnP65TeYQXwaMi87YzACuBRaHXFMiWAx8Pvr488CfWrV/LjpT8wygvNWpp6QUva74S2Cdu9/XapeO4VGYWX50BI6Z9QYuJDKnYClwZbRb22N34JheCbzkSXoTDHe/090L3H00kb/XXnL3z6BjFxMzyzazPgceAxcBq4nXP7funrQ/wMXABiLX2v417Hri7Qd4HNgFNBK5zvMlItfKXgQ2Ai8AA6J9jchs/w+A94DCsOsP+wc4i8i1tVXAyujPxTqGMR27KcA70WO3Grgr2j4W+AewCXgK6BVtz4xub4ruHxv2Z4iHH2A28Gcdu2M6ZmOBd6M/aw5kQ7z+udUd20RERBJUMp9OFxERSWgKcRERkQSlEBcREUlQCnEREZEEpRAXERFJUApxEekyZjb7wKpZIhI8hbiIiEiCUoiLJCEzuz66XvdKM/t5dLGRKjP7UXT97hfNLD/ad6qZvRldK3lRq3WUTzSzFyyy5vfbZnZC9OVzzGyhma03s0e1IpZIcBTiIknGzMYD1wCz3H0q0Ax8BsgGlrv7ROAV4O7oU34D/Iu7TyFyR6oD7Y8C8z2y5vfHiNzdDyKrtd0OTCBy96tZgX8okSSlVcxEks/5wGnAsugguTeRxRxagCeifX4H/MHM+gH93f2VaPsjwFPRe0sPd/dFAO5eBxB9vX+4e1F0eyUwGngt+I8lknwU4iLJx4BH3P3OQxrN/q1Nv87ek7m+1eNm9PeMSGB0Ol0k+bwIXBldKxkzG2Bmo4j8fXBglatPA6+5ezlQamZnR9s/C7zi7pVAkZldGn2NXmaW1a2fQkT0L2SRZOPua83se8BzZpZCZJW6W4BqYEZ0314i180hsuziA9GQ3gx8Idr+WeDnZnZP9DWu6saPISKgVcxEJMLMqtw9J+w6RCR2Op0uIiKSoDQSFxERSVAaiYuIiCQohbiIiEiCUoiLiIgkKIW4iIhIglKIi4iIJCiFuIiISIL6/wE+pRVzGupurgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graduate student Q2\n",
        "# first see how model3 predict the output\n",
        "predictions = model3.predict(XVALID)\n",
        "print(predictions[:10].T)\n",
        "print(YVALID[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1botDalxYD",
        "outputId": "6868df29-d876-4698-c38e-75e54c18adb7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.28 0.28 0.28 1.00 0.28 0.67 0.40 0.59 0.28 0.99]]\n",
            "[0.00 0.00 0.00 1.00 0.00 1.00 1.00 1.00 0.00 1.00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_prediction_function(model,data):\n",
        "  w =[None]*6\n",
        "  for i in range(6):  \n",
        "    w[i] = model.layers[3].get_weights()[0][i]\n",
        "    bias = model.layers[3].get_weights()[1]   \n",
        "  z = 0\n",
        "  for i in range(6):\n",
        "    z = z + data[:,i]*w[i]\n",
        "  z = z + bias\n",
        "  result = 1/(1+np.exp(-z))\n",
        "  return result \n",
        "  # this one isn't working due to some weird errors"
      ],
      "metadata": {
        "id": "zP_XmHPm3-Vt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_predict(final_best_model, XVALID):\n",
        "#parameters of 4 layers\n",
        "# without doing iteration, this is manually doing prediction according to my layers situation\n",
        "    W0 = final_best_model.get_weights()[0]\n",
        "    b0 = final_best_model.get_weights()[1]\n",
        "      \n",
        "    W1 = final_best_model.get_weights()[2]\n",
        "    b1 = final_best_model.get_weights()[3]\n",
        "\n",
        "    W2 = final_best_model.get_weights()[4]\n",
        "    b2 = final_best_model.get_weights()[5]\n",
        "\n",
        "    W3 = final_best_model.get_weights()[6]\n",
        "    b3 = final_best_model.get_weights()[7]\n",
        "\n",
        "    L1 = np.dot(XVALID,W0)+b0\n",
        "    X2 = np.maximum(L1,0)\n",
        "\n",
        "    L2 = np.dot(X2,W1)+b1\n",
        "    X3 = np.maximum(L2,0)\n",
        "\n",
        "    L3 = np.dot(X3,W2)+b2\n",
        "    X4 = np.maximum(L3,0)\n",
        "\n",
        "    L4 = np.dot(X4,W3)+b3\n",
        "    print(L4)\n",
        "\n",
        "    # Sigmoid\n",
        "    output = 1/(1+np.exp(-L4))\n",
        "    return output"
      ],
      "metadata": {
        "id": "Dw1gZ8HYoZmh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_pre = my_predict(model3, XVALID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf9584pxyWkq",
        "outputId": "cbdb8b7c-caa5-43ab-c670-e9793f99d0b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [24.81]\n",
            " [-0.93]\n",
            " [0.69]\n",
            " [-0.42]\n",
            " [0.37]\n",
            " [-0.93]\n",
            " [4.40]\n",
            " [-0.93]\n",
            " [0.96]\n",
            " [20.79]\n",
            " [-0.93]\n",
            " [3.93]\n",
            " [-0.35]\n",
            " [24.29]\n",
            " [0.45]\n",
            " [0.55]\n",
            " [28.59]\n",
            " [11.78]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.50]\n",
            " [7.82]\n",
            " [34.01]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [1.84]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [8.96]\n",
            " [-0.93]\n",
            " [-0.50]\n",
            " [11.28]\n",
            " [0.23]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [17.68]\n",
            " [19.85]\n",
            " [22.74]\n",
            " [1.96]\n",
            " [1.31]\n",
            " [1.31]\n",
            " [1.31]\n",
            " [54.12]\n",
            " [-0.93]\n",
            " [-0.85]\n",
            " [0.76]\n",
            " [19.76]\n",
            " [1.67]\n",
            " [-0.93]\n",
            " [7.73]\n",
            " [4.71]\n",
            " [-0.93]\n",
            " [7.73]\n",
            " [18.22]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [20.19]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [30.53]\n",
            " [3.33]\n",
            " [19.28]\n",
            " [3.63]\n",
            " [34.20]\n",
            " [54.12]\n",
            " [28.48]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [8.53]\n",
            " [-0.57]\n",
            " [31.26]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.50]\n",
            " [-0.93]\n",
            " [38.44]\n",
            " [1.14]\n",
            " [1.31]\n",
            " [0.37]\n",
            " [-0.93]\n",
            " [9.48]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.50]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [4.40]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [4.40]\n",
            " [3.93]\n",
            " [1.14]\n",
            " [28.59]\n",
            " [-0.93]\n",
            " [7.54]\n",
            " [-0.93]\n",
            " [54.12]\n",
            " [-0.93]\n",
            " [10.15]\n",
            " [-0.93]\n",
            " [-0.65]\n",
            " [-0.93]\n",
            " [-0.81]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [0.14]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [22.74]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [20.70]\n",
            " [-0.93]\n",
            " [0.37]\n",
            " [-0.93]\n",
            " [0.78]\n",
            " [1.71]\n",
            " [-0.93]\n",
            " [30.53]\n",
            " [-0.93]\n",
            " [1.31]\n",
            " [1.23]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [27.92]\n",
            " [2.89]\n",
            " [-0.93]\n",
            " [34.01]\n",
            " [0.78]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [38.44]\n",
            " [-0.22]\n",
            " [-0.93]\n",
            " [1.23]\n",
            " [3.64]\n",
            " [23.30]\n",
            " [-0.93]\n",
            " [0.57]\n",
            " [0.67]\n",
            " [2.18]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [1.71]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [4.66]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [20.79]\n",
            " [3.78]\n",
            " [0.87]\n",
            " [-0.93]\n",
            " [3.13]\n",
            " [-0.93]\n",
            " [1.15]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [7.82]\n",
            " [4.40]\n",
            " [-0.93]\n",
            " [0.76]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [40.91]\n",
            " [9.12]\n",
            " [-0.93]\n",
            " [3.90]\n",
            " [0.78]\n",
            " [6.52]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [0.37]\n",
            " [5.10]\n",
            " [-0.93]\n",
            " [6.65]\n",
            " [0.37]\n",
            " [4.71]\n",
            " [-0.93]\n",
            " [-0.93]\n",
            " [-0.67]\n",
            " [1.55]\n",
            " [3.16]\n",
            " [-0.60]\n",
            " [-0.93]\n",
            " [-0.38]\n",
            " [1.48]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"my predcition: \", my_pre[:10].T)\n",
        "print(\"model.predict: \", predictions[:10].T)\n",
        "print(\"true value: \", YVALID[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11CQjb6OleTN",
        "outputId": "29b4af9c-6d84-48f0-db27-68d0ed72a87d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my predcition:  [[0.28 0.28 0.28 1.00 0.28 0.67 0.40 0.59 0.28 0.99]]\n",
            "model.predict:  [[0.28 0.28 0.28 1.00 0.28 0.67 0.40 0.59 0.28 0.99]]\n",
            "true value:  [0.00 0.00 0.00 1.00 0.00 1.00 1.00 1.00 0.00 1.00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/Phrase_3_report.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4WEuQLJDl2KZ",
        "outputId": "41cfc21d-01eb-4ee7-e777-c9c7feafb2e2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern '/content/Phrase_3_report.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            `Exporter` class\n",
            "    Default: 'html'\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the \n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current \n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy \n",
            "            of reveal.js. \n",
            "            For speaker notes to work, this must be a relative path to a local \n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb\n",
            "\n",
            "            which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "\n",
            "            You can specify the export format with `--to`.\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "            can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of \n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ddbe3e39186c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jupyter nbconvert --to html /content/Phrase_3_report.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'jupyter nbconvert --to html /content/Phrase_3_report.ipynb' returned non-zero exit status 255."
          ]
        }
      ]
    }
  ]
}