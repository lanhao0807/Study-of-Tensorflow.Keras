{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "phrase4Report.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "ATWGYgNYdL5N",
        "outputId": "643bb622-222d-4407-fcc8-3bcbb7b0cd9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f800c28f-5214-434c-8ec7-d94350df9f14\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f800c28f-5214-434c-8ec7-d94350df9f14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Maternal_Health_Risk_Data_Set.csv to Maternal_Health_Risk_Data_Set (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "x = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "data = pd.read_csv('Maternal_Health_Risk_Data_Set.csv', delimiter = ',')\n",
        "data.head()\n",
        "# Binary classification is done in phrase 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OlkS7cY4gnoH",
        "outputId": "71a1d4db-6846-4bc6-a415-b11ee984fedd"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  in-Risk\n",
              "0   25         130           80  15.0      98.0         86        1\n",
              "1   35         140           90  13.0      98.0         70        1\n",
              "2   29          90           70   8.0     100.0         80        1\n",
              "3   30         140           85   7.0      98.0         70        1\n",
              "4   35         120           60   6.1      98.0         76        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7399793-6ba4-45c7-8e88-c81e847c3f38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>in-Risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>13.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>8.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>140</td>\n",
              "      <td>85</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7399793-6ba4-45c7-8e88-c81e847c3f38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7399793-6ba4-45c7-8e88-c81e847c3f38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7399793-6ba4-45c7-8e88-c81e847c3f38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataset = np.genfromtxt('Maternal_Health_Risk_Data_Set.csv',delimiter=',', skip_header = True)\n",
        "np.set_printoptions(formatter = {'float': '{:0.2f}'.format})\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxrmI1VUgo4n",
        "outputId": "6378e07d-0cc7-4788-bfdf-2a6989e5ec5f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1014, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "np.random.shuffle(dataset)"
      ],
      "metadata": {
        "id": "ksbS2MR0gs0e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation, 20% validation set and 80% training \n",
        "index_20percent = int(0.2 * len(dataset[:, 0]))\n",
        "print(index_20percent)\n",
        "\n",
        "# X train\n",
        "Xage_T = dataset[index_20percent:, 0]\n",
        "XsBP_T = dataset[index_20percent:, 1]\n",
        "XdBP_T = dataset[index_20percent:, 2]\n",
        "Xbs_T = dataset[index_20percent:, 3]\n",
        "Xbt_T = dataset[index_20percent:, 4]\n",
        "Xhr_T = dataset[index_20percent:, 5]\n",
        "\n",
        "# X valid\n",
        "Xage_V = dataset[:index_20percent, 0]\n",
        "XsBP_V = dataset[:index_20percent, 1]\n",
        "XdBP_V = dataset[:index_20percent, 2]\n",
        "Xbs_V = dataset[:index_20percent, 3]\n",
        "Xbt_V = dataset[:index_20percent, 4]\n",
        "Xhr_V = dataset[:index_20percent, 5]\n",
        "\n",
        "XVALID = dataset[:index_20percent, :-1]\n",
        "XTRAIN = dataset[index_20percent:, :-1]\n",
        "YVALID = dataset[:index_20percent, -1]\n",
        "YTRAIN = dataset[index_20percent:, -1]\n",
        "\n",
        "# without age\n",
        "X_T_no_age = np.delete(XTRAIN, [0] , 1)\n",
        "X_V_no_age = np.delete(XVALID, [0] , 1)\n",
        "# no age and bodyTemp\n",
        "X_T_no_age_bt = np.delete(XTRAIN,[0,4], 1)\n",
        "X_V_no_age_bt = np.delete(XVALID,[0,4], 1)\n",
        "# no age, bodytemp, heartrate\n",
        "X_T_no_age_bt_hr = np.delete(XTRAIN,[0,4,5], 1)\n",
        "X_V_no_age_bt_hr = np.delete(XVALID,[0,4,5], 1)\n",
        "# no age, bodytemp, heartrate, dBP\n",
        "X_T_no_age_bt_hr_dBP = np.delete(XTRAIN,[0,2,4,5], 1)\n",
        "X_V_no_age_bt_hr_dBP = np.delete(XVALID,[0,2,4,5], 1)\n",
        "print(X_V_no_age_bt_hr_dBP)\n",
        "print(XVALID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFwJEhH4h5Ok",
        "outputId": "fbdf22aa-bb23-4164-b6de-10dd14dc2938"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202\n",
            "[[0.08 -0.09]\n",
            " [0.08 -0.14]\n",
            " [-0.14 -0.13]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.09]\n",
            " [-0.41 -0.14]\n",
            " [-0.14 -0.13]\n",
            " [-0.25 -0.15]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.09]\n",
            " [0.19 0.72]\n",
            " [0.08 -0.06]\n",
            " [-0.25 -0.09]\n",
            " [-0.14 -0.09]\n",
            " [-0.25 -0.06]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.06]\n",
            " [0.19 -0.19]\n",
            " [0.02 -0.09]\n",
            " [-0.14 -0.06]\n",
            " [-0.14 -0.06]\n",
            " [-0.48 -0.06]\n",
            " [-0.25 -0.13]\n",
            " [-0.31 0.03]\n",
            " [0.08 0.03]\n",
            " [-0.25 0.03]\n",
            " [0.08 -0.13]\n",
            " [-0.14 -0.09]\n",
            " [0.08 -0.09]\n",
            " [-0.25 -0.13]\n",
            " [0.30 0.72]\n",
            " [0.30 0.80]\n",
            " [0.30 0.49]\n",
            " [0.08 0.03]\n",
            " [0.08 -0.09]\n",
            " [0.08 0.18]\n",
            " [0.08 -0.09]\n",
            " [0.30 -0.11]\n",
            " [-0.25 -0.13]\n",
            " [0.08 -0.09]\n",
            " [0.08 -0.13]\n",
            " [0.30 -0.09]\n",
            " [0.30 -0.05]\n",
            " [-0.14 -0.14]\n",
            " [0.08 0.18]\n",
            " [0.08 -0.06]\n",
            " [0.19 0.72]\n",
            " [-0.25 -0.09]\n",
            " [0.08 0.72]\n",
            " [0.08 -0.19]\n",
            " [0.08 0.49]\n",
            " [-0.14 -0.09]\n",
            " [0.08 -0.09]\n",
            " [0.08 -0.06]\n",
            " [-0.14 -0.09]\n",
            " [-0.25 0.18]\n",
            " [0.19 -0.13]\n",
            " [-0.25 -0.09]\n",
            " [-0.14 0.18]\n",
            " [-0.25 -0.07]\n",
            " [0.19 0.26]\n",
            " [0.08 0.18]\n",
            " [-0.14 -0.09]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.09]\n",
            " [-0.48 -0.20]\n",
            " [0.08 -0.05]\n",
            " [0.08 0.26]\n",
            " [0.08 -0.14]\n",
            " [0.08 0.11]\n",
            " [-0.25 -0.09]\n",
            " [0.19 0.57]\n",
            " [0.52 0.80]\n",
            " [0.08 -0.07]\n",
            " [0.19 -0.06]\n",
            " [0.19 0.57]\n",
            " [-0.25 -0.13]\n",
            " [-0.14 -0.13]\n",
            " [0.08 -0.09]\n",
            " [0.19 -0.09]\n",
            " [0.08 0.18]\n",
            " [0.08 -0.09]\n",
            " [0.30 0.49]\n",
            " [-0.03 -0.13]\n",
            " [0.08 -0.15]\n",
            " [-0.03 -0.13]\n",
            " [0.08 -0.14]\n",
            " [-0.14 -0.17]\n",
            " [0.30 0.64]\n",
            " [-0.42 -0.19]\n",
            " [0.08 -0.14]\n",
            " [0.08 -0.09]\n",
            " [0.08 0.49]\n",
            " [0.08 -0.13]\n",
            " [-0.31 -0.13]\n",
            " [0.30 -0.14]\n",
            " [0.52 0.80]\n",
            " [0.19 -0.15]\n",
            " [-0.25 -0.13]\n",
            " [0.19 0.57]\n",
            " [0.19 0.26]\n",
            " [-0.14 -0.09]\n",
            " [-0.31 -0.06]\n",
            " [0.30 -0.14]\n",
            " [-0.14 -0.11]\n",
            " [-0.25 -0.09]\n",
            " [0.08 -0.06]\n",
            " [0.30 0.80]\n",
            " [0.08 -0.07]\n",
            " [-0.03 0.34]\n",
            " [-0.41 -0.09]\n",
            " [0.19 -0.07]\n",
            " [0.08 -0.19]\n",
            " [0.08 -0.09]\n",
            " [0.30 0.80]\n",
            " [-0.25 -0.12]\n",
            " [0.19 0.57]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.09]\n",
            " [-0.14 -0.14]\n",
            " [-0.14 -0.12]\n",
            " [-0.31 0.18]\n",
            " [-0.03 -0.14]\n",
            " [0.30 -0.12]\n",
            " [-0.25 -0.09]\n",
            " [0.08 -0.09]\n",
            " [-0.25 -0.11]\n",
            " [-0.25 -0.05]\n",
            " [0.52 0.80]\n",
            " [0.08 0.18]\n",
            " [0.08 -0.13]\n",
            " [-0.25 -0.05]\n",
            " [0.08 -0.09]\n",
            " [0.19 -0.09]\n",
            " [0.08 0.49]\n",
            " [0.08 -0.07]\n",
            " [0.30 -0.13]\n",
            " [0.08 -0.09]\n",
            " [-0.14 -0.12]\n",
            " [0.30 0.72]\n",
            " [0.30 0.49]\n",
            " [0.30 0.26]\n",
            " [-0.14 -0.13]\n",
            " [0.08 -0.06]\n",
            " [-0.25 0.03]\n",
            " [0.30 0.80]\n",
            " [0.08 -0.19]\n",
            " [-0.14 -0.09]\n",
            " [0.52 0.80]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.19]\n",
            " [0.19 -0.12]\n",
            " [-0.42 -0.09]\n",
            " [0.19 -0.06]\n",
            " [0.08 -0.13]\n",
            " [-0.31 0.03]\n",
            " [0.08 0.18]\n",
            " [0.30 0.34]\n",
            " [0.19 0.57]\n",
            " [0.08 -0.14]\n",
            " [-0.31 -0.18]\n",
            " [0.08 -0.13]\n",
            " [-0.14 -0.13]\n",
            " [-0.03 -0.06]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.09]\n",
            " [0.08 -0.09]\n",
            " [0.08 0.18]\n",
            " [0.08 -0.13]\n",
            " [0.19 -0.15]\n",
            " [-0.14 -0.13]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.13]\n",
            " [-0.25 -0.06]\n",
            " [0.30 0.49]\n",
            " [-0.25 0.03]\n",
            " [-0.25 -0.15]\n",
            " [-0.25 -0.09]\n",
            " [0.08 -0.14]\n",
            " [0.08 0.26]\n",
            " [0.08 -0.14]\n",
            " [0.08 0.49]\n",
            " [0.08 -0.09]\n",
            " [0.08 0.18]\n",
            " [0.30 0.49]\n",
            " [-0.31 0.03]\n",
            " [0.08 -0.13]\n",
            " [0.08 -0.13]\n",
            " [0.08 0.18]\n",
            " [-0.14 -0.11]\n",
            " [0.08 0.49]\n",
            " [-0.14 -0.19]\n",
            " [-0.25 -0.13]\n",
            " [-0.25 -0.09]\n",
            " [0.08 -0.20]\n",
            " [0.02 -0.13]\n",
            " [0.08 0.18]\n",
            " [0.08 -0.13]\n",
            " [-0.14 -0.06]\n",
            " [0.08 -0.13]\n",
            " [0.19 0.57]\n",
            " [0.08 -0.09]]\n",
            "[[-0.13 0.08 0.27 -0.09 -0.14 0.09]\n",
            " [0.04 0.08 0.08 -0.14 -0.14 -0.05]\n",
            " [0.09 -0.14 -0.12 -0.13 -0.14 -0.17]\n",
            " ...\n",
            " [0.09 0.08 0.08 -0.13 -0.14 0.05]\n",
            " [0.34 0.19 0.08 0.57 0.66 0.02]\n",
            " [0.04 0.08 0.27 -0.09 -0.14 -0.05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = XTRAIN.mean(axis = 0)\n",
        "XTRAIN -= mean\n",
        "range = XTRAIN.max(axis = 0) - XTRAIN.min(axis = 0)\n",
        "XTRAIN /= range\n",
        "# mean normalization just like in phrase 1\n",
        "\n",
        "XVALID -= mean\n",
        "XVALID /= range"
      ],
      "metadata": {
        "id": "p_F6NbWpRcN9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IMTmWGlcj9Jr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= Sequential() # multi-layer network\n",
        "model.add(Dense(8, input_dim= len(XTRAIN[0,:])-4, activation = 'relu' ))\n",
        "model.add(Dense(4, activation = 'relu' ))\n",
        "model.add(Dense(2, activation = 'relu' ))\n",
        "model.add(Dense(1, activation = 'sigmoid')) \n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics='accuracy' )\n",
        "# the best model found in phrase 3"
      ],
      "metadata": {
        "id": "a2gmq6gqi_Xa"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# File name must be in quotes\n",
        "callback_a = ModelCheckpoint(filepath = 'Maternal_Health_Risk_Data_Set.csv', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "# The patience value can be 10, 20, 100, etc. depending on when your model starts to overfit\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=50, verbose=1)"
      ],
      "metadata": {
        "id": "k6PvtDgzYWir"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_T_no_age_bt_hr_dBP, YTRAIN, validation_data=(X_V_no_age_bt_hr_dBP, YVALID), batch_size=1,epochs=512, callbacks = [callback_a, callback_b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGstPmJaYbWJ",
        "outputId": "6ce4546b-7914-4d68-b443-1e075e57e7a1"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/512\n",
            "806/812 [============================>.] - ETA: 0s - loss: 0.6862 - accuracy: 0.5918\n",
            "Epoch 1: val_loss improved from inf to 0.67629, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.6862 - accuracy: 0.5911 - val_loss: 0.6763 - val_accuracy: 0.6040\n",
            "Epoch 2/512\n",
            "785/812 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.6127\n",
            "Epoch 2: val_loss improved from 0.67629 to 0.65537, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.6721 - accuracy: 0.6182 - val_loss: 0.6554 - val_accuracy: 0.7228\n",
            "Epoch 3/512\n",
            "788/812 [============================>.] - ETA: 0s - loss: 0.6567 - accuracy: 0.6447\n",
            "Epoch 3: val_loss improved from 0.65537 to 0.63644, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.6562 - accuracy: 0.6502 - val_loss: 0.6364 - val_accuracy: 0.7228\n",
            "Epoch 4/512\n",
            "803/812 [============================>.] - ETA: 0s - loss: 0.6427 - accuracy: 0.6563\n",
            "Epoch 4: val_loss improved from 0.63644 to 0.61699, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.6421 - accuracy: 0.6564 - val_loss: 0.6170 - val_accuracy: 0.7376\n",
            "Epoch 5/512\n",
            "791/812 [============================>.] - ETA: 0s - loss: 0.6287 - accuracy: 0.6561\n",
            "Epoch 5: val_loss improved from 0.61699 to 0.60094, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.6539 - val_loss: 0.6009 - val_accuracy: 0.7376\n",
            "Epoch 6/512\n",
            "786/812 [============================>.] - ETA: 0s - loss: 0.6178 - accuracy: 0.6590\n",
            "Epoch 6: val_loss improved from 0.60094 to 0.58510, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.6166 - accuracy: 0.6601 - val_loss: 0.5851 - val_accuracy: 0.7228\n",
            "Epoch 7/512\n",
            "778/812 [===========================>..] - ETA: 0s - loss: 0.6037 - accuracy: 0.6581\n",
            "Epoch 7: val_loss improved from 0.58510 to 0.57406, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.6047 - accuracy: 0.6564 - val_loss: 0.5741 - val_accuracy: 0.7525\n",
            "Epoch 8/512\n",
            "791/812 [============================>.] - ETA: 0s - loss: 0.5974 - accuracy: 0.6612\n",
            "Epoch 8: val_loss improved from 0.57406 to 0.56081, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5964 - accuracy: 0.6589 - val_loss: 0.5608 - val_accuracy: 0.7376\n",
            "Epoch 9/512\n",
            "791/812 [============================>.] - ETA: 0s - loss: 0.5874 - accuracy: 0.6612\n",
            "Epoch 9: val_loss improved from 0.56081 to 0.54882, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.5867 - accuracy: 0.6626 - val_loss: 0.5488 - val_accuracy: 0.7327\n",
            "Epoch 10/512\n",
            "796/812 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.6608\n",
            "Epoch 10: val_loss improved from 0.54882 to 0.54009, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.5793 - accuracy: 0.6564 - val_loss: 0.5401 - val_accuracy: 0.7277\n",
            "Epoch 11/512\n",
            "786/812 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.6552\n",
            "Epoch 11: val_loss improved from 0.54009 to 0.53128, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.5719 - accuracy: 0.6515 - val_loss: 0.5313 - val_accuracy: 0.7277\n",
            "Epoch 12/512\n",
            "791/812 [============================>.] - ETA: 0s - loss: 0.5645 - accuracy: 0.6536\n",
            "Epoch 12: val_loss improved from 0.53128 to 0.52414, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.6515 - val_loss: 0.5241 - val_accuracy: 0.7277\n",
            "Epoch 13/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.6553\n",
            "Epoch 13: val_loss improved from 0.52414 to 0.51781, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.5593 - accuracy: 0.6564 - val_loss: 0.5178 - val_accuracy: 0.7624\n",
            "Epoch 14/512\n",
            "783/812 [===========================>..] - ETA: 0s - loss: 0.5569 - accuracy: 0.6526\n",
            "Epoch 14: val_loss improved from 0.51781 to 0.51384, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5543 - accuracy: 0.6539 - val_loss: 0.5138 - val_accuracy: 0.7178\n",
            "Epoch 15/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.5475 - accuracy: 0.6747\n",
            "Epoch 15: val_loss improved from 0.51384 to 0.50514, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.6700 - val_loss: 0.5051 - val_accuracy: 0.7228\n",
            "Epoch 16/512\n",
            "790/812 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.6709\n",
            "Epoch 16: val_loss improved from 0.50514 to 0.49832, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.6724 - val_loss: 0.4983 - val_accuracy: 0.7624\n",
            "Epoch 17/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.5399 - accuracy: 0.6481\n",
            "Epoch 17: val_loss improved from 0.49832 to 0.49632, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.6490 - val_loss: 0.4963 - val_accuracy: 0.7228\n",
            "Epoch 18/512\n",
            "783/812 [===========================>..] - ETA: 0s - loss: 0.5354 - accuracy: 0.6692\n",
            "Epoch 18: val_loss improved from 0.49632 to 0.48719, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.6712 - val_loss: 0.4872 - val_accuracy: 0.7624\n",
            "Epoch 19/512\n",
            "794/812 [============================>.] - ETA: 0s - loss: 0.5318 - accuracy: 0.6763\n",
            "Epoch 19: val_loss improved from 0.48719 to 0.48522, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.6773 - val_loss: 0.4852 - val_accuracy: 0.7822\n",
            "Epoch 20/512\n",
            "811/812 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.6720\n",
            "Epoch 20: val_loss improved from 0.48522 to 0.48480, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.6724 - val_loss: 0.4848 - val_accuracy: 0.7525\n",
            "Epoch 21/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.5248 - accuracy: 0.6607\n",
            "Epoch 21: val_loss improved from 0.48480 to 0.47918, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5272 - accuracy: 0.6638 - val_loss: 0.4792 - val_accuracy: 0.7525\n",
            "Epoch 22/512\n",
            "795/812 [============================>.] - ETA: 0s - loss: 0.5209 - accuracy: 0.6906\n",
            "Epoch 22: val_loss improved from 0.47918 to 0.47712, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5231 - accuracy: 0.6860 - val_loss: 0.4771 - val_accuracy: 0.7624\n",
            "Epoch 23/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.5225 - accuracy: 0.7071\n",
            "Epoch 23: val_loss improved from 0.47712 to 0.47268, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5203 - accuracy: 0.7081 - val_loss: 0.4727 - val_accuracy: 0.7723\n",
            "Epoch 24/512\n",
            "812/812 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.6970\n",
            "Epoch 24: val_loss did not improve from 0.47268\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5180 - accuracy: 0.6970 - val_loss: 0.4754 - val_accuracy: 0.7525\n",
            "Epoch 25/512\n",
            "803/812 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.6824\n",
            "Epoch 25: val_loss improved from 0.47268 to 0.46955, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5165 - accuracy: 0.6835 - val_loss: 0.4695 - val_accuracy: 0.7475\n",
            "Epoch 26/512\n",
            "780/812 [===========================>..] - ETA: 0s - loss: 0.5128 - accuracy: 0.7038\n",
            "Epoch 26: val_loss improved from 0.46955 to 0.46755, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5143 - accuracy: 0.7007 - val_loss: 0.4676 - val_accuracy: 0.7475\n",
            "Epoch 27/512\n",
            "781/812 [===========================>..] - ETA: 0s - loss: 0.5123 - accuracy: 0.7004\n",
            "Epoch 27: val_loss did not improve from 0.46755\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5120 - accuracy: 0.6983 - val_loss: 0.4699 - val_accuracy: 0.7574\n",
            "Epoch 28/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.7001\n",
            "Epoch 28: val_loss did not improve from 0.46755\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5089 - accuracy: 0.7007 - val_loss: 0.4735 - val_accuracy: 0.7327\n",
            "Epoch 29/512\n",
            "802/812 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.6995\n",
            "Epoch 29: val_loss improved from 0.46755 to 0.46554, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5091 - accuracy: 0.7007 - val_loss: 0.4655 - val_accuracy: 0.7921\n",
            "Epoch 30/512\n",
            "805/812 [============================>.] - ETA: 0s - loss: 0.5095 - accuracy: 0.6894\n",
            "Epoch 30: val_loss improved from 0.46554 to 0.46178, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5077 - accuracy: 0.6921 - val_loss: 0.4618 - val_accuracy: 0.7525\n",
            "Epoch 31/512\n",
            "812/812 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.6958\n",
            "Epoch 31: val_loss improved from 0.46178 to 0.45862, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5061 - accuracy: 0.6958 - val_loss: 0.4586 - val_accuracy: 0.7475\n",
            "Epoch 32/512\n",
            "802/812 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7020\n",
            "Epoch 32: val_loss improved from 0.45862 to 0.45854, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5035 - accuracy: 0.7007 - val_loss: 0.4585 - val_accuracy: 0.7525\n",
            "Epoch 33/512\n",
            "795/812 [============================>.] - ETA: 0s - loss: 0.5038 - accuracy: 0.6943\n",
            "Epoch 33: val_loss improved from 0.45854 to 0.45787, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.6958 - val_loss: 0.4579 - val_accuracy: 0.7475\n",
            "Epoch 34/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.5003 - accuracy: 0.7058\n",
            "Epoch 34: val_loss did not improve from 0.45787\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5001 - accuracy: 0.7069 - val_loss: 0.4666 - val_accuracy: 0.7871\n",
            "Epoch 35/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.4947 - accuracy: 0.7015\n",
            "Epoch 35: val_loss improved from 0.45787 to 0.45650, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5024 - accuracy: 0.6983 - val_loss: 0.4565 - val_accuracy: 0.7525\n",
            "Epoch 36/512\n",
            "803/812 [============================>.] - ETA: 0s - loss: 0.5006 - accuracy: 0.6912\n",
            "Epoch 36: val_loss improved from 0.45650 to 0.45395, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.5013 - accuracy: 0.6921 - val_loss: 0.4539 - val_accuracy: 0.7475\n",
            "Epoch 37/512\n",
            "788/812 [============================>.] - ETA: 0s - loss: 0.5011 - accuracy: 0.6916\n",
            "Epoch 37: val_loss did not improve from 0.45395\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4996 - accuracy: 0.6909 - val_loss: 0.4625 - val_accuracy: 0.7475\n",
            "Epoch 38/512\n",
            "782/812 [===========================>..] - ETA: 0s - loss: 0.5026 - accuracy: 0.6854\n",
            "Epoch 38: val_loss did not improve from 0.45395\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.6884 - val_loss: 0.4557 - val_accuracy: 0.7475\n",
            "Epoch 39/512\n",
            "801/812 [============================>.] - ETA: 0s - loss: 0.4995 - accuracy: 0.7041\n",
            "Epoch 39: val_loss improved from 0.45395 to 0.45342, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4989 - accuracy: 0.7044 - val_loss: 0.4534 - val_accuracy: 0.7574\n",
            "Epoch 40/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4963 - accuracy: 0.6901\n",
            "Epoch 40: val_loss did not improve from 0.45342\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4987 - accuracy: 0.6884 - val_loss: 0.4556 - val_accuracy: 0.7525\n",
            "Epoch 41/512\n",
            "778/812 [===========================>..] - ETA: 0s - loss: 0.4925 - accuracy: 0.7134\n",
            "Epoch 41: val_loss did not improve from 0.45342\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.7094 - val_loss: 0.4673 - val_accuracy: 0.8069\n",
            "Epoch 42/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4930 - accuracy: 0.7064\n",
            "Epoch 42: val_loss improved from 0.45342 to 0.45097, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4967 - accuracy: 0.7044 - val_loss: 0.4510 - val_accuracy: 0.7525\n",
            "Epoch 43/512\n",
            "789/812 [============================>.] - ETA: 0s - loss: 0.4937 - accuracy: 0.7060\n",
            "Epoch 43: val_loss did not improve from 0.45097\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4965 - accuracy: 0.6995 - val_loss: 0.4533 - val_accuracy: 0.7475\n",
            "Epoch 44/512\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.7012\n",
            "Epoch 44: val_loss improved from 0.45097 to 0.45094, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.7020 - val_loss: 0.4509 - val_accuracy: 0.7475\n",
            "Epoch 45/512\n",
            "794/812 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.6902\n",
            "Epoch 45: val_loss did not improve from 0.45094\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4961 - accuracy: 0.6921 - val_loss: 0.4525 - val_accuracy: 0.7475\n",
            "Epoch 46/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4974 - accuracy: 0.7039\n",
            "Epoch 46: val_loss did not improve from 0.45094\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4947 - accuracy: 0.7044 - val_loss: 0.4596 - val_accuracy: 0.7970\n",
            "Epoch 47/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4938 - accuracy: 0.6989\n",
            "Epoch 47: val_loss did not improve from 0.45094\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.6946 - val_loss: 0.4529 - val_accuracy: 0.7525\n",
            "Epoch 48/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4962 - accuracy: 0.7026\n",
            "Epoch 48: val_loss did not improve from 0.45094\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.7032 - val_loss: 0.4549 - val_accuracy: 0.7426\n",
            "Epoch 49/512\n",
            "776/812 [===========================>..] - ETA: 0s - loss: 0.4864 - accuracy: 0.7075\n",
            "Epoch 49: val_loss did not improve from 0.45094\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4917 - accuracy: 0.7007 - val_loss: 0.4611 - val_accuracy: 0.7970\n",
            "Epoch 50/512\n",
            "798/812 [============================>.] - ETA: 0s - loss: 0.4971 - accuracy: 0.6892\n",
            "Epoch 50: val_loss improved from 0.45094 to 0.44984, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4945 - accuracy: 0.6933 - val_loss: 0.4498 - val_accuracy: 0.7574\n",
            "Epoch 51/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4932 - accuracy: 0.6964\n",
            "Epoch 51: val_loss improved from 0.44984 to 0.44798, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4936 - accuracy: 0.6958 - val_loss: 0.4480 - val_accuracy: 0.7475\n",
            "Epoch 52/512\n",
            "803/812 [============================>.] - ETA: 0s - loss: 0.4931 - accuracy: 0.6986\n",
            "Epoch 52: val_loss did not improve from 0.44798\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4931 - accuracy: 0.7007 - val_loss: 0.4512 - val_accuracy: 0.7475\n",
            "Epoch 53/512\n",
            "785/812 [============================>.] - ETA: 0s - loss: 0.4961 - accuracy: 0.6904\n",
            "Epoch 53: val_loss did not improve from 0.44798\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.6958 - val_loss: 0.4508 - val_accuracy: 0.7426\n",
            "Epoch 54/512\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4915 - accuracy: 0.7025\n",
            "Epoch 54: val_loss did not improve from 0.44798\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4913 - accuracy: 0.7020 - val_loss: 0.4484 - val_accuracy: 0.7475\n",
            "Epoch 55/512\n",
            "795/812 [============================>.] - ETA: 0s - loss: 0.4960 - accuracy: 0.6855\n",
            "Epoch 55: val_loss improved from 0.44798 to 0.44551, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4922 - accuracy: 0.6897 - val_loss: 0.4455 - val_accuracy: 0.7475\n",
            "Epoch 56/512\n",
            "799/812 [============================>.] - ETA: 0s - loss: 0.4890 - accuracy: 0.7021\n",
            "Epoch 56: val_loss did not improve from 0.44551\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7032 - val_loss: 0.4484 - val_accuracy: 0.7574\n",
            "Epoch 57/512\n",
            "808/812 [============================>.] - ETA: 0s - loss: 0.4890 - accuracy: 0.7116\n",
            "Epoch 57: val_loss did not improve from 0.44551\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4903 - accuracy: 0.7081 - val_loss: 0.4531 - val_accuracy: 0.7921\n",
            "Epoch 58/512\n",
            "806/812 [============================>.] - ETA: 0s - loss: 0.4921 - accuracy: 0.6985\n",
            "Epoch 58: val_loss did not improve from 0.44551\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.6995 - val_loss: 0.4485 - val_accuracy: 0.7475\n",
            "Epoch 59/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.6927\n",
            "Epoch 59: val_loss did not improve from 0.44551\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4899 - accuracy: 0.6921 - val_loss: 0.4459 - val_accuracy: 0.7475\n",
            "Epoch 60/512\n",
            "801/812 [============================>.] - ETA: 0s - loss: 0.4898 - accuracy: 0.7041\n",
            "Epoch 60: val_loss did not improve from 0.44551\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4901 - accuracy: 0.7069 - val_loss: 0.4461 - val_accuracy: 0.7475\n",
            "Epoch 61/512\n",
            "812/812 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.7217\n",
            "Epoch 61: val_loss improved from 0.44551 to 0.44463, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7217 - val_loss: 0.4446 - val_accuracy: 0.7574\n",
            "Epoch 62/512\n",
            "781/812 [===========================>..] - ETA: 0s - loss: 0.4922 - accuracy: 0.7004\n",
            "Epoch 62: val_loss did not improve from 0.44463\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4896 - accuracy: 0.6995 - val_loss: 0.4453 - val_accuracy: 0.7475\n",
            "Epoch 63/512\n",
            "794/812 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.6977\n",
            "Epoch 63: val_loss did not improve from 0.44463\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.6958 - val_loss: 0.4459 - val_accuracy: 0.7475\n",
            "Epoch 64/512\n",
            "790/812 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.6899\n",
            "Epoch 64: val_loss improved from 0.44463 to 0.44363, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4890 - accuracy: 0.6909 - val_loss: 0.4436 - val_accuracy: 0.7475\n",
            "Epoch 65/512\n",
            "793/812 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.7049\n",
            "Epoch 65: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4883 - accuracy: 0.7044 - val_loss: 0.4452 - val_accuracy: 0.7475\n",
            "Epoch 66/512\n",
            "788/812 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.7043\n",
            "Epoch 66: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4895 - accuracy: 0.7007 - val_loss: 0.4449 - val_accuracy: 0.7475\n",
            "Epoch 67/512\n",
            "801/812 [============================>.] - ETA: 0s - loss: 0.4888 - accuracy: 0.6979\n",
            "Epoch 67: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.6958 - val_loss: 0.4449 - val_accuracy: 0.7525\n",
            "Epoch 68/512\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4870 - accuracy: 0.6975\n",
            "Epoch 68: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4873 - accuracy: 0.6970 - val_loss: 0.4567 - val_accuracy: 0.7376\n",
            "Epoch 69/512\n",
            "805/812 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.7019\n",
            "Epoch 69: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4858 - accuracy: 0.7032 - val_loss: 0.4455 - val_accuracy: 0.7475\n",
            "Epoch 70/512\n",
            "796/812 [============================>.] - ETA: 0s - loss: 0.4898 - accuracy: 0.6997\n",
            "Epoch 70: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4893 - accuracy: 0.7020 - val_loss: 0.4456 - val_accuracy: 0.7475\n",
            "Epoch 71/512\n",
            "789/812 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.6907\n",
            "Epoch 71: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4883 - accuracy: 0.6860 - val_loss: 0.4443 - val_accuracy: 0.7525\n",
            "Epoch 72/512\n",
            "793/812 [============================>.] - ETA: 0s - loss: 0.4856 - accuracy: 0.6910\n",
            "Epoch 72: val_loss did not improve from 0.44363\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4887 - accuracy: 0.6860 - val_loss: 0.4465 - val_accuracy: 0.7525\n",
            "Epoch 73/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.6952\n",
            "Epoch 73: val_loss improved from 0.44363 to 0.44299, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4883 - accuracy: 0.6921 - val_loss: 0.4430 - val_accuracy: 0.7475\n",
            "Epoch 74/512\n",
            "812/812 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.7069\n",
            "Epoch 74: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4863 - accuracy: 0.7069 - val_loss: 0.4488 - val_accuracy: 0.7475\n",
            "Epoch 75/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4884 - accuracy: 0.7051\n",
            "Epoch 75: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4877 - accuracy: 0.7057 - val_loss: 0.4575 - val_accuracy: 0.8119\n",
            "Epoch 76/512\n",
            "801/812 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.7016\n",
            "Epoch 76: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7020 - val_loss: 0.4475 - val_accuracy: 0.7426\n",
            "Epoch 77/512\n",
            "785/812 [============================>.] - ETA: 0s - loss: 0.4849 - accuracy: 0.6955\n",
            "Epoch 77: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.6921 - val_loss: 0.4454 - val_accuracy: 0.7475\n",
            "Epoch 78/512\n",
            "800/812 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.6975\n",
            "Epoch 78: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.6958 - val_loss: 0.4433 - val_accuracy: 0.7525\n",
            "Epoch 79/512\n",
            "789/812 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.7022\n",
            "Epoch 79: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4863 - accuracy: 0.6995 - val_loss: 0.4468 - val_accuracy: 0.7525\n",
            "Epoch 80/512\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.7012\n",
            "Epoch 80: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4865 - accuracy: 0.7020 - val_loss: 0.4443 - val_accuracy: 0.7525\n",
            "Epoch 81/512\n",
            "789/812 [============================>.] - ETA: 0s - loss: 0.4881 - accuracy: 0.6895\n",
            "Epoch 81: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.6872 - val_loss: 0.4456 - val_accuracy: 0.7475\n",
            "Epoch 82/512\n",
            "804/812 [============================>.] - ETA: 0s - loss: 0.4856 - accuracy: 0.6940\n",
            "Epoch 82: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.6958 - val_loss: 0.4458 - val_accuracy: 0.7475\n",
            "Epoch 83/512\n",
            "804/812 [============================>.] - ETA: 0s - loss: 0.4890 - accuracy: 0.7114\n",
            "Epoch 83: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7118 - val_loss: 0.4453 - val_accuracy: 0.7475\n",
            "Epoch 84/512\n",
            "795/812 [============================>.] - ETA: 0s - loss: 0.4873 - accuracy: 0.6881\n",
            "Epoch 84: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.6897 - val_loss: 0.4439 - val_accuracy: 0.7525\n",
            "Epoch 85/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.7014\n",
            "Epoch 85: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4861 - accuracy: 0.6983 - val_loss: 0.4478 - val_accuracy: 0.7475\n",
            "Epoch 86/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.4854 - accuracy: 0.7079\n",
            "Epoch 86: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4872 - accuracy: 0.7057 - val_loss: 0.4436 - val_accuracy: 0.7525\n",
            "Epoch 87/512\n",
            "789/812 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.7072\n",
            "Epoch 87: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7069 - val_loss: 0.4434 - val_accuracy: 0.7525\n",
            "Epoch 88/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.4879 - accuracy: 0.6806\n",
            "Epoch 88: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.6847 - val_loss: 0.4448 - val_accuracy: 0.7475\n",
            "Epoch 89/512\n",
            "794/812 [============================>.] - ETA: 0s - loss: 0.4855 - accuracy: 0.7015\n",
            "Epoch 89: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.7032 - val_loss: 0.4440 - val_accuracy: 0.7426\n",
            "Epoch 90/512\n",
            "810/812 [============================>.] - ETA: 0s - loss: 0.4857 - accuracy: 0.7012\n",
            "Epoch 90: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7020 - val_loss: 0.4490 - val_accuracy: 0.8020\n",
            "Epoch 91/512\n",
            "793/812 [============================>.] - ETA: 0s - loss: 0.4859 - accuracy: 0.7024\n",
            "Epoch 91: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.6995 - val_loss: 0.4454 - val_accuracy: 0.7426\n",
            "Epoch 92/512\n",
            "780/812 [===========================>..] - ETA: 0s - loss: 0.4820 - accuracy: 0.6897\n",
            "Epoch 92: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.6884 - val_loss: 0.4433 - val_accuracy: 0.7475\n",
            "Epoch 93/512\n",
            "808/812 [============================>.] - ETA: 0s - loss: 0.4869 - accuracy: 0.6918\n",
            "Epoch 93: val_loss did not improve from 0.44299\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.6921 - val_loss: 0.4453 - val_accuracy: 0.7525\n",
            "Epoch 94/512\n",
            "799/812 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.6934\n",
            "Epoch 94: val_loss improved from 0.44299 to 0.44049, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.6983 - val_loss: 0.4405 - val_accuracy: 0.7475\n",
            "Epoch 95/512\n",
            "782/812 [===========================>..] - ETA: 0s - loss: 0.4861 - accuracy: 0.6957\n",
            "Epoch 95: val_loss did not improve from 0.44049\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.6933 - val_loss: 0.4495 - val_accuracy: 0.8069\n",
            "Epoch 96/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.6989\n",
            "Epoch 96: val_loss did not improve from 0.44049\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4862 - accuracy: 0.6983 - val_loss: 0.4440 - val_accuracy: 0.7525\n",
            "Epoch 97/512\n",
            "789/812 [============================>.] - ETA: 0s - loss: 0.4845 - accuracy: 0.6958\n",
            "Epoch 97: val_loss did not improve from 0.44049\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.6909 - val_loss: 0.4448 - val_accuracy: 0.7525\n",
            "Epoch 98/512\n",
            "785/812 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.6968\n",
            "Epoch 98: val_loss improved from 0.44049 to 0.43976, saving model to Maternal_Health_Risk_Data_Set.csv\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.6970 - val_loss: 0.4398 - val_accuracy: 0.7525\n",
            "Epoch 99/512\n",
            "798/812 [============================>.] - ETA: 0s - loss: 0.4846 - accuracy: 0.7030\n",
            "Epoch 99: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.7032 - val_loss: 0.4402 - val_accuracy: 0.7475\n",
            "Epoch 100/512\n",
            "782/812 [===========================>..] - ETA: 0s - loss: 0.4855 - accuracy: 0.6905\n",
            "Epoch 100: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4860 - accuracy: 0.6909 - val_loss: 0.4399 - val_accuracy: 0.7525\n",
            "Epoch 101/512\n",
            "803/812 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.6961\n",
            "Epoch 101: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4846 - accuracy: 0.6946 - val_loss: 0.4481 - val_accuracy: 0.8020\n",
            "Epoch 102/512\n",
            "805/812 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.7093\n",
            "Epoch 102: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4843 - accuracy: 0.7094 - val_loss: 0.4421 - val_accuracy: 0.7525\n",
            "Epoch 103/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.4814 - accuracy: 0.6793\n",
            "Epoch 103: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4851 - accuracy: 0.6798 - val_loss: 0.4428 - val_accuracy: 0.7475\n",
            "Epoch 104/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.6927\n",
            "Epoch 104: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4868 - accuracy: 0.6933 - val_loss: 0.4456 - val_accuracy: 0.7525\n",
            "Epoch 105/512\n",
            "785/812 [============================>.] - ETA: 0s - loss: 0.4866 - accuracy: 0.6866\n",
            "Epoch 105: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.6921 - val_loss: 0.4415 - val_accuracy: 0.7574\n",
            "Epoch 106/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4838 - accuracy: 0.6989\n",
            "Epoch 106: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.6958 - val_loss: 0.4410 - val_accuracy: 0.7426\n",
            "Epoch 107/512\n",
            "795/812 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.6918\n",
            "Epoch 107: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.6921 - val_loss: 0.4429 - val_accuracy: 0.7525\n",
            "Epoch 108/512\n",
            "790/812 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.7139\n",
            "Epoch 108: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.7143 - val_loss: 0.4433 - val_accuracy: 0.7475\n",
            "Epoch 109/512\n",
            "795/812 [============================>.] - ETA: 0s - loss: 0.4821 - accuracy: 0.6931\n",
            "Epoch 109: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.6921 - val_loss: 0.4467 - val_accuracy: 0.7475\n",
            "Epoch 110/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.4810 - accuracy: 0.6982\n",
            "Epoch 110: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4842 - accuracy: 0.6933 - val_loss: 0.4534 - val_accuracy: 0.7970\n",
            "Epoch 111/512\n",
            "795/812 [============================>.] - ETA: 0s - loss: 0.4846 - accuracy: 0.7006\n",
            "Epoch 111: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4853 - accuracy: 0.6983 - val_loss: 0.4423 - val_accuracy: 0.7525\n",
            "Epoch 112/512\n",
            "801/812 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.7079\n",
            "Epoch 112: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4835 - accuracy: 0.7106 - val_loss: 0.4402 - val_accuracy: 0.7475\n",
            "Epoch 113/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4815 - accuracy: 0.7026\n",
            "Epoch 113: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4823 - accuracy: 0.7032 - val_loss: 0.4450 - val_accuracy: 0.7475\n",
            "Epoch 114/512\n",
            "790/812 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.6962\n",
            "Epoch 114: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4872 - accuracy: 0.6946 - val_loss: 0.4412 - val_accuracy: 0.7426\n",
            "Epoch 115/512\n",
            "786/812 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.6934\n",
            "Epoch 115: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.6921 - val_loss: 0.4457 - val_accuracy: 0.7475\n",
            "Epoch 116/512\n",
            "798/812 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.6867\n",
            "Epoch 116: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4861 - accuracy: 0.6884 - val_loss: 0.4434 - val_accuracy: 0.7525\n",
            "Epoch 117/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.4838 - accuracy: 0.6939\n",
            "Epoch 117: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4822 - accuracy: 0.6983 - val_loss: 0.4453 - val_accuracy: 0.7475\n",
            "Epoch 118/512\n",
            "788/812 [============================>.] - ETA: 0s - loss: 0.4857 - accuracy: 0.6980\n",
            "Epoch 118: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.6958 - val_loss: 0.4431 - val_accuracy: 0.7426\n",
            "Epoch 119/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.4914 - accuracy: 0.6901\n",
            "Epoch 119: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.6933 - val_loss: 0.4452 - val_accuracy: 0.7426\n",
            "Epoch 120/512\n",
            "809/812 [============================>.] - ETA: 0s - loss: 0.4843 - accuracy: 0.6984\n",
            "Epoch 120: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4851 - accuracy: 0.6970 - val_loss: 0.4445 - val_accuracy: 0.7574\n",
            "Epoch 121/512\n",
            "806/812 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.6948\n",
            "Epoch 121: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4844 - accuracy: 0.6958 - val_loss: 0.4447 - val_accuracy: 0.7475\n",
            "Epoch 122/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.7045\n",
            "Epoch 122: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4841 - accuracy: 0.7094 - val_loss: 0.4406 - val_accuracy: 0.7475\n",
            "Epoch 123/512\n",
            "796/812 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.7098\n",
            "Epoch 123: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.7057 - val_loss: 0.4412 - val_accuracy: 0.7475\n",
            "Epoch 124/512\n",
            "805/812 [============================>.] - ETA: 0s - loss: 0.4843 - accuracy: 0.6857\n",
            "Epoch 124: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4853 - accuracy: 0.6835 - val_loss: 0.4451 - val_accuracy: 0.7525\n",
            "Epoch 125/512\n",
            "796/812 [============================>.] - ETA: 0s - loss: 0.4820 - accuracy: 0.7010\n",
            "Epoch 125: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.7044 - val_loss: 0.4412 - val_accuracy: 0.7426\n",
            "Epoch 126/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4896 - accuracy: 0.6902\n",
            "Epoch 126: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4879 - accuracy: 0.6921 - val_loss: 0.4452 - val_accuracy: 0.7574\n",
            "Epoch 127/512\n",
            "791/812 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.7004\n",
            "Epoch 127: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4826 - accuracy: 0.7020 - val_loss: 0.4418 - val_accuracy: 0.7475\n",
            "Epoch 128/512\n",
            "778/812 [===========================>..] - ETA: 0s - loss: 0.4804 - accuracy: 0.7005\n",
            "Epoch 128: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4859 - accuracy: 0.6958 - val_loss: 0.4419 - val_accuracy: 0.7525\n",
            "Epoch 129/512\n",
            "801/812 [============================>.] - ETA: 0s - loss: 0.4848 - accuracy: 0.6941\n",
            "Epoch 129: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4847 - accuracy: 0.6946 - val_loss: 0.4437 - val_accuracy: 0.7525\n",
            "Epoch 130/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.4871 - accuracy: 0.6926\n",
            "Epoch 130: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.6933 - val_loss: 0.4426 - val_accuracy: 0.7525\n",
            "Epoch 131/512\n",
            "807/812 [============================>.] - ETA: 0s - loss: 0.4823 - accuracy: 0.7125\n",
            "Epoch 131: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4811 - accuracy: 0.7131 - val_loss: 0.4582 - val_accuracy: 0.7426\n",
            "Epoch 132/512\n",
            "811/812 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.6868\n",
            "Epoch 132: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4840 - accuracy: 0.6860 - val_loss: 0.4422 - val_accuracy: 0.7426\n",
            "Epoch 133/512\n",
            "800/812 [============================>.] - ETA: 0s - loss: 0.4848 - accuracy: 0.6938\n",
            "Epoch 133: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4849 - accuracy: 0.6933 - val_loss: 0.4488 - val_accuracy: 0.7574\n",
            "Epoch 134/512\n",
            "809/812 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.6848\n",
            "Epoch 134: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4850 - accuracy: 0.6847 - val_loss: 0.4444 - val_accuracy: 0.7525\n",
            "Epoch 135/512\n",
            "786/812 [============================>.] - ETA: 0s - loss: 0.4841 - accuracy: 0.6959\n",
            "Epoch 135: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4842 - accuracy: 0.6946 - val_loss: 0.4458 - val_accuracy: 0.7525\n",
            "Epoch 136/512\n",
            "798/812 [============================>.] - ETA: 0s - loss: 0.4831 - accuracy: 0.6942\n",
            "Epoch 136: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4834 - accuracy: 0.6946 - val_loss: 0.4464 - val_accuracy: 0.7525\n",
            "Epoch 137/512\n",
            "802/812 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.6995\n",
            "Epoch 137: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4842 - accuracy: 0.6995 - val_loss: 0.4438 - val_accuracy: 0.7426\n",
            "Epoch 138/512\n",
            "784/812 [===========================>..] - ETA: 0s - loss: 0.4827 - accuracy: 0.6939\n",
            "Epoch 138: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4835 - accuracy: 0.6872 - val_loss: 0.4554 - val_accuracy: 0.8069\n",
            "Epoch 139/512\n",
            "800/812 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.7100\n",
            "Epoch 139: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4859 - accuracy: 0.7106 - val_loss: 0.4442 - val_accuracy: 0.7475\n",
            "Epoch 140/512\n",
            "797/812 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.6939\n",
            "Epoch 140: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4850 - accuracy: 0.6933 - val_loss: 0.4442 - val_accuracy: 0.7525\n",
            "Epoch 141/512\n",
            "790/812 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.6911\n",
            "Epoch 141: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4846 - accuracy: 0.6884 - val_loss: 0.4443 - val_accuracy: 0.7525\n",
            "Epoch 142/512\n",
            "792/812 [============================>.] - ETA: 0s - loss: 0.4852 - accuracy: 0.6932\n",
            "Epoch 142: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4843 - accuracy: 0.6946 - val_loss: 0.4431 - val_accuracy: 0.7426\n",
            "Epoch 143/512\n",
            "785/812 [============================>.] - ETA: 0s - loss: 0.4831 - accuracy: 0.7108\n",
            "Epoch 143: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4780 - accuracy: 0.7167 - val_loss: 0.4530 - val_accuracy: 0.7970\n",
            "Epoch 144/512\n",
            "800/812 [============================>.] - ETA: 0s - loss: 0.4806 - accuracy: 0.6875\n",
            "Epoch 144: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.6872 - val_loss: 0.4421 - val_accuracy: 0.7475\n",
            "Epoch 145/512\n",
            "808/812 [============================>.] - ETA: 0s - loss: 0.4820 - accuracy: 0.6968\n",
            "Epoch 145: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4832 - accuracy: 0.6946 - val_loss: 0.4449 - val_accuracy: 0.7475\n",
            "Epoch 146/512\n",
            "793/812 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.6974\n",
            "Epoch 146: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4840 - accuracy: 0.7007 - val_loss: 0.4498 - val_accuracy: 0.7426\n",
            "Epoch 147/512\n",
            "794/812 [============================>.] - ETA: 0s - loss: 0.4843 - accuracy: 0.6889\n",
            "Epoch 147: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4880 - accuracy: 0.6872 - val_loss: 0.4437 - val_accuracy: 0.7574\n",
            "Epoch 148/512\n",
            "812/812 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.6933\n",
            "Epoch 148: val_loss did not improve from 0.43976\n",
            "812/812 [==============================] - 2s 2ms/step - loss: 0.4849 - accuracy: 0.6933 - val_loss: 0.4428 - val_accuracy: 0.7525\n",
            "Epoch 148: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File name must be in quotes\n",
        "model.load_weights('Maternal_Health_Risk_Data_Set.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTIowhGQYOwM",
        "outputId": "3cf38168-cc34-4d9e-cd95-2791b39f9abd"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1b13e4d590>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on the validation set\n",
        "P3 = model.predict(X_V_no_age_bt_hr_dBP)\n",
        "accuracy = model.evaluate(X_V_no_age_bt_hr_dBP, YVALID)\n",
        "my_f1 = f1_score(YVALID, P3.round())\n",
        "my_precision = precision_score(YVALID, P3.round())\n",
        "print(\"f1: \",my_f1)\n",
        "print(\"precision: \",my_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIgPbwosSf4g",
        "outputId": "be67985a-7187-4076-8c15-c9ea764a9cb7"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.6040\n",
            "f1:  0.7530864197530863\n",
            "precision:  0.6039603960396039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after collecting 6 single attributes here is the plot \n",
        "singledata = [0.7228, 0.7079, 0.6188, 0.6040,  0.6040, 0.6040]\n",
        "labels = ['bloodSugar', 'systolicBP', 'diastolicBP', 'age', 'bodyTemp', 'heartRate']\n",
        "plt.xticks([0,1,2,3,4,5], labels)\n",
        "plt.xlabel('Inputs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('single attribute prediction performance')\n",
        "plt.bar([0,1,2,3,4,5], singledata, width = 0.3) \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "U4qFLGwX0Xf6",
        "outputId": "0699fc15-61c7-455a-83b3-9ef56e31ab16"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after collecting taking each single attribute out, here is the plot \n",
        "take_out_data = [0.7970, 0.8069, 0.7772, 0.7624,  0.7525]\n",
        "labels = ['whole model','without age', 'without age/bt', 'without age/bt/hr', 'without age/bt/hr/dBP']\n",
        "plt.xticks([0,1,2,3,4], labels, rotation = 45)\n",
        "\n",
        "plt.xlabel('Inputs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('model performance with decreasing input number')\n",
        "plt.bar([0,1,2,3,4], take_out_data, width = 0.4) \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "TZGmiRV7CY4s",
        "outputId": "a1754b2c-beaa-47a5-8a63-5fd650705b9e"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/phrase4Report.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eyeicz4_HcPV",
        "outputId": "f9e15a0f-ef9b-4b2b-e260-8a23ad311009"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern '/content/phrase4Report.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            `Exporter` class\n",
            "    Default: 'html'\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the \n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current \n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy \n",
            "            of reveal.js. \n",
            "            For speaker notes to work, this must be a relative path to a local \n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb\n",
            "\n",
            "            which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "\n",
            "            You can specify the export format with `--to`.\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "            can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of \n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b690fa24d35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jupyter nbconvert --to html /content/phrase4Report.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'jupyter nbconvert --to html /content/phrase4Report.ipynb' returned non-zero exit status 255."
          ]
        }
      ]
    }
  ]
}